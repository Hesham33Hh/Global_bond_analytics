{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PACKAGE IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from math import sqrt\n",
    "\n",
    "# Data science and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Scientific computing\n",
    "from scipy import stats\n",
    "\n",
    "# Statistics and econometrics\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch, het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_YIELDS_CSV = \"files/raw/us_treasury_yields_daily.csv\"\n",
    "YIELDS_CSV = \"files/raw/yields.csv\"\n",
    "MACRO_CSV  = \"files/raw/world_bank_development_indicators.csv\"\n",
    "WORLD_BANK_DATA = \"files/raw/world_bank_data_2025.csv\"\n",
    "DGS10 = \"files/raw/DGS10.csv\"\n",
    "IRLTLT=\"files/raw/IRLTLT01DEM156N.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USA: 10Y Yield vs Inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columna 10 a√±os\n",
    "def detect_10y_col(cols):\n",
    "    for c in cols:\n",
    "        cl = c.strip().lower()\n",
    "        if cl in {\"us10y\",\"10y\",\"10 yr\",\"10-year\",\"10 year\",\"10_yr\"}:\n",
    "            return c\n",
    "    for c in cols:\n",
    "        cl = c.lower()\n",
    "        if \"10\" in cl and (\"yr\" in cl or \"year\" in cl):\n",
    "            return c\n",
    "    if \"US10Y\" in cols: return \"US10Y\"\n",
    "    if \"10 Yr\" in cols: return \"10 Yr\"\n",
    "    raise ValueError(f\"No encuentro columna 10Y en yields. Columnas: {list(cols)[:12]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_col(df, preferred_cols=(\"year\",\"date\",\"fecha\",\"period\",\"time\",\"obs_date\",\"observationdate\")):\n",
    "    \"\"\"\n",
    "    Devuelve una Serie 'Year' (int) extra√≠da de la mejor columna disponible:\n",
    "    - Si hay 'year' num√©rico, lo usa.\n",
    "    - Si hay fechas, parsea a datetime y saca el a√±o.\n",
    "    - Si hay strings tipo '1960 [YR1960]' o 'YR1960', extrae los 4 d√≠gitos por regex.\n",
    "    \"\"\"\n",
    "    # 1) columna expl√≠cita de a√±o\n",
    "    for c in df.columns:\n",
    "        if c.lower() in (\"year\",\"anio\",\"a√±o\"):\n",
    "            y = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "            if y.notna().any():\n",
    "                return y.astype(\"Int64\")\n",
    "    # 2) columnas ‚Äúfecha‚Äù\n",
    "    for cand in preferred_cols:\n",
    "        for c in df.columns:\n",
    "            if c.lower()==cand:\n",
    "                # a) intentar datetime\n",
    "                dt = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=False)\n",
    "                if dt.notna().any():\n",
    "                    return dt.dt.year.astype(\"Int64\")\n",
    "                # b) extraer patr√≥n de 4 d√≠gitos\n",
    "                s = df[c].astype(str).str.extract(r'(\\d{4})', expand=False)\n",
    "                y = pd.to_numeric(s, errors=\"coerce\")\n",
    "                if y.notna().any():\n",
    "                    return y.astype(\"Int64\")\n",
    "    # 3) si ninguna funciona, intentar extraer 4 d√≠gitos de cualquier columna de texto\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype==object:\n",
    "            s = df[c].astype(str).str.extract(r'(\\d{4})', expand=False)\n",
    "            y = pd.to_numeric(s, errors=\"coerce\")\n",
    "            if y.notna().sum() >= len(df)*0.3:\n",
    "                return y.astype(\"Int64\")\n",
    "    return pd.Series([pd.NA]*len(df), index=df.index, dtype=\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inflation_col(df):\n",
    "    \"\"\"\n",
    "    Busca una columna de inflaci√≥n (%). Prioriza nombres t√≠picos.\n",
    "    \"\"\"\n",
    "    prefs = [\"inflation_annual%\", \"inflation_yoy\", \"inflation yoy\", \"inflation%\", \"inflation\", \"cpi_yoy\", \"cpi yoy\"]\n",
    "    # prioridad por nombre\n",
    "    for p in prefs:\n",
    "        for c in df.columns:\n",
    "            if p.replace(\" \",\"\") in c.replace(\" \",\"\").lower():\n",
    "                return c\n",
    "    # si no, una 'value' gen√©rica\n",
    "    for c in df.columns:\n",
    "        if \"value\" in c.lower() or \"valor\" in c.lower():\n",
    "            return c\n",
    "    # √∫ltimo recurso: columna num√©rica ‚Äúprometedora‚Äù\n",
    "    numc = [c for c in df.columns if pd.to_numeric(df[c], errors=\"coerce\").notna().sum()>0]\n",
    "    if numc:\n",
    "        return numc[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_country_usa(df):\n",
    "    \"\"\"\n",
    "    Intenta filtrar USA por varias columnas posibles.\n",
    "    \"\"\"\n",
    "    # a) 'Country Code' == USA\n",
    "    for c in df.columns:\n",
    "        if c.lower() in (\"country code\",\"country_code\",\"iso3\",\"isocode\",\"code\"):\n",
    "            mask = df[c].astype(str).str.upper().eq(\"USA\")\n",
    "            if mask.any(): \n",
    "                return df.loc[mask].copy()\n",
    "    # b) 'Country' / 'Country Name' contiene 'United States' o 'USA'\n",
    "    for c in df.columns:\n",
    "        if c.lower() in (\"country\",\"country name\",\"pais\"):\n",
    "            mask = df[c].astype(str).str.contains(r\"\\b(united states|usa)\\b\", case=False, na=False)\n",
    "            if mask.any():\n",
    "                return df.loc[mask].copy()\n",
    "    # si no hay pa√≠s, asumimos que el archivo ya es solo USA (devolver tal cual)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (funciona con \"country|date|inflation_annual%\")\n",
    "\n",
    "# ---------- 1) Yields USA -> anual 10Y ----------\n",
    "y = pd.read_csv(DAILY_YIELDS_CSV)\n",
    "\n",
    "# fecha\n",
    "date_col = next((c for c in y.columns if c.lower() in {\"date\",\"fecha\"}), None)\n",
    "if date_col is None:\n",
    "    raise ValueError(\"No encuentro columna de fecha en yields CSV.\")\n",
    "y[date_col] = pd.to_datetime(y[date_col], errors=\"coerce\")\n",
    "y = y.dropna(subset=[date_col])\n",
    "col10 = detect_10y_col(y.columns)\n",
    "\n",
    "# anual\n",
    "y = y[[date_col, col10]].rename(columns={date_col:\"date\", col10:\"yield_10y\"})\n",
    "y[\"Year\"] = y[\"date\"].dt.year.astype(int)\n",
    "us_annual = y.groupby(\"Year\", as_index=False)[\"yield_10y\"].mean()\n",
    "print(\"YIELDS USA ‚Äî a√±os:\", us_annual[\"Year\"].min(), \"‚Üí\", us_annual[\"Year\"].max(), \"| n:\", len(us_annual))\n",
    "\n",
    "# ========= DIAGN√ìSTICO + EXTRACCI√ìN ROBUSTA DE INFLACI√ìN (USA) =========\n",
    "m = pd.read_csv(MACRO_CSV)\n",
    "\n",
    "# 1) filtrar USA\n",
    "m_usa = filter_country_usa(m)\n",
    "\n",
    "# 2) obtener Year robusto\n",
    "m_usa[\"Year\"] = extract_year_col(m_usa)\n",
    "\n",
    "# 3) localizar columna de inflaci√≥n\n",
    "infl_col = find_inflation_col(m_usa)\n",
    "if infl_col is None:\n",
    "    raise RuntimeError(\"No encuentro columna de inflaci√≥n en tu archivo macro. Revisa nombres de columnas.\")\n",
    "\n",
    "# 4) preparar inflaci√≥n anual\n",
    "infl = (\n",
    "    m_usa[[\"Year\", infl_col]]\n",
    "      .rename(columns={infl_col:\"inflation_yoy\"})\n",
    "      .assign(inflation_yoy=lambda d: pd.to_numeric(d[\"inflation_yoy\"], errors=\"coerce\"))\n",
    "      .dropna(subset=[\"Year\",\"inflation_yoy\"])\n",
    ")\n",
    "infl[\"Year\"] = infl[\"Year\"].astype(int)\n",
    "\n",
    "# Si es mensual (m√∫ltiples filas por a√±o), promediamos\n",
    "infl = infl.groupby(\"Year\", as_index=False)[\"inflation_yoy\"].mean()\n",
    "\n",
    "print(\"Yields USA: \", us_annual[\"Year\"].min(), \"‚Üí\", us_annual[\"Year\"].max(), \"| n:\", len(us_annual))\n",
    "print(\"Inflaci√≥n USA:\", infl[\"Year\"].min() if len(infl) else None, \"‚Üí\", infl[\"Year\"].max() if len(infl) else None, \"| n:\", len(infl))\n",
    "\n",
    "# 5) forzar intersecci√≥n y MERGE\n",
    "min_year = max(us_annual[\"Year\"].min(), infl[\"Year\"].min())\n",
    "max_year = min(us_annual[\"Year\"].max(), infl[\"Year\"].max())\n",
    "infl_clip = infl[(infl[\"Year\"]>=min_year) & (infl[\"Year\"]<=max_year)]\n",
    "ua_clip   = us_annual[(us_annual[\"Year\"]>=min_year) & (us_annual[\"Year\"]<=max_year)]\n",
    "\n",
    "df = ua_clip.merge(infl_clip, on=\"Year\", how=\"inner\").sort_values(\"Year\").reset_index(drop=True)\n",
    "if df.empty:\n",
    "    # diagn√≥stico extra\n",
    "    print(\">>> DEBUG ‚Äî YEARS YIELDS:\", sorted(us_annual[\"Year\"].unique())[:10], \"...\", sorted(us_annual[\"Year\"].unique())[-10:])\n",
    "    print(\">>> DEBUG ‚Äî YEARS INFL :\", sorted(infl[\"Year\"].unique())[:10], \"...\", sorted(infl[\"Year\"].unique())[-10:])\n",
    "    raise RuntimeError(\"Sigue sin haber a√±os comunes. Revisa que 'Year' se est√© extrayendo bien del macro CSV.\")\n",
    "\n",
    "df[\"real_yield\"] = df[\"yield_10y\"] - df[\"inflation_yoy\"]\n",
    "\n",
    "print(\"Filas tras merge:\", len(df))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df[\"Year\"], df[\"yield_10y\"], label=\"US 10Y Yield\")\n",
    "plt.plot(df[\"Year\"], df[\"inflation_yoy\"], label=\"Inflation YoY\")\n",
    "plt.title(\"USA: 10Y Yield vs Inflation\")\n",
    "plt.xlabel(\"Year\"); plt.ylabel(\"%\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(df[\"inflation_yoy\"], df[\"yield_10y\"])\n",
    "plt.title(\"Relaci√≥n: Inflaci√≥n vs US 10Y Yield\")\n",
    "plt.xlabel(\"Inflation YoY (%)\"); plt.ylabel(\"US 10Y Yield (%)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Serie temporal: USA 10Y Yield vs Inflaci√≥n (l√≠neas)\n",
    "\n",
    "La l√≠nea azul (US 10Y Yield) muestra la rentabilidad de los bonos a 10 a√±os.\n",
    "\n",
    "La l√≠nea naranja (Inflation YoY) muestra la inflaci√≥n anual.\n",
    "\n",
    "Interpretaci√≥n r√°pida:\n",
    "\n",
    "En los a√±os 70-80 se ve un pico muy alto de inflaci√≥n y yield: es la √©poca de la crisis del petr√≥leo y la pol√≠tica monetaria dura de la Fed (Volcker subi√≥ tipos muy fuertes).\n",
    "\n",
    "Desde los a√±os 90 hasta 2020, ambos bajan gradualmente ‚Üí entorno de baja inflaci√≥n y yields decrecientes.\n",
    "\n",
    "Despu√©s de 2020, la inflaci√≥n se dispara otra vez (post-COVID, guerra, disrupciones en energ√≠a).\n",
    "\n",
    "üëâ Eso muestra que existe cierta relaci√≥n: cuando la inflaci√≥n sube fuerte, los yields suelen subir tambi√©n, pero con rezagos o diferente magnitud.\n",
    "\n",
    "#### 2. Diagrama de dispersi√≥n: Inflaci√≥n vs Yield\n",
    "\n",
    "Cada punto es un a√±o (x = inflaci√≥n, y = yield).\n",
    "\n",
    "Se ve una nube ascendente: cuando la inflaci√≥n es baja (0-4%), los yields tienden a estar en 2-6%.\n",
    "\n",
    "Cuando la inflaci√≥n es alta (6-12%), los yields tambi√©n tienden a estar arriba (8-14%).\n",
    "\n",
    "Interpretaci√≥n r√°pida:\n",
    "\n",
    "Hay una correlaci√≥n positiva: inflaci√≥n y yields tienden a moverse juntos.\n",
    "\n",
    "Pero no es 1:1 ‚Üí hay dispersi√≥n (porque los yields dependen tambi√©n de pol√≠tica monetaria, expectativas, riesgo, etc.).\n",
    "\n",
    "#### 3. Resumen antes de limpieza\n",
    "\n",
    "Los datos ya muestran una relaci√≥n clara: m√°s inflaci√≥n = m√°s yield.\n",
    "\n",
    "Pero hay ruido y valores extremos (ej: hiperinflaci√≥n o datos at√≠picos que vimos en la tabla).\n",
    "\n",
    "Por eso, la siguiente etapa de limpieza (quitar inflaciones absurdas, errores, etc.) servir√° para tener relaciones m√°s n√≠tidas y modelos m√°s confiables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estad√≠sticas b√°sicas antes de limpiar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Correlaci√≥n simple ---\")\n",
    "print(df[[\"yield_10y\", \"inflation_yoy\"]].corr())\n",
    "\n",
    "# Regresi√≥n lineal simple (Inflaci√≥n -> Yield)\n",
    "\n",
    "X = df[\"inflation_yoy\"]\n",
    "y = df[\"yield_10y\"]\n",
    "\n",
    "X = sm.add_constant(X)  # a√±adimos intercepto\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(\"\\n--- Regresi√≥n lineal simple ---\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Correlaci√≥n simple\n",
    "\n",
    "0.61 (positivo, moderado-fuerte) ‚Üí Significa que cuando la inflaci√≥n sube, los rendimientos del bono a 10 a√±os en USA tienden a subir tambi√©n.\n",
    "\n",
    "No es una correlaci√≥n perfecta (1.0), pero s√≠ clara y estad√≠sticamente significativa.\n",
    "\n",
    "#### üìà Regresi√≥n lineal simple\n",
    "\n",
    "Modelo:\n",
    "\n",
    "Yield¬†10Y\n",
    "\n",
    "=\n",
    "3.3783\n",
    "+\n",
    "0.6571\n",
    "‚ãÖ\n",
    "Inflaci\n",
    "o\n",
    "Àä\n",
    "n¬†YoY\n",
    "Yield¬†10Y=3.3783+0.6571‚ãÖInflaci\n",
    "o\n",
    "Àä\n",
    "n¬†YoY\n",
    "\n",
    "Constante (3.38): cuando la inflaci√≥n es 0, el modelo predice un rendimiento del 3.38%.\n",
    "\n",
    "Coeficiente (0.6571): por cada +1% en la inflaci√≥n, el yield sube en promedio +0.65%.\n",
    "\n",
    "p-valor (0.000): relaci√≥n estad√≠sticamente muy significativa.\n",
    "\n",
    "R¬≤ = 0.38: la inflaci√≥n explica el 38% de la variaci√≥n en los yields.\n",
    "\n",
    "Esto es bastante alto para datos macro, pero tambi√©n nos dice que hay un 62% de variaci√≥n que se explica por otros factores (ej. pol√≠tica monetaria, riesgo pa√≠s, oferta/demanda global de bonos, etc.).\n",
    "\n",
    "#### üìå Conclusi√≥n preliminar\n",
    "\n",
    "Existe una relaci√≥n positiva clara entre inflaci√≥n y yields en USA (1962‚Äì2024).\n",
    "\n",
    "La inflaci√≥n no lo explica todo, pero s√≠ es un driver muy importante.\n",
    "\n",
    "Esto tiene sentido econ√≥mico: los inversores piden m√°s rentabilidad en los bonos cuando esperan m√°s inflaci√≥n (para no perder poder adquisitivo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ Resumen r√°pido (checkpoint hasta ahora):\n",
    "\n",
    "Ya cargamos y visualizamos las series de rendimiento del bono USA 10Y y inflaci√≥n anual (1962‚Äì2024).\n",
    "\n",
    "Encontramos una correlaci√≥n positiva moderada (0.61) ‚Üí cuando la inflaci√≥n sube, los yields tambi√©n tienden a subir.\n",
    "\n",
    "La regresi√≥n lineal mostr√≥ que un +1% en inflaci√≥n se asocia con un +0.65% en el yield 10Y, con R¬≤ = 0.38 ‚Üí la inflaci√≥n explica parte importante, pero no todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paso 1: Copiar y limpiar outliers\n",
    "# ===============================\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Quitamos inflaciones absurdas (ej. errores de dataset o hiperinflaci√≥n)\n",
    "df_clean = df_clean[df_clean[\"inflation_yoy\"].between(-20, 50)]\n",
    "\n",
    "print(\"Filas antes:\", len(df), \" | despu√©s:\", len(df_clean))\n",
    "\n",
    "# ===============================\n",
    "# Paso 2: Recalcular real_yield\n",
    "# ===============================\n",
    "\n",
    "df_clean[\"real_yield\"] = df_clean[\"yield_10y\"] - df_clean[\"inflation_yoy\"]\n",
    "\n",
    "# ===============================\n",
    "# Paso 3: Chequeo r√°pido\n",
    "# ===============================\n",
    "print(\"\\n√öltimos a√±os limpios:\")\n",
    "print(df_clean.tail(10))\n",
    "\n",
    "# ===============================\n",
    "# Paso 4: Visualizaci√≥n post-limpieza\n",
    "# ===============================\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"yield_10y\"], label=\"US 10Y Yield\")\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"inflation_yoy\"], label=\"Inflation YoY\")\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"real_yield\"], label=\"Real Yield\", linestyle=\"--\")\n",
    "plt.title(\"USA: Yield 10Y, Inflaci√≥n y Real Yield (datos limpios)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n r√°pida del gr√°fico\n",
    "\n",
    "A√±os 70s ‚Äì 80s:\n",
    "\n",
    "La inflaci√≥n se dispara (choques del petr√≥leo).\n",
    "\n",
    "Los rendimientos nominales (azul) tambi√©n suben fuerte.\n",
    "\n",
    "El rendimiento real (verde) se mantiene positivo pero muy vol√°til.\n",
    "\n",
    "A√±os 90s ‚Äì 2000s:\n",
    "\n",
    "Inflaci√≥n baja y estable (2‚Äì3%).\n",
    "\n",
    "Yield nominal cae gradualmente.\n",
    "\n",
    "El rendimiento real es bajo pero estable.\n",
    "\n",
    "2010s en adelante:\n",
    "\n",
    "Rendimientos muy bajos (pol√≠tica monetaria expansiva).\n",
    "\n",
    "Inflaci√≥n estable‚Ä¶ hasta el repunte 2021‚Äì2022.\n",
    "\n",
    "En 2021‚Äì2022 el real yield se hace negativo (bonos pierden contra inflaci√≥n).\n",
    "\n",
    "#### Qu√© significa:\n",
    "\n",
    "Cuando el real yield es positivo ‚Üí los bonos dan un retorno por encima de la inflaci√≥n (buen refugio).\n",
    "\n",
    "Cuando el real yield es negativo ‚Üí los inversores pierden poder adquisitivo aunque inviertan en bonos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlaci√≥n con datos limpios ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Correlaci√≥n simple (datos limpios) ---\")\n",
    "print(df_clean[[\"yield_10y\", \"inflation_yoy\"]].corr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresi√≥n lineal simple (datos limpios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean[[\"inflation_yoy\"]]\n",
    "y = df_clean[\"yield_10y\"]\n",
    "\n",
    "# Agregar constante al modelo\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model_clean = sm.OLS(y, X).fit()\n",
    "print(\"\\n--- Regresi√≥n lineal simple (datos limpios) ---\")\n",
    "print(model_clean.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretaci√≥n del output de la regresi√≥n lineal:\n",
    "\n",
    "Coeficientes (const y inflaci√≥n)\n",
    "\n",
    "Constante (const = 3.3783) ‚Üí cuando la inflaci√≥n es 0, el rendimiento de los bonos a 10 a√±os tiende a estar en torno al 3.38%.\n",
    "\n",
    "Inflaci√≥n (0.6571) ‚Üí por cada +1% en inflaci√≥n, el yield sube en promedio +0.66 puntos porcentuales. Esto confirma una relaci√≥n positiva clara.\n",
    "\n",
    "R¬≤ (0.380)\n",
    "\n",
    "El 38% de la variabilidad del rendimiento de los bonos a 10 a√±os se explica por la inflaci√≥n.\n",
    "\n",
    "Esto significa que la inflaci√≥n influye mucho, pero no lo explica todo (hay otros factores: pol√≠tica monetaria, expectativas, prima de riesgo, etc.).\n",
    "\n",
    "p-values\n",
    "\n",
    "Ambos coeficientes (constante e inflaci√≥n) tienen p < 0.001, es decir, son estad√≠sticamente significativos.\n",
    "\n",
    "La relaci√≥n no es casualidad: hay evidencia fuerte de que la inflaci√≥n impacta en el yield.\n",
    "\n",
    "Durbin-Watson (0.227)\n",
    "\n",
    "Valor bajo ‚Üí indica que puede haber autocorrelaci√≥n en los errores (normal en series temporales).\n",
    "\n",
    "Esto nos dice que quiz√° m√°s adelante necesitemos un modelo de series temporales (ARIMA, VAR) o un modelo con variables adicionales.\n",
    "\n",
    "#### Conclusi√≥n r√°pida para tu proyecto\n",
    "üëâ Existe una relaci√≥n positiva y estad√≠sticamente significativa entre la inflaci√≥n y el rendimiento del bono USA 10Y: cuando la inflaci√≥n sube, el yield tambi√©n sube, aunque la inflaci√≥n explica solo un 38% de la variaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ispersi√≥n inflaci√≥n vs yield con la recta de regresi√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot con la recta de regresi√≥n\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=\"inflation_yoy\", y=\"yield_10y\", data=df_clean, color=\"blue\", label=\"Datos\")\n",
    "\n",
    "# Ajustar la recta\n",
    "coef = 0.6571\n",
    "intercept = 3.3783\n",
    "x_vals = np.linspace(df_clean[\"inflation_yoy\"].min(), df_clean[\"inflation_yoy\"].max(), 100)\n",
    "y_vals = intercept + coef * x_vals\n",
    "plt.plot(x_vals, y_vals, color=\"red\", linewidth=2, label=\"Recta de regresi√≥n\")\n",
    "\n",
    "# T√≠tulos\n",
    "plt.title(\"Inflaci√≥n vs US 10Y Yield con regresi√≥n lineal\")\n",
    "plt.xlabel(\"Inflaci√≥n YoY (%)\")\n",
    "plt.ylabel(\"US 10Y Yield (%)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ecuaci√≥n y el R¬≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot con recta de regresi√≥n y ecuaci√≥n\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=\"inflation_yoy\", y=\"yield_10y\", data=df_clean, color=\"blue\", label=\"Datos\")\n",
    "\n",
    "# Recta de regresi√≥n\n",
    "coef = 0.6571\n",
    "intercept = 3.3783\n",
    "r2 = 0.38  # R-cuadrado de tu modelo\n",
    "x_vals = np.linspace(df_clean[\"inflation_yoy\"].min(), df_clean[\"inflation_yoy\"].max(), 100)\n",
    "y_vals = intercept + coef * x_vals\n",
    "plt.plot(x_vals, y_vals, color=\"red\", linewidth=2, label=\"Recta de regresi√≥n\")\n",
    "\n",
    "# Texto con ecuaci√≥n\n",
    "plt.text(0.05, 0.95,\n",
    "         f\"Yield = {intercept:.2f} + {coef:.2f}*Inflation\\nR¬≤ = {r2:.2f}\",\n",
    "         transform=plt.gca().transAxes,\n",
    "         fontsize=12, color=\"red\", verticalalignment=\"top\")\n",
    "\n",
    "# T√≠tulos y etiquetas\n",
    "plt.title(\"Inflaci√≥n vs US 10Y Yield con regresi√≥n lineal\")\n",
    "plt.xlabel(\"Inflaci√≥n YoY (%)\")\n",
    "plt.ylabel(\"US 10Y Yield (%)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagn√≥stico del modelo (OLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Recalcular (por si abriste sesi√≥n nueva)\n",
    "X = sm.add_constant(df_clean[[\"inflation_yoy\"]])\n",
    "y = df_clean[\"yield_10y\"]\n",
    "model_clean = sm.OLS(y, X).fit()\n",
    "\n",
    "# 2) Residuales y ajustados\n",
    "fitted = model_clean.fittedvalues\n",
    "resid   = model_clean.resid\n",
    "std_res = (resid - resid.mean()) / resid.std(ddof=1)\n",
    "\n",
    "# 3) Plots b√°sicos\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(fitted, resid, alpha=0.8)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Fitted (predichos)\")\n",
    "plt.ylabel(\"Residuos\")\n",
    "plt.title(\"Residuos vs Predichos\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(resid, bins=12, edgecolor=\"k\", alpha=0.8)\n",
    "plt.title(\"Histograma de residuos\")\n",
    "plt.xlabel(\"Residuo\"); plt.ylabel(\"Frecuencia\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "sm.qqplot(resid, line=\"s\")\n",
    "plt.title(\"QQ-plot de residuos\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Residuos a lo largo del tiempo (para ver autocorrelaci√≥n visual)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_clean[\"Year\"], resid, marker=\"o\")\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.title(\"Residuos en el tiempo\")\n",
    "plt.xlabel(\"A√±o\"); plt.ylabel(\"Residuo\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 4) Tests estad√≠sticos\n",
    "print(\"\\n--- Tests de diagn√≥stico ---\")\n",
    "\n",
    "# Normalidad (Jarque‚ÄìBera)\n",
    "try:\n",
    "    # statsmodels siempre devuelve (jb, pvalue, skew, kurtosis)\n",
    "    jb_stat, jb_p, jb_skew, jb_kurt = sm_jb(resid)\n",
    "except Exception:\n",
    "    # fallback: SciPy (puede devolver solo 2 valores)\n",
    "    jb = stats.jarque_bera(resid)\n",
    "    if hasattr(jb, \"__len__\") and len(jb) >= 2:\n",
    "        jb_stat, jb_p = jb[0], jb[1]\n",
    "        jb_skew = jb_kurt = float(\"nan\")\n",
    "    else:\n",
    "        jb_stat = float(jb)\n",
    "        jb_p = float(\"nan\")\n",
    "        jb_skew = jb_kurt = float(\"nan\")\n",
    "print(f\"Jarque-Bera: stat={jb_stat:.3f}, p-value={jb_p:.4f}  (skew={jb_skew:.3f}, kurt={jb_kurt:.3f})\")\n",
    "\n",
    "# Heterocedasticidad (Breusch‚ÄìPagan)\n",
    "bp_stat, bp_p, _, _ = het_breuschpagan(resid, X)\n",
    "print(f\"Breusch-Pagan: stat={bp_stat:.3f}, p-value={bp_p:.4f}\")\n",
    "\n",
    "# Autocorrelaci√≥n en residuos (Ljung‚ÄìBox)\n",
    "lb = acorr_ljungbox(resid, lags=[1, 4, 8, 12], return_df=True)\n",
    "print(\"\\nLjung-Box (p-values):\")\n",
    "print(lb[\"lb_pvalue\"].rename(index={1:\"lag1\",4:\"lag4\",8:\"lag8\",12:\"lag12\"}))\n",
    "\n",
    "# Durbin‚ÄìWatson\n",
    "print(f\"\\nDurbin-Watson: {durbin_watson(resid):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Normalidad de los residuos (Jarque‚ÄìBera)\n",
    "\n",
    "JB = 3.936, p-value = 0.1397\n",
    "\n",
    "Como p > 0.05 ‚Üí no rechazamos la hip√≥tesis nula de normalidad.\n",
    "‚úÖ Los residuos son aproximadamente normales ‚Üí buen s√≠ntoma.\n",
    "\n",
    "2. Heterocedasticidad (Breusch‚ÄìPagan)\n",
    "\n",
    "BP = 1.790, p-value = 0.1809\n",
    "\n",
    "Como p > 0.05 ‚Üí no hay evidencia fuerte de heterocedasticidad.\n",
    "‚úÖ La varianza de los errores parece estable ‚Üí los errores est√°ndar son confiables.\n",
    "\n",
    "3. Autocorrelaci√≥n (Ljung‚ÄìBox + Durbin-Watson)\n",
    "\n",
    "Ljung‚ÄìBox:\n",
    "\n",
    "lag1, lag4, lag8, lag12 ‚Üí p-values casi cero ‚Üí rechazamos la hip√≥tesis de ‚Äúno autocorrelaci√≥n‚Äù.\n",
    "‚ùå Hay autocorrelaci√≥n muy fuerte en los residuos.\n",
    "\n",
    "Durbin‚ÄìWatson = 0.227\n",
    "\n",
    "Valores cercanos a 2 = no autocorrelaci√≥n.\n",
    "\n",
    "Valores < 1 = fuerte autocorrelaci√≥n positiva.\n",
    "\n",
    "Aqu√≠ 0.227 ‚Üí autocorrelaci√≥n positiva extrema.\n",
    "\n",
    "#### En resumen:\n",
    "\n",
    "Normalidad: bien.\n",
    "\n",
    "Homocedasticidad: bien.\n",
    "\n",
    "Autocorrelaci√≥n: muy mal ‚Üí el modelo lineal cl√°sico OLS no captura la din√°mica temporal.\n",
    "\n",
    "üëâ Esto significa que tu modelo simple (Yield ~ Inflaci√≥n) ignora la dependencia temporal. Los rendimientos de bonos son series temporales, por eso los residuos siguen un patr√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reestimaci√≥n con errores robustos HAC (Newey-West)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = sm.add_constant(df_clean[[\"inflation_yoy\"]])\n",
    "y = df_clean[\"yield_10y\"]\n",
    "\n",
    "# Modelo OLS\n",
    "ols_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Ajuste con errores robustos HAC (Newey-West)\n",
    "# lag=4 (aprox. autocorrelaci√≥n hasta 4 rezagos, puedes probar otros valores)\n",
    "nw_model = ols_model.get_robustcov_results(cov_type=\"HAC\", maxlags=4)\n",
    "\n",
    "print(\"\\n--- Regresi√≥n OLS con errores HAC (Newey-West) ---\")\n",
    "print(nw_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "#### üëâ ¬øQu√© cambi√≥ con HAC?\n",
    "\n",
    "Coeficientes (constante = 3.37, inflaci√≥n = 0.65) ‚Üí no cambiaron, porque la relaci√≥n base sigue siendo la misma.\n",
    "\n",
    "Errores est√°ndar (y por tanto t-stats y p-values) ‚Üí son m√°s grandes que antes (ej. la constante pas√≥ de std=0.51 a 0.69).\n",
    "\n",
    "Pero siguen siendo muy significativos (p<0.001) ‚Üí conclusi√≥n: la relaci√≥n inflaci√≥n ‚Üí yield sigue siendo estad√≠sticamente fuerte.\n",
    "\n",
    "Ahora los intervalos de confianza son m√°s realistas, porque tienen en cuenta la autocorrelaci√≥n.\n",
    "\n",
    "‚úÖ En resumen: ya tienemos un modelo lineal robusto que muestra que por cada +1% de inflaci√≥n, el rendimiento a 10 a√±os sube ~0.65% en promedio, con bastante confianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo VAR (Yield + Inflaci√≥n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selecci√≥n de variables\n",
    "var_data = df_clean[[\"yield_10y\", \"inflation_yoy\"]].dropna()\n",
    "\n",
    "# Crear el modelo VAR\n",
    "model_var = VAR(var_data)\n",
    "\n",
    "# Selecci√≥n de n√∫mero √≥ptimo de rezagos (lags)\n",
    "lag_order = model_var.select_order(maxlags=8)\n",
    "print(\"\\n--- Selecci√≥n de rezagos √≥ptimos ---\")\n",
    "print(lag_order.summary())\n",
    "\n",
    "# Ajustar el VAR con el lag √≥ptimo (ejemplo: AIC)\n",
    "best_lag = lag_order.aic\n",
    "results_var = model_var.fit(best_lag)\n",
    "\n",
    "print(\"\\n--- Resumen VAR ---\")\n",
    "print(results_var.summary())\n",
    "\n",
    "# Pron√≥stico 5 a√±os adelante\n",
    "forecast = results_var.forecast(var_data.values[-best_lag:], steps=5)\n",
    "forecast_df = pd.DataFrame(forecast, \n",
    "                           columns=[\"yield_10y_forecast\", \"inflation_forecast\"],\n",
    "                           index=range(df_clean[\"Year\"].max()+1, df_clean[\"Year\"].max()+6))\n",
    "\n",
    "print(\"\\n--- Pron√≥stico 5 a√±os ---\")\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Selecci√≥n de rezagos\n",
    "\n",
    "AIC ‚Üí lag 3 (destacado con *).\n",
    "\n",
    "Esto significa que tanto yield como inflaci√≥n se explican mejor mirando los √∫ltimos 3 a√±os de historia.\n",
    "\n",
    "Tiene sentido: los efectos de la inflaci√≥n en los bonos no son inmediatos, tardan algunos a√±os en reflejarse.\n",
    "\n",
    "#### 2. Resultados del VAR\n",
    "\n",
    "En el resumen VAR, cada ecuaci√≥n muestra c√≥mo una variable depende de sus propios rezagos y de los rezagos de la otra variable.\n",
    "\n",
    "Ejemplo interpretativo (simplificado):\n",
    "\n",
    "yield_10y depende positivamente de la inflaci√≥n rezagada ‚Üí confirma que inflaci√≥n alta hoy tiende a subir los rendimientos en 1‚Äì3 a√±os.\n",
    "\n",
    "inflation_yoy tambi√©n puede mostrar influencia de yield_10y pasado (aunque m√°s d√©bil), porque tipos de inter√©s altos suelen enfriar la inflaci√≥n.\n",
    "\n",
    "#### 3. Pron√≥stico (forecast)\n",
    "\n",
    "El modelo te dio predicciones para 5 a√±os:\n",
    "\n",
    "### A√±o\tYield 10y (%)\tInflaci√≥n (%)\n",
    "2024\t~4.74\t~6.44\n",
    "\n",
    "2025\t~5.21\t~6.03\n",
    "\n",
    "2026\t~5.86\t~6.39\n",
    "\n",
    "2027\t~6.43\t~6.52\n",
    "\n",
    "2028\t(seguir√≠a creciendo en l√≠nea)\t\n",
    "\n",
    "#### Interpretaci√≥n r√°pida:\n",
    "El modelo cree que si la din√°mica hist√≥rica se mantiene:\n",
    "\n",
    "Los rendimientos del 10 a√±os subir√≠an de ~4.7% a ~6.4% en 3 a√±os.\n",
    "\n",
    "La inflaci√≥n se mantendr√≠a alrededor de 6% ‚Üí persistente, no se reduce r√°pido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gr√°fico hist√≥rico + forecast VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datos hist√≥ricos\n",
    "hist_years = df_clean[\"Year\"]\n",
    "hist_yield = df_clean[\"yield_10y\"]\n",
    "hist_infl = df_clean[\"inflation_yoy\"]\n",
    "\n",
    "# Forecast del VAR (lo que ya calculamos antes)\n",
    "forecast_df.index.name = \"Year\"\n",
    "\n",
    "# Unimos hist√≥rico + forecast\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Yield\n",
    "plt.plot(hist_years, hist_yield, label=\"Yield 10y (hist√≥rico)\", color=\"blue\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"yield_10y_forecast\"], \n",
    "         label=\"Yield 10y (forecast VAR)\", color=\"blue\", linestyle=\"--\")\n",
    "\n",
    "# Inflaci√≥n\n",
    "plt.plot(hist_years, hist_infl, label=\"Inflaci√≥n YoY (hist√≥rico)\", color=\"red\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"inflation_forecast\"], \n",
    "         label=\"Inflaci√≥n YoY (forecast VAR)\", color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.axvline(x=2024, color=\"gray\", linestyle=\"--\", alpha=0.6)  # separaci√≥n entre hist√≥rico y forecast\n",
    "plt.title(\"Evoluci√≥n y Forecast (VAR) - Yield 10y vs Inflaci√≥n\")\n",
    "plt.xlabel(\"A√±o\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretaci√≥n del primer gr√°fico (Hist√≥rico + Forecast VAR)\n",
    "\n",
    "Lo que vemos en azul (Yield 10 a√±os)\n",
    "\n",
    "La l√≠nea azul continua: es la evoluci√≥n hist√≥rica del rendimiento de los bonos del Tesoro a 10 a√±os (yield).\n",
    "\n",
    "La l√≠nea azul discontinua: es la predicci√≥n del modelo VAR para los pr√≥ximos a√±os.\n",
    "\n",
    "Observamos que el yield tuvo picos muy altos en los 70‚Äì80 (crisis de inflaci√≥n) y luego una tendencia descendente hasta m√≠nimos recientes.\n",
    "\n",
    "El forecast proyecta un ligero repunte del yield, lo que indica que los tipos de inter√©s reales podr√≠an subir en el futuro.\n",
    "\n",
    "Lo que vemos en rojo (Inflaci√≥n YoY)\n",
    "\n",
    "La l√≠nea roja continua: es la inflaci√≥n hist√≥rica. Destacan los picos en los a√±os 70 (shocks petroleros) y el repunte fuerte en 2021‚Äì2022.\n",
    "\n",
    "La l√≠nea roja discontinua: es la predicci√≥n del VAR. Muestra que la inflaci√≥n podr√≠a bajar desde los picos recientes, pero a√∫n mantenerse algo elevada comparada con los 2010s.\n",
    "\n",
    "Interpretaci√≥n conjunta\n",
    "\n",
    "El modelo VAR nos dice que yield e inflaci√≥n est√°n claramente relacionadas en el tiempo: cuando sube la inflaci√≥n, el yield tiende a subir despu√©s (los inversores exigen m√°s rentabilidad para compensar la p√©rdida de poder adquisitivo).\n",
    "\n",
    "La proyecci√≥n indica un escenario de inflaci√≥n todav√≠a algo elevada con yields acompa√±ando al alza ‚Üí t√≠pico de un contexto post-crisis inflacionaria.\n",
    "\n",
    "#### En resumen:\n",
    "\n",
    "El gr√°fico confirma la relaci√≥n positiva entre inflaci√≥n y yield.\n",
    "\n",
    "El modelo espera que en los pr√≥ximos a√±os ambos suban moderadamente, no a niveles extremos como los 70, pero tampoco tan bajos como en los 2010s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  VAR completo: selecci√≥n de rezagos + ajuste + forecast + IRF\n",
    " Requiere: statsmodels, pandas, matplotlib\n",
    " Usa df_clean con columnas: Year, yield_10y, inflation_yoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Preparar datos para VAR\n",
    "df_var = df_clean[[\"yield_10y\", \"inflation_yoy\"]].dropna().copy()\n",
    "\n",
    "# 1) Selecci√≥n de rezagos √≥ptimos\n",
    "model_var = VAR(df_var)\n",
    "sel = model_var.select_order(maxlags=8)\n",
    "print(\"\\n--- Selecci√≥n de rezagos ---\")\n",
    "print(sel.summary())\n",
    "\n",
    "# Tomamos el lag con mejor AIC (puedes cambiar a .bic/.hqic/.fpe si prefieres)\n",
    "best_lag = sel.aic\n",
    "print(f\"\\nLag elegido (AIC): {best_lag}\")\n",
    "\n",
    "# 2) Ajuste del VAR con ese lag\n",
    "var_res = model_var.fit(best_lag)\n",
    "print(\"\\n--- Resumen VAR ---\")\n",
    "print(var_res.summary())\n",
    "\n",
    "# 3) Forecast 5 pasos hacia adelante\n",
    "steps = 5\n",
    "last_year = int(df_clean[\"Year\"].max())\n",
    "fcast = var_res.forecast(df_var.values[-best_lag:], steps=steps)\n",
    "forecast_df = pd.DataFrame(\n",
    "    fcast,\n",
    "    columns=[\"yield_10y_forecast\",\"inflation_forecast\"],\n",
    "    index=range(last_year+1, last_year+1+steps)\n",
    ")\n",
    "forecast_df.index.name = \"Year\"\n",
    "print(\"\\n--- Forecast ---\")\n",
    "print(forecast_df)\n",
    "\n",
    "# 4) Gr√°fico hist√≥rico + forecast (opcional si ya lo ten√≠as)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"yield_10y\"], label=\"Yield 10y (hist√≥rico)\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"yield_10y_forecast\"], \"--\", label=\"Yield 10y (forecast VAR)\")\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"inflation_yoy\"], label=\"Inflaci√≥n YoY (hist√≥rico)\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"inflation_forecast\"], \"--\", label=\"Inflaci√≥n YoY (forecast VAR)\")\n",
    "plt.axvline(x=last_year, color=\"gray\", linestyle=\"--\", alpha=0.6)\n",
    "plt.title(\"Evoluci√≥n y Forecast (VAR) - Yield 10y vs Inflaci√≥n\")\n",
    "plt.xlabel(\"A√±o\"); plt.ylabel(\"%\"); plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 5) IRF (Impulse Response Functions)\n",
    "irf_h = 10  # horizonte en a√±os\n",
    "irf = var_res.irf(irf_h)\n",
    "\n",
    "# IRF combinadas\n",
    "fig = irf.plot(orth=True)\n",
    "plt.suptitle(\"Funciones de Impulso-Respuesta (IRF)\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# IRF espec√≠ficas (opcional): respuesta de yield a shock de inflaci√≥n, y viceversa\n",
    "fig = irf.plot_cum_effects(orth=True)\n",
    "plt.suptitle(\"IRF acumuladas (orth)\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los resultados del modelo VAR muestran que:\n",
    "\n",
    "La inflaci√≥n impulsa al rendimiento del bono a 10 a√±os, confirmando que mayor inflaci√≥n esperada eleva los tipos largos.\n",
    "\n",
    "El efecto contrario (yields sobre inflaci√≥n) existe pero es m√°s d√©bil y menos persistente.\n",
    "\n",
    "Tanto la inflaci√≥n como los yields presentan persistencia en sus shocks, manteniendo efectos durante varios periodos.\n",
    "\n",
    "El pron√≥stico VAR anticipa un repunte moderado en ambas variables, con algo m√°s de volatilidad en la inflaci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis VAR: Diagn√≥stico y Extensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Ljung‚ÄìBox por variable (univariante)\n",
    "for col in var_res.resid.columns:\n",
    "    print(f\"\\nLjung‚ÄìBox (lags=10) para {col}\")\n",
    "    print(acorr_ljungbox(var_res.resid[col].dropna(), lags=[10], return_df=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Durbin‚ÄìWatson (otra medida de autocorrelaci√≥n)\n",
    "dw = durbin_watson(var_res.resid.values)\n",
    "for col, val in zip(var_res.resid.columns, dw):\n",
    "    print(f\"Durbin‚ÄìWatson {col}: {val:.2f}\")  # ~2 es bueno (sin autocorrelaci√≥n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Estabilidad del VAR\n",
    "var_res.is_stable(verbose=True)  # Debe devolver True / ra√≠ces dentro del c√≠rculo unitario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Heterocedasticidad (ARCH) por variable\n",
    "for col in var_res.resid.columns:\n",
    "    stat, pval, _, _ = het_arch(var_res.resid[col].dropna())\n",
    "    print(f\"ARCH para {col}: p-value = {pval:.4f}\")  # >= 0.05 ‚áí OK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Normalidad conjunta de residuos\n",
    "norm = var_res.test_normality()\n",
    "print(norm.summary())  # p-value alto ‚áí OK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in var_res.resid.columns:\n",
    "    plt.figure(); plot_acf(var_res.resid[col].dropna(), lags=20); plt.title(f\"ACF {col}\")\n",
    "    plt.figure(); plot_pacf(var_res.resid[col].dropna(), lags=20); plt.title(f\"PACF {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretaci√≥n de los resultados (Punto 3.1)\n",
    "\n",
    "En los gr√°ficos de ACF y PACF:\n",
    "\n",
    "La mayor√≠a de las barras caen dentro de la banda azul (intervalo de confianza).\n",
    "\n",
    "Eso significa que no hay autocorrelaci√≥n significativa en los residuos.\n",
    "\n",
    "Un modelo VAR bien especificado debe dejar los residuos como ‚Äúruido blanco‚Äù, y eso es lo que se ve aqu√≠."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Test de autocorrelaci√≥n alternativa (Durbin‚ÄìWatson)\n",
    "\n",
    "El estad√≠stico Durbin‚ÄìWatson verifica la autocorrelaci√≥n de primer orden.  \n",
    "- Valor cercano a **2** ‚áí sin autocorrelaci√≥n.  \n",
    "- Valor < 2 ‚áí autocorrelaci√≥n positiva.  \n",
    "- Valor > 2 ‚áí autocorrelaci√≥n negativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = durbin_watson(var_res.resid.values)\n",
    "for col, val in zip(var_res.resid.columns, dw):\n",
    "    print(f\"Durbin‚ÄìWatson {col}: {val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Test de estabilidad del VAR\n",
    "\n",
    "Un VAR estable tiene todas sus ra√≠ces dentro del c√≠rculo unitario.  \n",
    "Si es **True**, los pron√≥sticos son fiables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_res.is_stable(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Test de heterocedasticidad (ARCH)\n",
    "\n",
    "El test ARCH eval√∫a si la varianza de los residuos es constante.  \n",
    "- **p-value ‚â• 0.05** ‚áí no hay heterocedasticidad (bien).  \n",
    "- **p-value < 0.05** ‚áí problemas de heterocedasticidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in var_res.resid.columns:\n",
    "    stat, pval, _, _ = het_arch(var_res.resid[col].dropna())\n",
    "    print(f\"ARCH {col}: p-value = {pval:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Test de normalidad de residuos\n",
    "\n",
    "El test de Jarque‚ÄìBera verifica si los residuos siguen una distribuci√≥n normal.  \n",
    "- **p-value ‚â• 0.05** ‚áí no rechazamos normalidad (OK).  \n",
    "- **p-value < 0.05** ‚áí residuos no normales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = var_res.test_normality()\n",
    "print(norm.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pron√≥stico extendido con intervalos de confianza\n",
    "\n",
    "El objetivo es proyectar las series `yield_10y` e `inflation_yoy` varios pasos hacia adelante.\n",
    "Mostramos tanto las predicciones puntuales como las bandas de confianza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 4. Pron√≥stico extendido con intervalos de confianza (VARResults) ====\n",
    "steps = 10  # a√±os a proyectar\n",
    "last_year = int(df_clean[\"Year\"].max())\n",
    "\n",
    "# n¬∫ de rezagos que us√≥ el VAR\n",
    "k = var_res.k_ar\n",
    "\n",
    "# Pron√≥stico: medias y bandas (lower/upper)\n",
    "fcast_mean, fcast_lower, fcast_upper = var_res.forecast_interval(\n",
    "    y=var_res.endog[-k:],  # las √∫ltimas k observaciones como estado inicial\n",
    "    steps=steps,\n",
    "    alpha=0.05             # 95% IC\n",
    ")\n",
    "\n",
    "cols = var_res.names  # ['yield_10y','inflation_yoy']\n",
    "\n",
    "# DataFrames ordenados con √≠ndice de a√±os futuros\n",
    "idx_future = range(last_year+1, last_year+steps+1)\n",
    "f_mean  = pd.DataFrame(fcast_mean,  index=idx_future, columns=cols)\n",
    "f_lower = pd.DataFrame(fcast_lower, index=idx_future, columns=cols)\n",
    "f_upper = pd.DataFrame(fcast_upper, index=idx_future, columns=cols)\n",
    "\n",
    "print(\"\\n--- Pron√≥stico extendido (medias) ---\")\n",
    "print(f_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gr√°fico hist√≥rico + forecast con bandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for col in cols:\n",
    "    # hist√≥rico\n",
    "    plt.plot(df_clean[\"Year\"], df_clean[col], label=f\"{col} (hist√≥rico)\")\n",
    "    # predicci√≥n\n",
    "    plt.plot(f_mean.index, f_mean[col], linestyle=\"--\", label=f\"{col} (forecast)\")\n",
    "    # intervalos\n",
    "    plt.fill_between(f_mean.index, f_lower[col], f_upper[col], alpha=0.2)\n",
    "\n",
    "plt.axvline(x=last_year, color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "plt.title(\"Pron√≥stico extendido VAR con intervalos de confianza (95%)\")\n",
    "plt.xlabel(\"A√±o\"); plt.ylabel(\"%\"); plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretaci√≥n r√°pida:\n",
    "\n",
    "Se observa que el yield_10y tender√≠a a estabilizarse, mientras que la inflaci√≥n muestra un ligero descenso en el forecast, aunque con bastante incertidumbre (bandas amplias).\n",
    "\n",
    "Esto refleja la l√≥gica: el modelo VAR capta relaciones, pero a largo plazo las predicciones son menos seguras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descomposici√≥n de varianza del error de pron√≥stico (FEVD)\n",
    "\n",
    "Mide qu√© porcentaje del error de predicci√≥n de cada variable se explica por shocks propios y por la otra variable, a distintos horizontes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10  # horizonte FEVD\n",
    "fevd = var_res.fevd(steps)\n",
    "\n",
    "# Resumen en texto\n",
    "print(fevd.summary())\n",
    "\n",
    "# Gr√°fico por variable\n",
    "_ = fevd.plot(figsize=(10,6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Causalidad de Granger\n",
    "\n",
    "Contrasta si los rezagos de una variable ayudan a predecir a la otra (m√°s all√° de sus propios rezagos).\n",
    "- p-value < 0.05 ‚áí Rechazamos ‚Äúno causa‚Äù ‚áí hay causalidad de Granger en esa direcci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¬øInflation_yoy causa (Granger) a yield_10y?\n",
    "print(var_res.test_causality('yield_10y', ['inflation_yoy'], kind='f').summary())\n",
    "\n",
    "# ¬øYield_10y causa (Granger) a inflation_yoy?\n",
    "print(var_res.test_causality('inflation_yoy', ['yield_10y'], kind='f').summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Funciones de Impulso-Respuesta (IRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 IRF ortogonalizadas (Cholesky) con bandas de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizonte (a√±os)\n",
    "h = 10\n",
    "\n",
    "# IRF b√°sicas\n",
    "irf = var_res.irf(h)\n",
    "\n",
    "# Gr√°fico de IRF ortogonalizadas (Cholesky)\n",
    "fig = irf.plot(orth=True)\n",
    "fig.suptitle(\"IRF ortogonalizadas (Cholesky)\", fontsize=14)\n",
    "\n",
    "# Bandas de confianza por bootstrap Monte Carlo\n",
    "# (repl=1000 si quieres m√°s precisi√≥n; tardar√° m√°s)\n",
    "fig_ci = irf.errband_mc(orth=True, repl=500)  # devuelve fig y ejes con bandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 IRF acumuladas (efecto total a lo largo del horizonte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cum = irf.plot_cum_effects(orth=True)\n",
    "fig_cum.suptitle(\"IRF acumuladas (orth)\", fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Sensibilidad al orden de las variables\n",
    "Cambiar el orden es buena pr√°ctica de robustez: primero inflaci√≥n, luego yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-ajustamos el VAR con columnas reordenadas\n",
    "df_alt = df_clean[[\"inflation_yoy\", \"yield_10y\"]].dropna().copy()\n",
    "model_alt = VAR(df_alt)\n",
    "var_res_alt = model_alt.fit(var_res.k_ar)  # usa el mismo n¬∫ de rezagos\n",
    "\n",
    "irf_alt = var_res_alt.irf(h)\n",
    "fig_alt = irf_alt.plot(orth=True)\n",
    "fig_alt.suptitle(\"IRF orth con orden alternativo (inflaci√≥n primero)\", fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Guardar figuras a disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"irf_orth.png\", dpi=150, bbox_inches=\"tight\")\n",
    "fig_cum.savefig(\"irf_cum_orth.png\", dpi=150, bbox_inches=\"tight\")\n",
    "fig_alt.savefig(\"irf_orth_alt_order.png\", dpi=150, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Interpretaci√≥n Punto 7 (IRFs)\n",
    "\n",
    "Shock inflaci√≥n ‚Üí Yield 10Y: impacto fuerte y sostenido, los bonos suben porque el mercado exige m√°s rentabilidad.\n",
    "\n",
    "Shock Yield 10Y ‚Üí Inflaci√≥n: efecto d√©bil y pasajero, incluso negativo (tipos altos enfr√≠an la econom√≠a).\n",
    "\n",
    "Inflaci√≥n sobre s√≠ misma: persistente, pero va perdiendo fuerza.\n",
    "\n",
    "Yield sobre s√≠ mismo: se corrige r√°pido.\n",
    "\n",
    "IRFs acumuladas: confirman que la inflaci√≥n arrastra a los yields, no al rev√©s.\n",
    "\n",
    "Sensibilidad al orden: los resultados son robustos, no dependen del orden de variables.\n",
    "\n",
    "üìå Conclusi√≥n clara:\n",
    "La inflaci√≥n lidera y los yields siguen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparar el dataset USA para el pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa = (\n",
    "    df_clean[['Year', 'yield_10y', 'inflation_yoy']]\n",
    "      .dropna()\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "df_usa['Year'] = df_usa['Year'].astype(int)\n",
    "df_usa = df_usa.set_index('Year').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define el pipeline (elige rezagos autom√°ticamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_country_pipeline_auto(df, country_name, steps=10, maxlags=8, crit=\"aic\"):\n",
    "    \"\"\"\n",
    "    Pipeline VAR completo con selecci√≥n autom√°tica de rezagos.\n",
    "    df: DataFrame con index=Year y columnas ['yield_10y','inflation_yoy']\n",
    "    steps: horizonte de forecast\n",
    "    maxlags: rezago m√°ximo a evaluar\n",
    "    crit: 'aic' | 'bic' | 'hqic' | 'fpe'\n",
    "    \"\"\"\n",
    "    df = df[['yield_10y','inflation_yoy']].dropna().copy()\n",
    "    model = VAR(df)\n",
    "\n",
    "    # 1) Selecci√≥n de rezagos\n",
    "    sel = model.select_order(maxlags=maxlags)\n",
    "    best_lag = getattr(sel, crit)\n",
    "    print(f\"\\n[{country_name}] Rezagos √≥ptimos por {crit.upper()}: {best_lag}\")\n",
    "\n",
    "    # 2) Ajuste\n",
    "    res = model.fit(best_lag)\n",
    "    print(res.summary())\n",
    "\n",
    "    # 3) Diagn√≥stico (r√°pido)\n",
    "    print(\"\\n--- Diagn√≥stico ---\")\n",
    "    for col in res.resid.columns:\n",
    "        lb = acorr_ljungbox(res.resid[col].dropna(), lags=[10], return_df=True)\n",
    "        print(f\"Ljung-Box {col} (lag=10): p-value={lb['lb_pvalue'].iloc[0]:.4f}\")\n",
    "    dw = durbin_watson(res.resid.values)\n",
    "    for c,v in zip(res.resid.columns, dw):\n",
    "        print(f\"Durbin‚ÄìWatson {c}: {v:.2f}\")\n",
    "    print(\"Estabilidad:\", res.is_stable(verbose=True))\n",
    "\n",
    "    # 4) Forecast con bandas\n",
    "    k = res.k_ar\n",
    "    mean, low, up = res.forecast_interval(res.endog[-k:], steps=steps, alpha=0.05)\n",
    "    idx_future = range(df.index.max()+1, df.index.max()+1+steps)\n",
    "    f_mean = pd.DataFrame(mean, index=idx_future, columns=res.names)\n",
    "    f_low  = pd.DataFrame(low,  index=idx_future, columns=res.names)\n",
    "    f_up   = pd.DataFrame(up,   index=idx_future, columns=res.names)\n",
    "\n",
    "    plt.figure(figsize=(11,5))\n",
    "    for col in res.names:\n",
    "        plt.plot(df.index, df[col], label=f\"{col} (hist.)\")\n",
    "        plt.plot(f_mean.index, f_mean[col], \"--\", label=f\"{col} (fcst)\")\n",
    "        plt.fill_between(f_mean.index, f_low[col], f_up[col], alpha=0.2)\n",
    "    plt.axvline(df.index.max(), color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.title(f\"{country_name} ‚Äì Forecast VAR (95% IC)\")\n",
    "    plt.xlabel(\"A√±o\"); plt.ylabel(\"%\"); plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # 5) FEVD\n",
    "    fevd = res.fevd(steps)\n",
    "    print(\"\\n--- FEVD ---\")\n",
    "    print(fevd.summary())\n",
    "    fevd.plot(figsize=(9,5)); plt.show()\n",
    "\n",
    "    # 6) Granger\n",
    "    print(\"\\n--- Granger ---\")\n",
    "    print(res.test_causality('yield_10y',['inflation_yoy'], kind='f').summary())\n",
    "    print(res.test_causality('inflation_yoy',['yield_10y'], kind='f').summary())\n",
    "\n",
    "    # 7) IRFs (orth y acumuladas)\n",
    "    irf = res.irf(steps)\n",
    "    irf.plot(orth=True); plt.suptitle(f\"{country_name} ‚Äì IRF orth\"); plt.show()\n",
    "    irf.plot_cum_effects(orth=True); plt.suptitle(f\"{country_name} ‚Äì IRF acumuladas\"); plt.show()\n",
    "\n",
    "    return res, {\"forecast_mean\": f_mean, \"forecast_low\": f_low, \"forecast_up\": f_up}, fevd, irf, best_lag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecutar el pipeline para USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_results, usa_fcst, usa_fevd, usa_irf, usa_bestlag = run_country_pipeline_auto(\n",
    "    df_usa, country_name=\"USA\", steps=10, maxlags=8, crit=\"aic\"\n",
    ")\n",
    "print(\"Lag elegido (AIC):\", usa_bestlag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectar la columna 10Y de Alemania en yields.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar si no esta ya en memoria:\n",
    "yields = pd.read_csv(YIELDS_CSV)\n",
    "\n",
    "# columnas 10Y tipo 'US10', 'DE10', etc.\n",
    "ten_cols = [c for c in yields.columns if re.fullmatch(r\"[A-Z]{2}\\d{2}\", c) and c.endswith(\"10\")]\n",
    "print(\"10Y detectadas (primeras 30):\", ten_cols[:30])\n",
    "\n",
    "# Intento autom√°tico para Alemania\n",
    "candidatos_de = [c for c in ten_cols if c.startswith((\"DE\",\"GE\",\"BD\",\"GM\"))]\n",
    "print(\"Candidatos Alemania:\", candidatos_de)\n",
    "\n",
    "# Si aparece 'DE10', √∫sala; si no, toma el primer candidato que salga.\n",
    "col_de = \"DE10\" if \"DE10\" in ten_cols else (candidatos_de[0] if candidatos_de else None)\n",
    "print(\"Columna usada para Alemania 10Y:\", col_de)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anualizar yields USA + Alemania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields_yr = yields.copy()\n",
    "yields_yr['Year'] = pd.to_datetime(yields_yr['time'], unit='ms').dt.year\n",
    "\n",
    "col_us = \"US10\"   # USA 10Y\n",
    "col_de = \"DE10\"   # Alemania 10Y\n",
    "\n",
    "y_ann = (\n",
    "    yields_yr[['Year', col_us, col_de]]\n",
    "      .groupby('Year', as_index=False)\n",
    "      .mean()\n",
    "      .rename(columns={col_us:'yield_10y_US', col_de:'yield_10y_DE'})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflaci√≥n del Banco Mundial (USA + Alemania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = pd.read_csv(WORLD_BANK_DATA)\n",
    "\n",
    "wb_small = wb.rename(columns={\n",
    "    'country_name':'Country',\n",
    "    'year':'Year',\n",
    "    'Inflation (CPI %)':'inflation_yoy'\n",
    "})[['Country','Year','inflation_yoy']].dropna()\n",
    "\n",
    "infl_us = wb_small.query(\"Country == 'United States'\")[['Year','inflation_yoy']].rename(columns={'inflation_yoy':'inflation_yoy_US'})\n",
    "infl_de = wb_small.query(\"Country == 'Germany'\")[['Year','inflation_yoy']].rename(columns={'inflation_yoy':'inflation_yoy_DE'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir datasets y lanzar el pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga el CSV de Alemania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) Cargar CSV Alemania desde FRED ===\n",
    "de_raw = pd.read_csv(IRLTLT)\n",
    "\n",
    "# Normalizar columnas\n",
    "de_raw['observation_date'] = pd.to_datetime(de_raw['observation_date'], errors='coerce')\n",
    "de_raw = de_raw.rename(columns={'IRLTLT01DEM156N':'yield_10y'})\n",
    "\n",
    "# === 2) Pasar de mensual ‚Üí anual (promedio) ===\n",
    "de_annual = de_raw.set_index('observation_date').resample('YE').mean()\n",
    "de_annual.index = de_annual.index.year\n",
    "de_annual.index.name = 'Year'\n",
    "de_annual = de_annual.reset_index()\n",
    "\n",
    "print(\"Alemania yields anuales:\", de_annual['Year'].min(), \"‚Üí\", de_annual['Year'].max())\n",
    "display(de_annual.head())\n",
    "\n",
    "# === 3) Inflaci√≥n Alemania desde World Bank ===\n",
    "wb_small = wb.rename(columns={\n",
    "    'country_name':'Country',\n",
    "    'year':'Year',\n",
    "    'Inflation (CPI %)':'inflation_yoy'\n",
    "})[['Country','Year','inflation_yoy']].dropna()\n",
    "\n",
    "infl_de = wb_small.query(\"Country == 'Germany'\")[['Year','inflation_yoy']]\n",
    "\n",
    "# === 4) Merge yields + inflaci√≥n ===\n",
    "df_germany = (\n",
    "    de_annual.merge(infl_de, on='Year', how='inner')\n",
    "             .set_index('Year').sort_index()\n",
    ")\n",
    "\n",
    "print(\"Alemania combinado:\", df_germany.index.min(), \"‚Üí\", df_germany.index.max())\n",
    "display(df_germany.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alemania: cortar a 2010‚Äì2024 y correr el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Alemania 2010‚Äì2024 ---\n",
    "df_germany_2010_24 = df_germany.loc[2010:2024].copy()\n",
    "\n",
    "N = len(df_germany_2010_24)\n",
    "safe_maxlags = max(1, min(3, (N - 3)//2))   # con ~15 a√±os suele salir 1‚Äì2\n",
    "print(f\"[Germany] N={N} | maxlags sugerido={safe_maxlags}\")\n",
    "\n",
    "de_res, de_fcst, de_fevd, de_irf, de_bestlag = run_country_pipeline_auto(\n",
    "    df_germany_2010_24, country_name=\"Germany (2010‚Äì2024)\",\n",
    "    steps=10, maxlags=safe_maxlags, crit=\"aic\"\n",
    ")\n",
    "print(\"Germany (2010‚Äì2024) ‚Äì lag elegido:\", de_bestlag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA: mismo corte 2010‚Äì2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_country_pipeline_auto(df, country_name, steps=5, maxlags=2, crit=\"aic\"):\n",
    "    \"\"\"\n",
    "    df: index=Year (int), columnas ['yield_10y','inflation_yoy']\n",
    "    steps: horizonte de forecast\n",
    "    maxlags: rezago m√°ximo permitido (luego se capea autom√°ticamente)\n",
    "    \"\"\"\n",
    "    # 0) Formato y limpieza\n",
    "    df = df[['yield_10y','inflation_yoy']].dropna().copy()\n",
    "    df.index = df.index.astype(int)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # 1) C√°lculo de un maxlags seguro seg√∫n n¬∫ de observaciones\n",
    "    N = len(df)\n",
    "    k_endog = df.shape[1]  # 2\n",
    "    safe_max = max(1, min(maxlags, (N - 5)//k_endog))  # cap defensivo\n",
    "    if safe_max < 1:\n",
    "        raise ValueError(f\"Datos insuficientes (N={N}). Reduce rango de a√±os o a√±ade datos.\")\n",
    "    if safe_max < maxlags:\n",
    "        print(f\"[{country_name}] maxlags reducido de {maxlags} a {safe_max} por N={N}\")\n",
    "\n",
    "    # 2) Selecci√≥n de rezagos y ajuste\n",
    "    model = VAR(df)\n",
    "    sel = model.select_order(maxlags=safe_max)\n",
    "    best_lag = getattr(sel, crit)\n",
    "    if best_lag is None or best_lag < 1:\n",
    "        best_lag = min(1, safe_max)\n",
    "    print(f\"\\n[{country_name}] Rezagos √≥ptimos por {crit.upper()}: {best_lag}\")\n",
    "    res = model.fit(best_lag)\n",
    "    print(res.summary())\n",
    "\n",
    "    # 3) Diagn√≥stico robusto (Ljung‚ÄìBox con lag seguro)\n",
    "    print(\"\\n--- Diagn√≥stico ---\")\n",
    "    nres = len(res.resid)\n",
    "    lb_lag = max(1, min(10, nres - 2, 2*best_lag))  # evita el error por tama√±os\n",
    "    for col in res.resid.columns:\n",
    "        if lb_lag >= 1:\n",
    "            lb = acorr_ljungbox(res.resid[col].dropna(), lags=[lb_lag], return_df=True)\n",
    "            print(f\"Ljung-Box {col} (lag={lb_lag}): p={lb['lb_pvalue'].iloc[0]:.4f}\")\n",
    "        else:\n",
    "            print(f\"Ljung-Box {col}: saltado (muy pocas observaciones)\")\n",
    "    dw = durbin_watson(res.resid.values)\n",
    "    for c, v in zip(res.resid.columns, dw):\n",
    "        print(f\"Durbin‚ÄìWatson {c}: {v:.2f}\")\n",
    "    print(\"Estabilidad:\", res.is_stable(verbose=True))\n",
    "\n",
    "    # 4) Forecast con bandas (95%)\n",
    "    k = res.k_ar\n",
    "    mean, low, up = res.forecast_interval(res.endog[-k:], steps=steps, alpha=0.05)\n",
    "    idx_future = range(df.index.max()+1, df.index.max()+1+steps)\n",
    "    f_mean = pd.DataFrame(mean, index=idx_future, columns=res.names)\n",
    "    f_low  = pd.DataFrame(low,  index=idx_future, columns=res.names)\n",
    "    f_up   = pd.DataFrame(up,   index=idx_future, columns=res.names)\n",
    "\n",
    "    plt.figure(figsize=(11,5))\n",
    "    for col in res.names:\n",
    "        plt.plot(df.index, df[col], label=f\"{col} (hist.)\")\n",
    "        plt.plot(f_mean.index, f_mean[col], \"--\", label=f\"{col} (fcst)\")\n",
    "        plt.fill_between(f_mean.index, f_low[col], f_up[col], alpha=0.2)\n",
    "    plt.axvline(df.index.max(), color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.title(f\"{country_name} ‚Äì Forecast VAR (95% IC)\")\n",
    "    plt.xlabel(\"A√±o\"); plt.ylabel(\"%\"); plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # 5) FEVD\n",
    "    fevd = res.fevd(steps)\n",
    "    print(\"\\n--- FEVD ---\")\n",
    "    print(fevd.summary())\n",
    "    fevd.plot(figsize=(9,5)); plt.show()\n",
    "\n",
    "    # 6) Causalidad de Granger\n",
    "    print(\"\\n--- Granger ---\")\n",
    "    print(res.test_causality('yield_10y', ['inflation_yoy'], kind='f').summary())\n",
    "    print(res.test_causality('inflation_yoy', ['yield_10y'], kind='f').summary())\n",
    "\n",
    "    # 7) IRFs (orth y acumuladas)\n",
    "    irf = res.irf(steps)\n",
    "    irf.plot(orth=True); plt.suptitle(f\"{country_name} ‚Äì IRF orth\"); plt.show()\n",
    "    irf.plot_cum_effects(orth=True); plt.suptitle(f\"{country_name} ‚Äì IRF acumuladas\"); plt.show()\n",
    "\n",
    "    return res, {\"forecast_mean\": f_mean, \"forecast_low\": f_low, \"forecast_up\": f_up}, fevd, irf, best_lag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa_2010_24     = df_usa.loc[2010:2024].copy()\n",
    "df_germany_2010_24 = df_germany.loc[2010:2024].copy()\n",
    "\n",
    "print(\"USA 2010‚Äì2024:\", df_usa_2010_24.index.min(), \"‚Üí\", df_usa_2010_24.index.max(), \"| N=\", len(df_usa_2010_24))\n",
    "print(\"DE  2010‚Äì2024:\", df_germany_2010_24.index.min(), \"‚Üí\", df_germany_2010_24.index.max(), \"| N=\", len(df_germany_2010_24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA\n",
    "us_res, us_fcst, us_fevd, us_irf, us_bestlag = run_country_pipeline_auto(\n",
    "    df_usa_2010_24, country_name=\"USA (2010‚Äì2024)\", steps=5, maxlags=2, crit=\"aic\"\n",
    ")\n",
    "print(\"USA (2010‚Äì2024) ‚Äì lag elegido:\", us_bestlag)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert {'yield_10y','inflation_yoy'}.issubset(df_usa.columns), \"df_usa no tiene las columnas correctas\"\n",
    "df_usa_2010_24 = df_usa.loc[2010:2024].copy()\n",
    "print(\"Rango USA recortado:\", df_usa_2010_24.index.min(), \"‚Üí\", df_usa_2010_24.index.max(), \"| N=\", len(df_usa_2010_24))\n",
    "print(df_usa_2010_24.head(), \"\\n\", df_usa_2010_24.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A√±os disponibles en cada fuente (USA)\n",
    "print(\"Yields USA (y_ann):\", y_ann[['Year','yield_10y_US']].dropna()['Year'].min(), \"‚Üí\", y_ann[['Year','yield_10y_US']].dropna()['Year'].max())\n",
    "print(\"Inflaci√≥n USA (infl_us):\", infl_us['Year'].min(), \"‚Üí\", infl_us['Year'].max())\n",
    "\n",
    "# Qu√© a√±os faltan en cada una dentro de 2010‚Äì2024\n",
    "yrs = set(range(2010, 2025))\n",
    "y_ok  = set(y_ann.loc[y_ann['yield_10y_US'].notna(), 'Year'])\n",
    "i_ok  = set(infl_us['Year'])\n",
    "print(\"Faltan en yields:\", sorted(yrs - y_ok))\n",
    "print(\"Faltan en inflaci√≥n:\", sorted(yrs - i_ok))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anualizar DGS10 y crear Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar CSV DGS10 (tiene columnas: observation_date, DGS10)\n",
    "dgs = pd.read_csv(DGS10)\n",
    "\n",
    "# Limpiar tipos\n",
    "dgs[\"observation_date\"] = pd.to_datetime(dgs[\"observation_date\"], errors=\"coerce\")\n",
    "dgs[\"DGS10\"] = pd.to_numeric(dgs[\"DGS10\"], errors=\"coerce\")\n",
    "dgs = dgs.dropna(subset=[\"observation_date\", \"DGS10\"]).sort_values(\"observation_date\")\n",
    "\n",
    "# Resample anual (promedio) y crear Year de forma expl√≠cita\n",
    "dgs_ann = (\n",
    "    dgs.set_index(\"observation_date\")\n",
    "       .resample(\"YE\").mean()                  # promedio anual\n",
    "       .assign(Year=lambda x: x.index.year)    # crear Year desde el √≠ndice\n",
    "       .reset_index(drop=True)[[\"Year\", \"DGS10\"]]\n",
    "       .rename(columns={\"DGS10\": \"yield_10y\"})\n",
    ")\n",
    "\n",
    "# Filtrar 2021‚Äì2024 (o lo que tengas)\n",
    "dgs_ann = dgs_ann.query(\"Year >= 2021\").copy()\n",
    "\n",
    "print(dgs_ann.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unir con tu serie USA previa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalcular US10 anual (hasta 2020) desde tu yields.csv\n",
    "yields_yr = yields.copy()\n",
    "yields_yr['Year'] = pd.to_datetime(yields_yr['time'], unit='ms').dt.year\n",
    "\n",
    "us10_ann_old = (\n",
    "    yields_yr.groupby('Year')['US10'].mean()\n",
    "             .rename('yield_10y')\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "print(\"US10 anualizado (hasta 2020):\")\n",
    "print(us10_ann_old.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us10_ann_old: tu serie hist√≥rica hasta 2020 (Year, yield_10y)\n",
    "us10_full = (\n",
    "    pd.concat([us10_ann_old, dgs_ann], ignore_index=True)\n",
    "      .sort_values(\"Year\")\n",
    "      .drop_duplicates(\"Year\", keep=\"last\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(us10_full.tail(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir df_usa_2010_24 para el VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aseg√∫rate de tener infl_us: (Year, inflation_yoy)\n",
    "df_usa_2010_24 = (\n",
    "    us10_full.merge(infl_us, on=\"Year\", how=\"inner\")\n",
    "             .query(\"Year >= 2010 and Year <= 2024\")\n",
    "             .set_index(\"Year\")\n",
    "             .sort_index()\n",
    "             .dropna()\n",
    ")\n",
    "\n",
    "print(df_usa_2010_24.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA (2015‚Äì2024) ‚Äì VAR robusto con cap autom√°tico de lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa tu DataFrame ya preparado (√≠ndice Year, cols: yield_10y, inflation_yoy[_US])\n",
    "df_us = df_usa_2015_24.copy() if 'df_usa_2015_24' in globals() else df_usa_2010_24.loc[2015:2024].copy()\n",
    "if 'inflation_yoy_US' in df_us.columns:\n",
    "    df_us = df_us.rename(columns={'inflation_yoy_US':'inflation_yoy'})\n",
    "df_us = df_us[['yield_10y','inflation_yoy']].dropna().sort_index()\n",
    "df_us.index = df_us.index.astype(int)\n",
    "\n",
    "N, k = len(df_us), 2\n",
    "print(f\"[USA 2015‚Äì2024] N={N}\")\n",
    "\n",
    "# --- Selecci√≥n de rezagos robusta ---\n",
    "# Cap muy prudente con muestras cortas:\n",
    "max_try = max(1, min(2, (N-5)//k))  # con N~10 esto da 1‚Äì2\n",
    "best_lag = None\n",
    "last_err = None\n",
    "\n",
    "for p_cap in [max_try, 1]:  # probamos con el cap calculado y, si falla, con 1\n",
    "    try:\n",
    "        sel = VAR(df_us).select_order(maxlags=p_cap)\n",
    "        cand = getattr(sel, 'aic') or 1\n",
    "        cand = int(cand) if cand is not None else 1\n",
    "        cand = max(1, min(cand, p_cap))\n",
    "        res  = VAR(df_us).fit(cand)\n",
    "        best_lag = cand\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "        continue\n",
    "\n",
    "if best_lag is None:\n",
    "    raise last_err\n",
    "\n",
    "print(f\"Rezago √≥ptimo (AIC, cap={p_cap}): {best_lag}\")\n",
    "print(res.summary())\n",
    "\n",
    "# --- Diagn√≥stico robusto ---\n",
    "lb_lag = max(1, min(5, N - 2, 2*best_lag))\n",
    "print(\"\\n--- Diagn√≥stico ---\")\n",
    "for col in res.resid.columns:\n",
    "    lb = acorr_ljungbox(res.resid[col].dropna(), lags=[lb_lag], return_df=True)\n",
    "    print(f\"Ljung-Box {col} (lag={lb_lag})  p={lb['lb_pvalue'].iloc[0]:.3f}\")\n",
    "dw_vals = durbin_watson(res.resid.values)\n",
    "print(\"Durbin‚ÄìWatson:\", {c: round(dw,2) for c, dw in zip(res.resid.columns, dw_vals)})\n",
    "print(\"Estabilidad:\", res.is_stable(verbose=True))\n",
    "\n",
    "# --- Forecast (5 a√±os, sin IC para N peque√±o) ---\n",
    "steps = 5\n",
    "yhat = res.forecast(df_us.values[-best_lag:], steps=steps)\n",
    "years_fc = np.arange(df_us.index.max()+1, df_us.index.max()+steps+1)\n",
    "fc_df = pd.DataFrame(yhat, columns=df_us.columns, index=years_fc)\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.plot(df_us.index, df_us['yield_10y'], label='yield_10y (hist)')\n",
    "plt.plot(df_us.index, df_us['inflation_yoy'], label='inflation_yoy (hist)')\n",
    "plt.plot(fc_df.index, fc_df['yield_10y'], '--', label='yield_10y (fcst)')\n",
    "plt.plot(fc_df.index, fc_df['inflation_yoy'], '--', label='inflation_yoy (fcst)')\n",
    "plt.axvline(x=df_us.index.max(), color='grey', ls='--', alpha=0.6)\n",
    "plt.title('USA (2015‚Äì2024) ‚Äì VAR forecast (5 a√±os)')\n",
    "plt.xlabel('A√±o'); plt.ylabel('%'); plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- FEVD e IRFs (10 pasos) ---\n",
    "fevd = res.fevd(10); fig = fevd.plot(figsize=(10,6)); fig.suptitle('USA ‚Äì FEVD (10)'); plt.show()\n",
    "irf = res.irf(10); fig1 = irf.plot(orth=True); fig1.suptitle('USA ‚Äì IRF (orth)'); plt.show()\n",
    "fig2 = irf.plot_cum_effects(orth=True); fig2.suptitle('USA ‚Äì IRF acumuladas (orth)'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparativa Alemania vs USA (2010‚Äì2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üá©üá™ Alemania\n",
    "\n",
    "Yields 10Y: en m√≠nimos hist√≥ricos, incluso negativos 2016‚Äì2020.\n",
    "\n",
    "Inflaci√≥n: fuerte repunte desde 2021 por crisis energ√©tica y guerra en Ucrania.\n",
    "\n",
    "Relaci√≥n: shocks de inflaci√≥n ‚Üí suben los yields (mercado exige m√°s rentabilidad).\n",
    "\n",
    "#### üá∫üá∏ Estados Unidos\n",
    "\n",
    "Yields 10Y: bajan fuerte en 2020 (COVID), suben r√°pido hasta 2024.\n",
    "\n",
    "Inflaci√≥n: pico hist√≥rico en 2022 (8%) tras pandemia y energ√≠a.\n",
    "\n",
    "Relaci√≥n: inflaci√≥n explica gran parte de la variabilidad de yields; modelo algo inestable por pocos datos.\n",
    "\n",
    "#### üîé Conclusi√≥n\n",
    "\n",
    "Inflaci√≥n lidera, yields siguen en ambos pa√≠ses.\n",
    "\n",
    "Alemania vivi√≥ rendimientos negativos (BCE muy expansiva), USA nunca baj√≥ de 0.8% (Fed menos agresiva).\n",
    "\n",
    "Dos respuestas distintas a choques globales, pero misma direcci√≥n: m√°s inflaci√≥n = yields m√°s altos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAIN (2010‚Äì2024) ‚Äì Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 0) Cargar fuentes si faltan ----------\n",
    "if 'yields' not in globals():\n",
    "    yields = pd.read_csv(YIELDS_CSV)\n",
    "if 'wb' not in globals():\n",
    "    wb = pd.read_csv(WORLD_BANK_DATA)\n",
    "\n",
    "# ---------- 1) Yields 10Y Espa√±a (ES10) ‚Üí anual ----------\n",
    "yields_yr = yields.copy()\n",
    "# 'time' suele ser epoch ms en tu fichero\n",
    "yields_yr['Year'] = pd.to_datetime(yields_yr['time'], unit='ms').dt.year\n",
    "\n",
    "if 'ES10' not in yields_yr.columns:\n",
    "    raise RuntimeError(\"No encuentro la columna ES10 en yields.csv\")\n",
    "\n",
    "es10_ann = (yields_yr.groupby('Year')['ES10'].mean()\n",
    "                        .rename('yield_10y')\n",
    "                        .reset_index())\n",
    "\n",
    "# ---------- 2) Inflaci√≥n Espa√±a desde World Bank (detecci√≥n robusta) ----------\n",
    "cols = {c.lower(): c for c in wb.columns}\n",
    "country_col = cols.get('country_name') or cols.get('country') or cols.get('country name')\n",
    "year_col    = cols.get('year') or cols.get('date')\n",
    "\n",
    "if not country_col or not year_col:\n",
    "    raise RuntimeError(\"No encuentro columnas de pa√≠s/a√±o en el archivo WB. Revisa nombres.\")\n",
    "\n",
    "inflation_candidates = [c for c in wb.columns if \"inflation\" in c.lower() and \"cpi\" in c.lower()]\n",
    "if not inflation_candidates:\n",
    "    raise RuntimeError(\"No encuentro columna de inflaci√≥n CPI en WB (busqu√© 'inflation' y 'CPI').\")\n",
    "infl_col = inflation_candidates[0]\n",
    "\n",
    "infl_es = (wb[[country_col, year_col, infl_col]]\n",
    "             .rename(columns={country_col:'Country', year_col:'Year', infl_col:'inflation_yoy'})\n",
    "             .query(\"Country == 'Spain'\")\n",
    "             [['Year','inflation_yoy']]\n",
    "             .dropna())\n",
    "\n",
    "# ---------- 3) Merge + recorte 2010‚Äì2024 ----------\n",
    "df_spain = (es10_ann.merge(infl_es, on='Year', how='inner')\n",
    "                    .set_index('Year').sort_index())\n",
    "df_spain_2010_24 = df_spain.loc[2010:2024].dropna().copy()\n",
    "\n",
    "print(\"Spain ‚Äì rango disponible tras merge:\",\n",
    "      df_spain_2010_24.index.min(), \"‚Üí\", df_spain_2010_24.index.max(),\n",
    "      \"| N =\", len(df_spain_2010_24))\n",
    "display(df_spain_2010_24.tail())\n",
    "\n",
    "# ---------- 4) Ejecutar VAR (par√°metros prudentes para N~10‚Äì15) ----------\n",
    "sp_res, sp_fcst, sp_fevd, sp_irf, sp_bestlag = run_country_pipeline_auto(\n",
    "    df_spain_2010_24, country_name=\"Spain (2010‚Äì2024)\", steps=5, maxlags=2, crit=\"aic\"\n",
    ")\n",
    "print(\"Spain (2010‚Äì2024) ‚Äì rezagos elegidos (AIC):\", sp_bestlag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yield_10y ‚Üí inflation_yoy (izquierda):\n",
    "\n",
    "Un shock positivo en los rendimientos de 10 a√±os genera un aumento inicial de la inflaci√≥n, que se estabiliza despu√©s de 3 a√±os.\n",
    "\n",
    "La respuesta es moderada y se disipa r√°pido.\n",
    "\n",
    "Eso sugiere que los tipos largos tienen poca capacidad de traspaso directo a la inflaci√≥n en Espa√±a en este periodo.\n",
    "\n",
    "inflation_yoy ‚Üí inflation_yoy (derecha):\n",
    "\n",
    "Un shock de inflaci√≥n tiende a persistir 2‚Äì3 a√±os, con efecto negativo moderado y luego recuperaci√≥n.\n",
    "\n",
    "En otras palabras, los shocks inflacionarios en Espa√±a no son totalmente transitorios, pero tampoco se vuelven explosivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üìå Conclusi√≥n r√°pida (Espa√±a 2010‚Äì2024):\n",
    "\n",
    "Los tipos largos no causan fuertemente la inflaci√≥n (apoyo a lo visto en Granger).\n",
    "\n",
    "La inflaci√≥n s√≠ muestra cierta din√°mica propia (persistencia).\n",
    "\n",
    "El sistema (VAR) es estable y razonablemente predecible en el corto plazo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reino Unido üá¨üáß"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Verificar columnas de yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yields.columns.tolist())\n",
    "print(yields.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si el √≠ndice ya es el a√±o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields = yields.reset_index().rename(columns={'index':'Year'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Reino Unido ===\n",
    "\n",
    "# 1) Rendimientos 10Y (UK)\n",
    "y_uk = (\n",
    "    yields[['Year','GB10']]\n",
    "    .rename(columns={'GB10':'yield_10y_UK'})\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "# 2) Inflaci√≥n UK\n",
    "infl_uk = (\n",
    "    wb_small.query(\"Country == 'United Kingdom'\")\n",
    "    [['Year','inflation_yoy']]\n",
    "    .rename(columns={'inflation_yoy':'inflation_yoy_UK'})\n",
    ")\n",
    "\n",
    "# 3) Merge\n",
    "df_uk = (\n",
    "    y_uk.merge(infl_uk, on='Year', how='inner')\n",
    "         .rename(columns={'yield_10y_UK':'yield_10y',\n",
    "                          'inflation_yoy_UK':'inflation_yoy'})\n",
    "         .set_index('Year').sort_index()\n",
    ")\n",
    "\n",
    "# Filtrar rango 2010‚Äì2024\n",
    "df_uk = df_uk.loc[2010:2024]\n",
    "\n",
    "print(\"UK rango disponible:\", df_uk.index.min(), \"‚Üí\", df_uk.index.max(), \"| N=\", len(df_uk))\n",
    "display(df_uk.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corre el VAR y genera gr√°ficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reino Unido: VAR 2010‚Äì2024 ---\n",
    "uk_res, uk_fcst, uk_fevd, uk_irf, uk_bestlag = run_country_pipeline_auto(\n",
    "    df_uk, country_name=\"UK (2010‚Äì2024)\", steps=5, maxlags=2, crit=\"aic\"\n",
    ")\n",
    "print(\"UK ‚Äì rezago elegido (AIC):\", uk_bestlag)\n",
    "\n",
    "# (opcional) guardar figuras si tu funci√≥n las pinta\n",
    "plt.savefig(\"uk_irf_orth.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reino Unido ‚Äì Resultados VAR (2010‚Äì2024)\n",
    "\n",
    "Datos disponibles:\n",
    "\n",
    "Rendimiento 10 a√±os (yield_10y_UK) y inflaci√≥n anual (inflation_yoy).\n",
    "\n",
    "Rango: 2010‚Äì2024 ‚Üí 15 observaciones.\n",
    "\n",
    "VAR estimado:\n",
    "\n",
    "Rezagos √≥ptimos: 2 (AIC).\n",
    "\n",
    "El sistema es estable (no explota).\n",
    "\n",
    "Forecast (2025‚Äì2029):\n",
    "\n",
    "Los rendimientos 10Y se mantienen estables en torno a 3.5‚Äì4%.\n",
    "\n",
    "La inflaci√≥n muestra tendencia moderada: repunte hacia ~3% pero con intervalos amplios (incertidumbre alta).\n",
    "\n",
    "Descomposici√≥n de varianza (FEVD):\n",
    "\n",
    "Los yields dependen principalmente de s√≠ mismos (>90%).\n",
    "\n",
    "La inflaci√≥n tambi√©n es mayormente explicada por s√≠ misma (>80‚Äì90%), con poca influencia de los rendimientos.\n",
    "\n",
    "Causalidad de Granger:\n",
    "\n",
    "No hay evidencia de causalidad significativa (p-valores > 0.1).\n",
    "\n",
    "Es decir: ni la inflaci√≥n predice claramente los rendimientos, ni al rev√©s.\n",
    "\n",
    "Respuestas a impulsos (IRF):\n",
    "\n",
    "Un shock en los rendimientos tiene efecto muy leve sobre inflaci√≥n (positivo al inicio, se disipa).\n",
    "\n",
    "Un shock en la inflaci√≥n apenas impacta los rendimientos, incluso con respuestas negativas peque√±as.\n",
    "\n",
    "#### Conclusi√≥n corta (UK):\n",
    "En Reino Unido, los rendimientos a 10 a√±os son bastante aut√≥nomos y siguen su propia din√°mica. La inflaci√≥n influye muy poco y no hay relaci√≥n causal fuerte entre ambas variables. El modelo proyecta estabilidad en yields y una inflaci√≥n moderada, aunque con mucha incertidumbre tras 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jap√≥n üáØüáµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Rendimientos 10Y (JP)\n",
    "y_jp = (\n",
    "    yields[['JP10']]\n",
    "    .rename(columns={'JP10':'yield_10y'})\n",
    "    .dropna()\n",
    ")\n",
    "y_jp.index.name = \"Year\"\n",
    "\n",
    "# 2) Inflaci√≥n Jap√≥n\n",
    "infl_jp = (\n",
    "    wb_small.query(\"Country == 'Japan'\")\n",
    "    [['Year','inflation_yoy']]\n",
    "    .set_index(\"Year\")\n",
    ")\n",
    "\n",
    "# 3) Merge de las dos series\n",
    "df_jp = (\n",
    "    y_jp.join(infl_jp, how=\"inner\")\n",
    "    .rename(columns={'inflation_yoy':'inflation_yoy'})\n",
    ")\n",
    "\n",
    "# 4) Recorte 2010‚Äì2024\n",
    "df_jp = df_jp.loc[2010:2024]\n",
    "\n",
    "print(\"JP rango disponible:\", df_jp.index.min(), \"-\", df_jp.index.max(), \"| N=\", len(df_jp))\n",
    "display(df_jp.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === JAP√ìN ‚Äì VAR completo y robusto (crea res_jp y hace forecast con bandas) ===\n",
    "# 0) Asegurar formato\n",
    "df_jp = df_jp[['yield_10y','inflation_yoy']].dropna().copy()\n",
    "df_jp.index = df_jp.index.astype(int)\n",
    "df_jp = df_jp.sort_index().loc[2010:2024]\n",
    "N = len(df_jp)\n",
    "print(f\"[JP] N={N} | a√±os {df_jp.index.min()}‚Äì{df_jp.index.max()}\")\n",
    "\n",
    "# 1) Selecci√≥n de rezagos robusta (cap descendente)\n",
    "model_jp = VAR(df_jp)\n",
    "safe_p = None\n",
    "for cap in [4,3,2,1]:\n",
    "    try:\n",
    "        sel = model_jp.select_order(cap)\n",
    "        p = sel.aic if sel.aic is not None else 1\n",
    "        p = int(max(1, min(p, cap)))\n",
    "        res_jp = model_jp.fit(p)\n",
    "        safe_p = p\n",
    "        print(f\"Rezago elegido (AIC dentro de cap={cap}): p={p}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"cap={cap} no estimable ‚Üí {e}\")\n",
    "\n",
    "if safe_p is None:\n",
    "    # √∫ltima red\n",
    "    safe_p = 1\n",
    "    res_jp = model_jp.fit(safe_p)\n",
    "    print(\"Forzado p=1\")\n",
    "\n",
    "print(res_jp.summary())\n",
    "print(\"Estabilidad VAR:\", res_jp.is_stable())\n",
    "\n",
    "# 2) Forecast con bandas (5 a√±os)\n",
    "steps = 5\n",
    "p = res_jp.k_ar\n",
    "last_Y = df_jp.values[-p:]                       # condiciones iniciales\n",
    "fc_mean, fc_lo, fc_hi = res_jp.forecast_interval(last_Y, steps=steps, alpha=0.05)\n",
    "\n",
    "start = int(df_jp.index.max()) + 1\n",
    "idx_fc = np.arange(start, start + steps)\n",
    "\n",
    "fc = pd.DataFrame(fc_mean, index=idx_fc, columns=df_jp.columns)\n",
    "lo = pd.DataFrame(fc_lo,   index=idx_fc, columns=df_jp.columns).add_suffix('_lo')\n",
    "hi = pd.DataFrame(fc_hi,   index=idx_fc, columns=df_jp.columns).add_suffix('_hi')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "df_jp[['yield_10y','inflation_yoy']].plot(ax=ax)\n",
    "ax.plot(fc.index, fc['yield_10y'], '--', label='yield_10y (fcst)')\n",
    "ax.fill_between(fc.index, lo['yield_10y_lo'], hi['yield_10y_hi'], alpha=0.2)\n",
    "ax.plot(fc.index, fc['inflation_yoy'], '--', label='inflation_yoy (fcst)')\n",
    "ax.fill_between(fc.index, lo['inflation_yoy_lo'], hi['inflation_yoy_hi'], alpha=0.2)\n",
    "ax.axvline(df_jp.index.max(), ls='--', color='gray', alpha=0.6)\n",
    "ax.set_title(f\"Jap√≥n (2010‚Äì{df_jp.index.max()}) ‚Äì VAR forecast ({steps} a√±os)\")\n",
    "ax.set_ylabel('%'); ax.grid(True); ax.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 3) FEVD, Granger e IRFs\n",
    "fevd = res_jp.fevd(10); print(fevd.summary()); fevd.plot(figsize=(9,5)); plt.show()\n",
    "print(res_jp.test_causality('yield_10y', ['inflation_yoy'], kind='f').summary())\n",
    "print(res_jp.test_causality('inflation_yoy', ['yield_10y'], kind='f').summary())\n",
    "irf = res_jp.irf(10); irf.plot(orth=True); plt.show(); irf.plot_cum_effects(orth=True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados clave\n",
    "\n",
    "Orden elegido (AIC): 4 ‚Üí El modelo usa hasta 4 rezagos para explicar la din√°mica.\n",
    "\n",
    "Estabilidad VAR: False ‚Üí üö® Esto significa que el sistema no cumple la condici√≥n de estabilidad (al menos una ra√≠z caracter√≠stica >1).\n",
    "En la pr√°ctica ‚Üí el forecast es v√°lido pero menos fiable, las bandas de error se disparan (como ves en la zona naranja).\n",
    "\n",
    "### Interpretaci√≥n del gr√°fico\n",
    "\n",
    "Yield 10 a√±os (l√≠nea azul)\n",
    "\n",
    "Hist√≥ricamente muy estable (alrededor del 1.5%‚Äì2%).\n",
    "\n",
    "El forecast (l√≠nea verde discontinua) se mantiene casi plano, con poca variaci√≥n.\n",
    "\n",
    "‚Üí El VAR refleja que Jap√≥n no tiene grandes movimientos en tipos largos.\n",
    "\n",
    "Inflaci√≥n interanual (l√≠nea naranja)\n",
    "\n",
    "Mucha m√°s volatilidad en la historia reciente (negativa en 2020, picos altos tras 2022).\n",
    "\n",
    "El forecast (l√≠nea roja discontinua) muestra un rebote hacia arriba, con alta incertidumbre (bandas muy anchas).\n",
    "\n",
    "‚Üí Esto refleja que la inflaci√≥n en Jap√≥n es muy dif√≠cil de prever con pocos datos.\n",
    "\n",
    "### Conclusi√≥n corta para Jap√≥n\n",
    "\n",
    "Los rendimientos a 10 a√±os son muy estables, con pron√≥stico casi plano.\n",
    "\n",
    "La inflaci√≥n es altamente incierta, y el VAR la proyecta con posible aumento, pero con gran varianza.\n",
    "\n",
    "La falta de estabilidad estad√≠stica sugiere que el modelo podr√≠a necesitar:\n",
    "\n",
    "M√°s a√±os de datos, o\n",
    "\n",
    "Incluir m√°s variables (ej. PIB, pol√≠tica monetaria, tipo de cambio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üá©üá™ Alemania\n",
    "\n",
    "Datos completos y estables.\n",
    "\n",
    "Rendimientos y tipos muestran relaci√≥n moderada.\n",
    "\n",
    "Inflaci√≥n relativamente contenida, forecast razonable.\n",
    "\n",
    "## üá∫üá∏ Estados Unidos\n",
    "\n",
    "Serie m√°s larga y robusta.\n",
    "\n",
    "VAR bien estimado con lags peque√±os.\n",
    "\n",
    "Forecast estable: yields suben suavemente, inflaci√≥n m√°s vol√°til pero con se√±al clara.\n",
    "\n",
    "## üá™üá∏ Espa√±a\n",
    "\n",
    "Serie corta pero consistente.\n",
    "\n",
    "Rendimientos bajando tras 2010, inflaci√≥n moderada.\n",
    "\n",
    "Forecast: yields ligeramente al alza, inflaci√≥n estable con bandas amplias.\n",
    "\n",
    "## üá¨üáß Reino Unido\n",
    "\n",
    "Datos completos, VAR estable.\n",
    "\n",
    "Rendimientos estables en torno a 4‚Äì5%.\n",
    "\n",
    "Inflaci√≥n muy vol√°til (pico 2022), forecast muestra normalizaci√≥n pero con incertidumbre.\n",
    "\n",
    "üáØüáµ Jap√≥n\n",
    "\n",
    "Serie con 15 observaciones ‚Üí pocos datos.\n",
    "\n",
    "Rendimientos extremadamente estables (1‚Äì2%).\n",
    "\n",
    "Inflaci√≥n impredecible: forecast incierto, modelo inestable.\n",
    "\n",
    "Conclusi√≥n: se necesitan m√°s variables para mejorar.\n",
    "\n",
    "## üìå Conclusi√≥n general\n",
    "\n",
    "Robustos: USA y Alemania (mejor calidad de forecast).\n",
    "\n",
    "Interesantes para comparar: UK y Espa√±a (muestran volatilidad post-crisis e inflaci√≥n reciente).\n",
    "\n",
    "Fr√°gil: Jap√≥n (modelo inestable, forecast poco fiable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ML Utilities (usamos para todos los pa√≠ses) ===\n",
    "\n",
    "# 1) Dataset supervisado: lags como features\n",
    "def make_supervised(df, lags=3, h=1, target='yield_10y'):\n",
    "    Xy = df.copy()\n",
    "    for L in range(1, lags+1):\n",
    "        Xy[f'yield_lag{L}'] = Xy['yield_10y'].shift(L)\n",
    "        Xy[f'infl_lag{L}']  = Xy['inflation_yoy'].shift(L)\n",
    "    Xy['target'] = Xy[target].shift(-h)\n",
    "    return Xy.dropna()\n",
    "\n",
    "# 2) Expanding backtest con un modelo sklearn\n",
    "def expanding_backtest(df, model, lags=3, h=1, test_start=2018):\n",
    "    Xy = make_supervised(df, lags=lags, h=h)\n",
    "    preds, trues, years = [], [], []\n",
    "    for yr in Xy.index:\n",
    "        if yr < test_start: \n",
    "            continue\n",
    "        train = Xy.loc[Xy.index < yr]\n",
    "        test  = Xy.loc[[yr]]\n",
    "        if len(train) < 6: \n",
    "            continue\n",
    "        X_tr, y_tr = train.drop(columns=['target']), train['target']\n",
    "        X_te, y_te = test.drop(columns=['target']), test['target'].iloc[0]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_hat = model.predict(X_te)[0]\n",
    "        preds.append(y_hat); trues.append(y_te); years.append(int(yr))\n",
    "    return pd.DataFrame({'Year': years, 'y_true': trues, 'y_pred': preds}).set_index('Year')\n",
    "\n",
    "# 3) Baseline naive\n",
    "def naive_forecast(df, h=1, start_year=2018):\n",
    "    target = df['yield_10y'].shift(-h)\n",
    "    naive  = df['yield_10y']\n",
    "    out = pd.DataFrame({'y_true': target, 'y_pred': naive}).dropna()\n",
    "    return out.loc[out.index >= start_year]\n",
    "\n",
    "# 4) VAR baseline\n",
    "def var_recursive_forecast(df, h=1, start_year=2018, maxlags=3):\n",
    "    preds, trues, years = [], [], []\n",
    "    for yr in range(start_year, int(df.index.max())+1):\n",
    "        train = df.loc[df.index < yr]\n",
    "        if len(train) < 6:\n",
    "            continue\n",
    "        safe = max(1, min(maxlags, (len(train)-3)//2))\n",
    "        try:\n",
    "            res = VAR(train).fit(ic='aic', maxlags=safe)\n",
    "            y_hat = res.forecast(res.y, steps=1)[0][0]\n",
    "            preds.append(y_hat)\n",
    "            trues.append(df.loc[yr,'yield_10y'])\n",
    "            years.append(yr)\n",
    "        except Exception as e:\n",
    "            print(f\"skip {yr}: {e}\")\n",
    "            continue\n",
    "    return pd.DataFrame({'Year': years, 'y_true': trues, 'y_pred': preds}).set_index('Year')\n",
    "\n",
    "# 5) M√©tricas\n",
    "def eval_metrics(df_pred):\n",
    "    mae = mean_absolute_error(df_pred['y_true'], df_pred['y_pred'])\n",
    "    rmse = sqrt(mean_squared_error(df_pred['y_true'], df_pred['y_pred']))\n",
    "    return mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ML para USA ===\n",
    "TEST_START = 2018\n",
    "\n",
    "dfc = df_us[['yield_10y','inflation_yoy']].dropna().copy()\n",
    "dfc.index = dfc.index.astype(int)\n",
    "\n",
    "# Baseline Naive\n",
    "p_naive = naive_forecast(dfc, h=1, start_year=TEST_START)\n",
    "m_naive = eval_metrics(p_naive)\n",
    "\n",
    "# VAR baseline\n",
    "p_var = var_recursive_forecast(dfc, h=1, start_year=TEST_START, maxlags=3)\n",
    "m_var = eval_metrics(p_var)\n",
    "\n",
    "# ElasticNet\n",
    "enet = ElasticNetCV(l1_ratio=[0.1,0.5,0.9], cv=3, max_iter=20000)\n",
    "p_en  = expanding_backtest(dfc, enet, lags=3, h=1, test_start=TEST_START)\n",
    "m_en  = eval_metrics(p_en)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "p_rf = expanding_backtest(dfc, rf, lags=3, h=1, test_start=TEST_START)\n",
    "m_rf = eval_metrics(p_rf)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "p_gb = expanding_backtest(dfc, gb, lags=3, h=1, test_start=TEST_START)\n",
    "m_gb = eval_metrics(p_gb)\n",
    "\n",
    "# Tabla resumen USA\n",
    "usa_results = pd.DataFrame([\n",
    "    ['Naive', *m_naive],\n",
    "    ['VAR', *m_var],\n",
    "    ['ElasticNet', *m_en],\n",
    "    ['RandomForest', *m_rf],\n",
    "    ['GradientBoosting', *m_gb],\n",
    "], columns=['Model','MAE','RMSE'])\n",
    "\n",
    "usa_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset con las variables relevantes\n",
    "dfc = df[['yield_10y', 'inflation_yoy']].dropna().copy()\n",
    "dfc.index = dfc['Year'].astype(int)   # Usar el a√±o como √≠ndice\n",
    "\n",
    "# Probar naive forecast\n",
    "p_naive = naive_forecast(dfc, h=1, start_year=2018)\n",
    "\n",
    "print(p_naive.head())\n",
    "print(p_naive.tail())\n",
    "print(\"Shape:\", p_naive.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLOQUE ML ROBUSTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- utilidades ----------\n",
    "def make_supervised(df, lags=1):\n",
    "    \"\"\"\n",
    "    Construye X,y con rezagos de yield_10y e inflation_yoy.\n",
    "    y = yield_10y_t ; X = [yield_10y_{t-1..t-l}, infl_{t-1..t-l}]\n",
    "    \"\"\"\n",
    "    work = df.copy()\n",
    "    cols = []\n",
    "    for k in range(1, lags+1):\n",
    "        for c in ['yield_10y','inflation_yoy']:\n",
    "            name = f\"{c}_lag{k}\"\n",
    "            work[name] = work[c].shift(k)\n",
    "            cols.append(name)\n",
    "    work = work.dropna()\n",
    "    X = work[cols].values\n",
    "    y = work['yield_10y'].values\n",
    "    idx = work.index.values.astype(int)\n",
    "    return X, y, idx\n",
    "\n",
    "def eval_metrics_safe(df_pred, label):\n",
    "    if df_pred is None or len(df_pred)==0:\n",
    "        return pd.Series({'Model':label, 'MAE':np.nan, 'RMSE':np.nan})\n",
    "    mae = mean_absolute_error(df_pred['y_true'], df_pred['y_pred'])\n",
    "    rmse = sqrt(mean_squared_error(df_pred['y_true'], df_pred['y_pred']))\n",
    "    return pd.Series({'Model':label, 'MAE':mae, 'RMSE':rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- pron√≥sticos por ventana expandida ----------\n",
    "def naive_recursive_forecast(df, start_year):\n",
    "    preds, trues, years = [], [], []\n",
    "    for yr in range(start_year, int(df.index.max())+1):\n",
    "        hist = df.loc[df.index < yr]\n",
    "        if len(hist) < 1: \n",
    "            continue\n",
    "        y_hat = float(hist['yield_10y'].iloc[-1])    # √∫ltimo valor\n",
    "        y_true = float(df.loc[yr, 'yield_10y'])\n",
    "        preds.append(y_hat); trues.append(y_true); years.append(int(yr))\n",
    "    return pd.DataFrame({'Year':years, 'y_true':trues, 'y_pred':preds}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_recursive_forecast_fix(df, start_year, p=1, min_train=3):\n",
    "    preds, trues, years = [], [], []\n",
    "    for yr in range(start_year, int(df.index.max())+1):\n",
    "        train = df.loc[df.index < yr]\n",
    "        if len(train) < max(min_train, p+1):\n",
    "            continue\n",
    "        try:\n",
    "            res = VAR(train).fit(p)  # p fijo para muestras peque√±as\n",
    "            preds.append(float(res.forecast(res.y, steps=1)[0][0]))  # 1¬™ col = yield\n",
    "            trues.append(float(df.loc[yr, 'yield_10y']))\n",
    "            years.append(int(yr))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.DataFrame({'Year':years, 'y_true':trues, 'y_pred':preds}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_recursive_forecast(df, start_year, lags, model):\n",
    "    X_all, y_all, idx = make_supervised(df, lags=lags)\n",
    "    preds, trues, years = [], [], []\n",
    "    # map year -> row position en X_all\n",
    "    year_to_pos = {int(y):i for i,y in enumerate(idx)}\n",
    "    for yr in range(start_year, int(df.index.max())+1):\n",
    "        if yr not in year_to_pos: \n",
    "            continue\n",
    "        pos = year_to_pos[yr]\n",
    "        if pos < 1: \n",
    "            continue\n",
    "        X_train, y_train = X_all[:pos], y_all[:pos]\n",
    "        X_test, y_test   = X_all[pos:pos+1], y_all[pos:pos+1]\n",
    "        if len(y_train) < 3:\n",
    "            continue\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_hat = float(model.predict(X_test)[0])\n",
    "            preds.append(y_hat); trues.append(float(y_test[0])); years.append(int(yr))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.DataFrame({'Year':years, 'y_true':trues, 'y_pred':preds}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- ejecuci√≥n para un pa√≠s ----------\n",
    "def run_country_ML(dfc, country_name, test_start=2018, lags=1):\n",
    "    dfc = dfc.dropna().copy()\n",
    "    dfc.index = dfc.index.astype(int)\n",
    "    if len(dfc) < max(6, lags+3):\n",
    "        print(f\"[{country_name}] muy pocos datos -> se omite.\")\n",
    "        return pd.DataFrame(columns=['Model','MAE','RMSE'])\n",
    "    first, last = int(dfc.index.min()), int(dfc.index.max())\n",
    "    print(f\"{country_name} a√±os disponibles: {first} ‚Üí {last} | N= {len(dfc)}\")\n",
    "    TEST_START = max(test_start, first + lags + 2)  # garant√≠a de m√≠nimo train\n",
    "    print(\"TEST_START usado:\", TEST_START)\n",
    "\n",
    "    # Naive\n",
    "    p_naive = naive_recursive_forecast(dfc, TEST_START)\n",
    "    m_naive = eval_metrics_safe(p_naive, \"Naive\")\n",
    "\n",
    "    # VAR (p=1)\n",
    "    p_var = var_recursive_forecast_fix(dfc, TEST_START, p=1, min_train=3)\n",
    "    m_var  = eval_metrics_safe(p_var, \"VAR(p=1)\")\n",
    "\n",
    "    # ElasticNet\n",
    "    enet = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('model', ElasticNetCV(l1_ratio=[0.1,0.5,0.9], cv=3, max_iter=20000, n_jobs=None))])\n",
    "    p_en = sk_recursive_forecast(dfc, TEST_START, lags=lags, model=enet)\n",
    "    m_en = eval_metrics_safe(p_en, \"ElasticNet\")\n",
    "\n",
    "    # RandomForest\n",
    "    rf = RandomForestRegressor(n_estimators=400, max_depth=None, random_state=0)\n",
    "    p_rf = sk_recursive_forecast(dfc, TEST_START, lags=lags, model=rf)\n",
    "    m_rf = eval_metrics_safe(p_rf, \"RandomForest\")\n",
    "\n",
    "    # GradientBoosting\n",
    "    gb = GradientBoostingRegressor(random_state=0)\n",
    "    p_gb = sk_recursive_forecast(dfc, TEST_START, lags=lags, model=gb)\n",
    "    m_gb = eval_metrics_safe(p_gb, \"GradientBoosting\")\n",
    "\n",
    "    res = pd.DataFrame([m_naive, m_var, m_en, m_rf, m_gb])\n",
    "    print(f\"# de predicciones usadas -> Naive: {len(p_naive)} | VAR: {len(p_var)} | EN: {len(p_en)} | RF: {len(p_rf)} | GB: {len(p_gb)}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Lanza para los pa√≠ses disponibles ----------\n",
    "all_results = []\n",
    "\n",
    "countries = {\n",
    "    'USA': 'df_us',\n",
    "    'Germany': 'df_germany' if 'df_germany' in globals() else 'df_de',\n",
    "    'Spain': 'df_es',\n",
    "    'United Kingdom': 'df_uk',\n",
    "    'Japan': 'df_jp'\n",
    "}\n",
    "\n",
    "for name, varname in countries.items():\n",
    "    if isinstance(varname, str) and varname in globals():\n",
    "        dfc = globals()[varname]\n",
    "        try:\n",
    "            dfc = dfc[['yield_10y','inflation_yoy']]\n",
    "        except Exception:\n",
    "            print(f\"[{name}] dataframe no tiene columnas esperadas, se omite.\")\n",
    "            continue\n",
    "        res = run_country_ML(dfc, name, test_start=2018, lags=1)\n",
    "        if len(res):\n",
    "            res.insert(0, 'Country', name)\n",
    "            all_results.append(res)\n",
    "    else:\n",
    "        print(f\"[{name}] no encontrado en el entorno, se omite.\")\n",
    "\n",
    "results_table = pd.concat(all_results, ignore_index=True) if all_results else pd.DataFrame(columns=['Country','Model','MAE','RMSE'])\n",
    "display(results_table)\n",
    "# ========= FIN BLOQUE =========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest ML multi-pa√≠s: yield_10y ~ {lags(yield_10y), lags(inflation_yoy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 0) ENTRADAS ESPERADAS --------\n",
    "# - DataFrame 'yields' con col 'time' (epoch ms o fecha) y columnas 10Y tipo 'US10','DE10','GB10','JP10','ES10',...\n",
    "# - DataFrame 'wb_small' con columnas ['Country','Year','inflation_yoy']\n",
    "#\n",
    "# Si no existen en memoria, intenta cargarlos desde archivos habituales:\n",
    "try:\n",
    "    yields\n",
    "except NameError:\n",
    "    yields = pd.read_csv(YIELDS_CSV)\n",
    "\n",
    "try:\n",
    "    wb_small\n",
    "except NameError:\n",
    "    wb = pd.read_csv(WORLD_BANK_DATA)\n",
    "    wb_small = wb.rename(columns={\n",
    "        'country_name':'Country',\n",
    "        'year':'Year',\n",
    "        'Inflation (CPI %)':'inflation_yoy'\n",
    "    })[['Country','Year','inflation_yoy']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 1) UTILIDADES DE DATOS --------\n",
    "def make_annual_yields(yields_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agrega por a√±o todas las columnas XX10 que existan en 'yields'.\"\"\"\n",
    "    df = yields_df.copy()\n",
    "    # Asegura columna fecha->a√±o\n",
    "    if 'time' in df.columns:\n",
    "        try:\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='ms', errors='coerce')\n",
    "        except Exception:\n",
    "            df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        df = df.dropna(subset=['time'])\n",
    "        df['Year'] = df['time'].dt.year\n",
    "    elif 'Year' not in df.columns:\n",
    "        raise ValueError(\"No encuentro 'time' ni 'Year' en yields.\")\n",
    "    # columnas 10Y (XX10)\n",
    "    ten10 = [c for c in df.columns if re.fullmatch(r\"[A-Z]{2}10\", str(c))]\n",
    "    if not ten10:\n",
    "        raise ValueError(\"No encuentro columnas '*10' (p.ej. US10, DE10) en yields.\")\n",
    "    # media anual\n",
    "    y_ann = df.groupby('Year', as_index=False)[ten10].mean()\n",
    "    return y_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_country_df(y_ann: pd.DataFrame, wb_small: pd.DataFrame, code2: str, country_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Crea df con Year, yield_10y, inflation_yoy para un pa√≠s.\"\"\"\n",
    "    col = f\"{code2}10\"\n",
    "    if col not in y_ann.columns:\n",
    "        raise KeyError(f\"No existe {col} en yields anuales.\")\n",
    "    y = (y_ann[['Year', col]]\n",
    "         .rename(columns={col:'yield_10y'}))\n",
    "    i = (wb_small.query(\"Country == @country_name\")[['Year','inflation_yoy']]\n",
    "         .copy())\n",
    "    df = (y.merge(i, on='Year', how='inner')\n",
    "            .dropna()\n",
    "            .set_index('Year')\n",
    "            .sort_index())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(df: pd.DataFrame, lags:int=3) -> pd.DataFrame:\n",
    "    \"\"\"Crea variables rezagadas para ambos (yield_10y, inflation_yoy). Salida: X, y, index.\"\"\"\n",
    "    d = df.copy()\n",
    "    for L in range(1, lags+1):\n",
    "        d[f'yield_10y_l{L}'] = d['yield_10y'].shift(L)\n",
    "        d[f'inflation_yoy_l{L}'] = d['inflation_yoy'].shift(L)\n",
    "    d = d.dropna().copy()\n",
    "    y = d['yield_10y'].copy()\n",
    "    X = d.drop(columns=['yield_10y'])\n",
    "    return X, y, d.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 2) MODELOS ROLLING --------\n",
    "def naive_recursive(df: pd.DataFrame, start_year:int) -> pd.DataFrame:\n",
    "    \"\"\"Predicci√≥n naive: y_hat_t = y_{t-1}.\"\"\"\n",
    "    df = df.sort_index()\n",
    "    preds, truth, idx = [], [], []\n",
    "    years = df.index.values\n",
    "    for t in years:\n",
    "        if t < start_year: \n",
    "            continue\n",
    "        pos = np.where(years==t)[0][0]\n",
    "        if pos == 0: \n",
    "            continue\n",
    "        y_hat = df.iloc[pos-1]['yield_10y']\n",
    "        preds.append(float(y_hat))\n",
    "        truth.append(float(df.iloc[pos]['yield_10y']))\n",
    "        idx.append(int(t))\n",
    "    return pd.DataFrame({'Year':idx,'y_pred':preds,'y_true':truth}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_recursive(df: pd.DataFrame, start_year:int, maxlags:int=3) -> pd.DataFrame:\n",
    "    \"\"\"VAR rolling 1 paso; se salta si no hay suficientes datos.\"\"\"\n",
    "    df = df.sort_index()\n",
    "    preds, truth, idx = [], [], []\n",
    "    years = df.index.values\n",
    "    for t in years:\n",
    "        if t < start_year:\n",
    "            continue\n",
    "        end_pos = np.where(years==t)[0][0]\n",
    "        train = df.iloc[:end_pos]\n",
    "        if len(train) < (maxlags+4):  # seguridad\n",
    "            continue\n",
    "        safe = max(1, min(maxlags, (len(train)-2)//2))\n",
    "        try:\n",
    "            res = VAR(train).fit(ic='aic', maxlags=safe)\n",
    "            y_hat = res.forecast(train.values[-res.k_ar:], steps=1)[0][0]  # 1¬™ variable = yield\n",
    "        except Exception:\n",
    "            continue\n",
    "        preds.append(float(y_hat))\n",
    "        truth.append(float(df.iloc[end_pos]['yield_10y']))\n",
    "        idx.append(int(t))\n",
    "    return pd.DataFrame({'Year':idx,'y_pred':preds,'y_true':truth}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_recursive(df: pd.DataFrame, start_year:int, model, lags:int=3) -> pd.DataFrame:\n",
    "    \"\"\"Framework com√∫n para ElasticNet / RF / GB con features de rezagos.\"\"\"\n",
    "    df = df.sort_index()\n",
    "    # Pre-lags para no recalcular en cada ventana\n",
    "    Xall, yall, idx_all = make_lags(df, lags=lags)  # √≠ndices coinciden con a√±os v√°lidos\n",
    "    preds, truth, idx = [], [], []\n",
    "    years = df.index.values\n",
    "    for t in years:\n",
    "        if t < start_year: \n",
    "            continue\n",
    "        if t not in idx_all: \n",
    "            # no hay suficientes rezagos a√∫n\n",
    "            continue\n",
    "        # train = a√±os con √≠ndice < t dentro de idx_all\n",
    "        mask_train = idx_all < t\n",
    "        if mask_train.sum() < 5:  # m√≠nimo razonable\n",
    "            continue\n",
    "        X_tr, y_tr = Xall[mask_train], yall[mask_train]\n",
    "        try:\n",
    "            mdl = model() if callable(model) else model\n",
    "            mdl.fit(X_tr, y_tr)\n",
    "            # pred para el a√±o t (fila exacta de idx_all == t)\n",
    "            x_t = Xall[idx_all==t]\n",
    "            y_hat = mdl.predict(x_t)[0]\n",
    "        except Exception:\n",
    "            continue\n",
    "        preds.append(float(y_hat))\n",
    "        # verdad para t\n",
    "        truth.append(float(df.loc[t, 'yield_10y']))\n",
    "        idx.append(int(t))\n",
    "    return pd.DataFrame({'Year':idx,'y_pred':preds,'y_true':truth}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(df_pred: pd.DataFrame):\n",
    "    if df_pred is None or df_pred.empty:\n",
    "        return np.nan, np.nan, 0\n",
    "    return (mean_absolute_error(df_pred['y_true'], df_pred['y_pred']),\n",
    "            sqrt(mean_squared_error(df_pred['y_true'], df_pred['y_pred'])),\n",
    "            len(df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 3) PREPARAR Y CORRER --------\n",
    "y_ann = make_annual_yields(yields)\n",
    "\n",
    "countries = [\n",
    "    # (nombre_mostrar, code2 en yields, nombre_en_WB)\n",
    "    (\"USA\",     \"US\", \"United States\"),\n",
    "    (\"Germany\", \"DE\", \"Germany\"),\n",
    "    (\"United Kingdom\", \"GB\", \"United Kingdom\"),\n",
    "    (\"Japan\",   \"JP\", \"Japan\"),\n",
    "    (\"Spain\",   \"ES\", \"Spain\"),\n",
    "]\n",
    "\n",
    "TEST_START_DEFAULT = 2018   # para garantizar observaciones en la ventana de test\n",
    "LAGS_SK = 3\n",
    "\n",
    "rows = []\n",
    "\n",
    "for display_name, code2, wb_name in countries:\n",
    "    # construir panel pa√≠s\n",
    "    try:\n",
    "        dfc = build_country_df(y_ann, wb_small, code2, wb_name)\n",
    "    except Exception as e:\n",
    "        print(f\"[{display_name}] no se pudo construir el panel -> {e}. Se omite.\")\n",
    "        continue\n",
    "\n",
    "    # rango y elecci√≥n de test_start\n",
    "    yr_min, yr_max, N = int(dfc.index.min()), int(dfc.index.max()), len(dfc)\n",
    "    # si hay al menos 8‚Äì9 obs, usa 2018; si no, desplaza\n",
    "    TEST_START = TEST_START_DEFAULT\n",
    "    while TEST_START <= yr_min and TEST_START < yr_max:\n",
    "        TEST_START += 1\n",
    "    while (yr_max - TEST_START + 1) < 3 and TEST_START > yr_min:  # al menos 3 puntos de test\n",
    "        TEST_START -= 1\n",
    "\n",
    "    print(f\"\\n{display_name} a√±os disponibles: {yr_min} ‚Üí {yr_max} | N= {N}\")\n",
    "    print(\"TEST_START usado:\", TEST_START)\n",
    "\n",
    "    # NAIVE\n",
    "    p_naive = naive_recursive(dfc, TEST_START)\n",
    "    mae, rmse, n = metrics(p_naive)\n",
    "    rows.append([display_name, \"Naive\", mae, rmse, n])\n",
    "\n",
    "    # VAR (si alcanza)\n",
    "    p_var = var_recursive(dfc, TEST_START, maxlags=3)\n",
    "    mae, rmse, n = metrics(p_var)\n",
    "    rows.append([display_name, f\"VAR(p=? )\", mae, rmse, n])\n",
    "\n",
    "    # ElasticNet\n",
    "    def EN(): return ElasticNetCV(l1_ratio=[0.1,0.5,0.9], cv=3, max_iter=30000, n_jobs=None)\n",
    "    p_en = sk_recursive(dfc, TEST_START, EN, lags=LAGS_SK)\n",
    "    mae, rmse, n = metrics(p_en)\n",
    "    rows.append([display_name, \"ElasticNet\", mae, rmse, n])\n",
    "\n",
    "    # RandomForest\n",
    "    def RF(): return RandomForestRegressor(n_estimators=500, random_state=7)\n",
    "    p_rf = sk_recursive(dfc, TEST_START, RF, lags=LAGS_SK)\n",
    "    mae, rmse, n = metrics(p_rf)\n",
    "    rows.append([display_name, \"RandomForest\", mae, rmse, n])\n",
    "\n",
    "    # GradientBoosting\n",
    "    def GB(): return GradientBoostingRegressor(random_state=7)\n",
    "    p_gb = sk_recursive(dfc, TEST_START, GB, lags=LAGS_SK)\n",
    "    mae, rmse, n = metrics(p_gb)\n",
    "    rows.append([display_name, \"GradientBoosting\", mae, rmse, n])\n",
    "\n",
    "    print(f\"# de predicciones usadas => Naive: {len(p_naive)} | VAR: {len(p_var)} | EN: {len(p_en)} | RF: {len(p_rf)} | GB: {len(p_gb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 4) RESUMEN --------\n",
    "summary = pd.DataFrame(rows, columns=['Country','Model','MAE','RMSE','N_pred']).sort_values(['Country','MAE'])\n",
    "display(summary)\n",
    "filename = \"files/output/ml_backtest_summary.csv\"\n",
    "summary.to_csv(filename, index=False)\n",
    "print(f\"\\nGuardado: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
