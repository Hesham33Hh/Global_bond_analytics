{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PACKAGE IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from math import sqrt\n",
    "\n",
    "# Data science and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Scientific computing\n",
    "from scipy import stats\n",
    "\n",
    "# Statistics and econometrics\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch, het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_YIELDS_CSV = \"files/raw/us_treasury_yields_daily.csv\"\n",
    "YIELDS_CSV = \"files/raw/yields.csv\"\n",
    "MACRO_CSV  = \"files/raw/world_bank_development_indicators.csv\"\n",
    "WORLD_BANK_DATA = \"files/raw/world_bank_data_2025.csv\"\n",
    "DGS10 = \"files/raw/DGS10.csv\"\n",
    "IRLTLT=\"files/raw/IRLTLT01DEM156N.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USA: 10Y Yield vs Inflation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columna 10 años\n",
    "def detect_10y_col(cols):\n",
    "    for c in cols:\n",
    "        cl = c.strip().lower()\n",
    "        if cl in {\"us10y\",\"10y\",\"10 yr\",\"10-year\",\"10 year\",\"10_yr\"}:\n",
    "            return c\n",
    "    for c in cols:\n",
    "        cl = c.lower()\n",
    "        if \"10\" in cl and (\"yr\" in cl or \"year\" in cl):\n",
    "            return c\n",
    "    if \"US10Y\" in cols: return \"US10Y\"\n",
    "    if \"10 Yr\" in cols: return \"10 Yr\"\n",
    "    raise ValueError(f\"No encuentro columna 10Y en yields. Columnas: {list(cols)[:12]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_year_col(df, preferred_cols=(\"year\",\"date\",\"fecha\",\"period\",\"time\",\"obs_date\",\"observationdate\")):\n",
    "    \"\"\"\n",
    "    Devuelve una Serie 'Year' (int) extraída de la mejor columna disponible:\n",
    "    - Si hay 'year' numérico, lo usa.\n",
    "    - Si hay fechas, parsea a datetime y saca el año.\n",
    "    - Si hay strings tipo '1960 [YR1960]' o 'YR1960', extrae los 4 dígitos por regex.\n",
    "    \"\"\"\n",
    "    # 1) columna explícita de año\n",
    "    for c in df.columns:\n",
    "        if c.lower() in (\"year\",\"anio\",\"año\"):\n",
    "            y = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "            if y.notna().any():\n",
    "                return y.astype(\"Int64\")\n",
    "    # 2) columnas “fecha”\n",
    "    for cand in preferred_cols:\n",
    "        for c in df.columns:\n",
    "            if c.lower()==cand:\n",
    "                # a) intentar datetime\n",
    "                dt = pd.to_datetime(df[c], errors=\"coerce\", dayfirst=False)\n",
    "                if dt.notna().any():\n",
    "                    return dt.dt.year.astype(\"Int64\")\n",
    "                # b) extraer patrón de 4 dígitos\n",
    "                s = df[c].astype(str).str.extract(r'(\\d{4})', expand=False)\n",
    "                y = pd.to_numeric(s, errors=\"coerce\")\n",
    "                if y.notna().any():\n",
    "                    return y.astype(\"Int64\")\n",
    "    # 3) si ninguna funciona, intentar extraer 4 dígitos de cualquier columna de texto\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype==object:\n",
    "            s = df[c].astype(str).str.extract(r'(\\d{4})', expand=False)\n",
    "            y = pd.to_numeric(s, errors=\"coerce\")\n",
    "            if y.notna().sum() >= len(df)*0.3:\n",
    "                return y.astype(\"Int64\")\n",
    "    return pd.Series([pd.NA]*len(df), index=df.index, dtype=\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inflation_col(df):\n",
    "    \"\"\"\n",
    "    Busca una columna de inflación (%). Prioriza nombres típicos.\n",
    "    \"\"\"\n",
    "    prefs = [\"inflation_annual%\", \"inflation_yoy\", \"inflation yoy\", \"inflation%\", \"inflation\", \"cpi_yoy\", \"cpi yoy\"]\n",
    "    # prioridad por nombre\n",
    "    for p in prefs:\n",
    "        for c in df.columns:\n",
    "            if p.replace(\" \",\"\") in c.replace(\" \",\"\").lower():\n",
    "                return c\n",
    "    # si no, una 'value' genérica\n",
    "    for c in df.columns:\n",
    "        if \"value\" in c.lower() or \"valor\" in c.lower():\n",
    "            return c\n",
    "    # último recurso: columna numérica “prometedora”\n",
    "    numc = [c for c in df.columns if pd.to_numeric(df[c], errors=\"coerce\").notna().sum()>0]\n",
    "    if numc:\n",
    "        return numc[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_country_usa(df):\n",
    "    \"\"\"\n",
    "    Intenta filtrar USA por varias columnas posibles.\n",
    "    \"\"\"\n",
    "    # a) 'Country Code' == USA\n",
    "    for c in df.columns:\n",
    "        if c.lower() in (\"country code\",\"country_code\",\"iso3\",\"isocode\",\"code\"):\n",
    "            mask = df[c].astype(str).str.upper().eq(\"USA\")\n",
    "            if mask.any(): \n",
    "                return df.loc[mask].copy()\n",
    "    # b) 'Country' / 'Country Name' contiene 'United States' o 'USA'\n",
    "    for c in df.columns:\n",
    "        if c.lower() in (\"country\",\"country name\",\"pais\"):\n",
    "            mask = df[c].astype(str).str.contains(r\"\\b(united states|usa)\\b\", case=False, na=False)\n",
    "            if mask.any():\n",
    "                return df.loc[mask].copy()\n",
    "    # si no hay país, asumimos que el archivo ya es solo USA (devolver tal cual)\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (funciona con \"country|date|inflation_annual%\")\n",
    "\n",
    "# ---------- 1) Yields USA -> anual 10Y ----------\n",
    "y = pd.read_csv(DAILY_YIELDS_CSV)\n",
    "\n",
    "# fecha\n",
    "date_col = next((c for c in y.columns if c.lower() in {\"date\",\"fecha\"}), None)\n",
    "if date_col is None:\n",
    "    raise ValueError(\"No encuentro columna de fecha en yields CSV.\")\n",
    "y[date_col] = pd.to_datetime(y[date_col], errors=\"coerce\")\n",
    "y = y.dropna(subset=[date_col])\n",
    "col10 = detect_10y_col(y.columns)\n",
    "\n",
    "# anual\n",
    "y = y[[date_col, col10]].rename(columns={date_col:\"date\", col10:\"yield_10y\"})\n",
    "y[\"Year\"] = y[\"date\"].dt.year.astype(int)\n",
    "us_annual = y.groupby(\"Year\", as_index=False)[\"yield_10y\"].mean()\n",
    "print(\"YIELDS USA — años:\", us_annual[\"Year\"].min(), \"→\", us_annual[\"Year\"].max(), \"| n:\", len(us_annual))\n",
    "\n",
    "# ========= DIAGNÓSTICO + EXTRACCIÓN ROBUSTA DE INFLACIÓN (USA) =========\n",
    "m = pd.read_csv(MACRO_CSV)\n",
    "\n",
    "# 1) filtrar USA\n",
    "m_usa = filter_country_usa(m)\n",
    "\n",
    "# 2) obtener Year robusto\n",
    "m_usa[\"Year\"] = extract_year_col(m_usa)\n",
    "\n",
    "# 3) localizar columna de inflación\n",
    "infl_col = find_inflation_col(m_usa)\n",
    "if infl_col is None:\n",
    "    raise RuntimeError(\"No encuentro columna de inflación en tu archivo macro. Revisa nombres de columnas.\")\n",
    "\n",
    "# 4) preparar inflación anual\n",
    "infl = (\n",
    "    m_usa[[\"Year\", infl_col]]\n",
    "      .rename(columns={infl_col:\"inflation_yoy\"})\n",
    "      .assign(inflation_yoy=lambda d: pd.to_numeric(d[\"inflation_yoy\"], errors=\"coerce\"))\n",
    "      .dropna(subset=[\"Year\",\"inflation_yoy\"])\n",
    ")\n",
    "infl[\"Year\"] = infl[\"Year\"].astype(int)\n",
    "\n",
    "# Si es mensual (múltiples filas por año), promediamos\n",
    "infl = infl.groupby(\"Year\", as_index=False)[\"inflation_yoy\"].mean()\n",
    "\n",
    "print(\"Yields USA: \", us_annual[\"Year\"].min(), \"→\", us_annual[\"Year\"].max(), \"| n:\", len(us_annual))\n",
    "print(\"Inflación USA:\", infl[\"Year\"].min() if len(infl) else None, \"→\", infl[\"Year\"].max() if len(infl) else None, \"| n:\", len(infl))\n",
    "\n",
    "# 5) forzar intersección y MERGE\n",
    "min_year = max(us_annual[\"Year\"].min(), infl[\"Year\"].min())\n",
    "max_year = min(us_annual[\"Year\"].max(), infl[\"Year\"].max())\n",
    "infl_clip = infl[(infl[\"Year\"]>=min_year) & (infl[\"Year\"]<=max_year)]\n",
    "ua_clip   = us_annual[(us_annual[\"Year\"]>=min_year) & (us_annual[\"Year\"]<=max_year)]\n",
    "\n",
    "df = ua_clip.merge(infl_clip, on=\"Year\", how=\"inner\").sort_values(\"Year\").reset_index(drop=True)\n",
    "if df.empty:\n",
    "    # diagnóstico extra\n",
    "    print(\">>> DEBUG — YEARS YIELDS:\", sorted(us_annual[\"Year\"].unique())[:10], \"...\", sorted(us_annual[\"Year\"].unique())[-10:])\n",
    "    print(\">>> DEBUG — YEARS INFL :\", sorted(infl[\"Year\"].unique())[:10], \"...\", sorted(infl[\"Year\"].unique())[-10:])\n",
    "    raise RuntimeError(\"Sigue sin haber años comunes. Revisa que 'Year' se esté extrayendo bien del macro CSV.\")\n",
    "\n",
    "df[\"real_yield\"] = df[\"yield_10y\"] - df[\"inflation_yoy\"]\n",
    "\n",
    "print(\"Filas tras merge:\", len(df))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df[\"Year\"], df[\"yield_10y\"], label=\"US 10Y Yield\")\n",
    "plt.plot(df[\"Year\"], df[\"inflation_yoy\"], label=\"Inflation YoY\")\n",
    "plt.title(\"USA: 10Y Yield vs Inflation\")\n",
    "plt.xlabel(\"Year\"); plt.ylabel(\"%\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(df[\"inflation_yoy\"], df[\"yield_10y\"])\n",
    "plt.title(\"Relación: Inflación vs US 10Y Yield\")\n",
    "plt.xlabel(\"Inflation YoY (%)\"); plt.ylabel(\"US 10Y Yield (%)\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Serie temporal: USA 10Y Yield vs Inflación (líneas)\n",
    "\n",
    "La línea azul (US 10Y Yield) muestra la rentabilidad de los bonos a 10 años.\n",
    "\n",
    "La línea naranja (Inflation YoY) muestra la inflación anual.\n",
    "\n",
    "Interpretación rápida:\n",
    "\n",
    "En los años 70-80 se ve un pico muy alto de inflación y yield: es la época de la crisis del petróleo y la política monetaria dura de la Fed (Volcker subió tipos muy fuertes).\n",
    "\n",
    "Desde los años 90 hasta 2020, ambos bajan gradualmente → entorno de baja inflación y yields decrecientes.\n",
    "\n",
    "Después de 2020, la inflación se dispara otra vez (post-COVID, guerra, disrupciones en energía).\n",
    "\n",
    "👉 Eso muestra que existe cierta relación: cuando la inflación sube fuerte, los yields suelen subir también, pero con rezagos o diferente magnitud.\n",
    "\n",
    "#### 2. Diagrama de dispersión: Inflación vs Yield\n",
    "\n",
    "Cada punto es un año (x = inflación, y = yield).\n",
    "\n",
    "Se ve una nube ascendente: cuando la inflación es baja (0-4%), los yields tienden a estar en 2-6%.\n",
    "\n",
    "Cuando la inflación es alta (6-12%), los yields también tienden a estar arriba (8-14%).\n",
    "\n",
    "Interpretación rápida:\n",
    "\n",
    "Hay una correlación positiva: inflación y yields tienden a moverse juntos.\n",
    "\n",
    "Pero no es 1:1 → hay dispersión (porque los yields dependen también de política monetaria, expectativas, riesgo, etc.).\n",
    "\n",
    "#### 3. Resumen antes de limpieza\n",
    "\n",
    "Los datos ya muestran una relación clara: más inflación = más yield.\n",
    "\n",
    "Pero hay ruido y valores extremos (ej: hiperinflación o datos atípicos que vimos en la tabla).\n",
    "\n",
    "Por eso, la siguiente etapa de limpieza (quitar inflaciones absurdas, errores, etc.) servirá para tener relaciones más nítidas y modelos más confiables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas básicas antes de limpiar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Correlación simple ---\")\n",
    "print(df[[\"yield_10y\", \"inflation_yoy\"]].corr())\n",
    "\n",
    "# Regresión lineal simple (Inflación -> Yield)\n",
    "\n",
    "X = df[\"inflation_yoy\"]\n",
    "y = df[\"yield_10y\"]\n",
    "\n",
    "X = sm.add_constant(X)  # añadimos intercepto\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(\"\\n--- Regresión lineal simple ---\")\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Correlación simple\n",
    "\n",
    "0.61 (positivo, moderado-fuerte) → Significa que cuando la inflación sube, los rendimientos del bono a 10 años en USA tienden a subir también.\n",
    "\n",
    "No es una correlación perfecta (1.0), pero sí clara y estadísticamente significativa.\n",
    "\n",
    "#### 📈 Regresión lineal simple\n",
    "\n",
    "Modelo:\n",
    "\n",
    "Yield 10Y\n",
    "\n",
    "=\n",
    "3.3783\n",
    "+\n",
    "0.6571\n",
    "⋅\n",
    "Inflaci\n",
    "o\n",
    "ˊ\n",
    "n YoY\n",
    "Yield 10Y=3.3783+0.6571⋅Inflaci\n",
    "o\n",
    "ˊ\n",
    "n YoY\n",
    "\n",
    "Constante (3.38): cuando la inflación es 0, el modelo predice un rendimiento del 3.38%.\n",
    "\n",
    "Coeficiente (0.6571): por cada +1% en la inflación, el yield sube en promedio +0.65%.\n",
    "\n",
    "p-valor (0.000): relación estadísticamente muy significativa.\n",
    "\n",
    "R² = 0.38: la inflación explica el 38% de la variación en los yields.\n",
    "\n",
    "Esto es bastante alto para datos macro, pero también nos dice que hay un 62% de variación que se explica por otros factores (ej. política monetaria, riesgo país, oferta/demanda global de bonos, etc.).\n",
    "\n",
    "#### 📌 Conclusión preliminar\n",
    "\n",
    "Existe una relación positiva clara entre inflación y yields en USA (1962–2024).\n",
    "\n",
    "La inflación no lo explica todo, pero sí es un driver muy importante.\n",
    "\n",
    "Esto tiene sentido económico: los inversores piden más rentabilidad en los bonos cuando esperan más inflación (para no perder poder adquisitivo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Resumen rápido (checkpoint hasta ahora):\n",
    "\n",
    "Ya cargamos y visualizamos las series de rendimiento del bono USA 10Y y inflación anual (1962–2024).\n",
    "\n",
    "Encontramos una correlación positiva moderada (0.61) → cuando la inflación sube, los yields también tienden a subir.\n",
    "\n",
    "La regresión lineal mostró que un +1% en inflación se asocia con un +0.65% en el yield 10Y, con R² = 0.38 → la inflación explica parte importante, pero no todo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paso 1: Copiar y limpiar outliers\n",
    "# ===============================\n",
    "\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Quitamos inflaciones absurdas (ej. errores de dataset o hiperinflación)\n",
    "df_clean = df_clean[df_clean[\"inflation_yoy\"].between(-20, 50)]\n",
    "\n",
    "print(\"Filas antes:\", len(df), \" | después:\", len(df_clean))\n",
    "\n",
    "# ===============================\n",
    "# Paso 2: Recalcular real_yield\n",
    "# ===============================\n",
    "\n",
    "df_clean[\"real_yield\"] = df_clean[\"yield_10y\"] - df_clean[\"inflation_yoy\"]\n",
    "\n",
    "# ===============================\n",
    "# Paso 3: Chequeo rápido\n",
    "# ===============================\n",
    "print(\"\\nÚltimos años limpios:\")\n",
    "print(df_clean.tail(10))\n",
    "\n",
    "# ===============================\n",
    "# Paso 4: Visualización post-limpieza\n",
    "# ===============================\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"yield_10y\"], label=\"US 10Y Yield\")\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"inflation_yoy\"], label=\"Inflation YoY\")\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"real_yield\"], label=\"Real Yield\", linestyle=\"--\")\n",
    "plt.title(\"USA: Yield 10Y, Inflación y Real Yield (datos limpios)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación rápida del gráfico\n",
    "\n",
    "Años 70s – 80s:\n",
    "\n",
    "La inflación se dispara (choques del petróleo).\n",
    "\n",
    "Los rendimientos nominales (azul) también suben fuerte.\n",
    "\n",
    "El rendimiento real (verde) se mantiene positivo pero muy volátil.\n",
    "\n",
    "Años 90s – 2000s:\n",
    "\n",
    "Inflación baja y estable (2–3%).\n",
    "\n",
    "Yield nominal cae gradualmente.\n",
    "\n",
    "El rendimiento real es bajo pero estable.\n",
    "\n",
    "2010s en adelante:\n",
    "\n",
    "Rendimientos muy bajos (política monetaria expansiva).\n",
    "\n",
    "Inflación estable… hasta el repunte 2021–2022.\n",
    "\n",
    "En 2021–2022 el real yield se hace negativo (bonos pierden contra inflación).\n",
    "\n",
    "#### Qué significa:\n",
    "\n",
    "Cuando el real yield es positivo → los bonos dan un retorno por encima de la inflación (buen refugio).\n",
    "\n",
    "Cuando el real yield es negativo → los inversores pierden poder adquisitivo aunque inviertan en bonos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlación con datos limpios ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Correlación simple (datos limpios) ---\")\n",
    "print(df_clean[[\"yield_10y\", \"inflation_yoy\"]].corr())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión lineal simple (datos limpios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean[[\"inflation_yoy\"]]\n",
    "y = df_clean[\"yield_10y\"]\n",
    "\n",
    "# Agregar constante al modelo\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "model_clean = sm.OLS(y, X).fit()\n",
    "print(\"\\n--- Regresión lineal simple (datos limpios) ---\")\n",
    "print(model_clean.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación del output de la regresión lineal:\n",
    "\n",
    "Coeficientes (const y inflación)\n",
    "\n",
    "Constante (const = 3.3783) → cuando la inflación es 0, el rendimiento de los bonos a 10 años tiende a estar en torno al 3.38%.\n",
    "\n",
    "Inflación (0.6571) → por cada +1% en inflación, el yield sube en promedio +0.66 puntos porcentuales. Esto confirma una relación positiva clara.\n",
    "\n",
    "R² (0.380)\n",
    "\n",
    "El 38% de la variabilidad del rendimiento de los bonos a 10 años se explica por la inflación.\n",
    "\n",
    "Esto significa que la inflación influye mucho, pero no lo explica todo (hay otros factores: política monetaria, expectativas, prima de riesgo, etc.).\n",
    "\n",
    "p-values\n",
    "\n",
    "Ambos coeficientes (constante e inflación) tienen p < 0.001, es decir, son estadísticamente significativos.\n",
    "\n",
    "La relación no es casualidad: hay evidencia fuerte de que la inflación impacta en el yield.\n",
    "\n",
    "Durbin-Watson (0.227)\n",
    "\n",
    "Valor bajo → indica que puede haber autocorrelación en los errores (normal en series temporales).\n",
    "\n",
    "Esto nos dice que quizá más adelante necesitemos un modelo de series temporales (ARIMA, VAR) o un modelo con variables adicionales.\n",
    "\n",
    "#### Conclusión rápida para tu proyecto\n",
    "👉 Existe una relación positiva y estadísticamente significativa entre la inflación y el rendimiento del bono USA 10Y: cuando la inflación sube, el yield también sube, aunque la inflación explica solo un 38% de la variación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ispersión inflación vs yield con la recta de regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot con la recta de regresión\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=\"inflation_yoy\", y=\"yield_10y\", data=df_clean, color=\"blue\", label=\"Datos\")\n",
    "\n",
    "# Ajustar la recta\n",
    "coef = 0.6571\n",
    "intercept = 3.3783\n",
    "x_vals = np.linspace(df_clean[\"inflation_yoy\"].min(), df_clean[\"inflation_yoy\"].max(), 100)\n",
    "y_vals = intercept + coef * x_vals\n",
    "plt.plot(x_vals, y_vals, color=\"red\", linewidth=2, label=\"Recta de regresión\")\n",
    "\n",
    "# Títulos\n",
    "plt.title(\"Inflación vs US 10Y Yield con regresión lineal\")\n",
    "plt.xlabel(\"Inflación YoY (%)\")\n",
    "plt.ylabel(\"US 10Y Yield (%)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ecuación y el R²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot con recta de regresión y ecuación\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=\"inflation_yoy\", y=\"yield_10y\", data=df_clean, color=\"blue\", label=\"Datos\")\n",
    "\n",
    "# Recta de regresión\n",
    "coef = 0.6571\n",
    "intercept = 3.3783\n",
    "r2 = 0.38  # R-cuadrado de tu modelo\n",
    "x_vals = np.linspace(df_clean[\"inflation_yoy\"].min(), df_clean[\"inflation_yoy\"].max(), 100)\n",
    "y_vals = intercept + coef * x_vals\n",
    "plt.plot(x_vals, y_vals, color=\"red\", linewidth=2, label=\"Recta de regresión\")\n",
    "\n",
    "# Texto con ecuación\n",
    "plt.text(0.05, 0.95,\n",
    "         f\"Yield = {intercept:.2f} + {coef:.2f}*Inflation\\nR² = {r2:.2f}\",\n",
    "         transform=plt.gca().transAxes,\n",
    "         fontsize=12, color=\"red\", verticalalignment=\"top\")\n",
    "\n",
    "# Títulos y etiquetas\n",
    "plt.title(\"Inflación vs US 10Y Yield con regresión lineal\")\n",
    "plt.xlabel(\"Inflación YoY (%)\")\n",
    "plt.ylabel(\"US 10Y Yield (%)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnóstico del modelo (OLS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Recalcular (por si abriste sesión nueva)\n",
    "X = sm.add_constant(df_clean[[\"inflation_yoy\"]])\n",
    "y = df_clean[\"yield_10y\"]\n",
    "model_clean = sm.OLS(y, X).fit()\n",
    "\n",
    "# 2) Residuales y ajustados\n",
    "fitted = model_clean.fittedvalues\n",
    "resid   = model_clean.resid\n",
    "std_res = (resid - resid.mean()) / resid.std(ddof=1)\n",
    "\n",
    "# 3) Plots básicos\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.scatter(fitted, resid, alpha=0.8)\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.xlabel(\"Fitted (predichos)\")\n",
    "plt.ylabel(\"Residuos\")\n",
    "plt.title(\"Residuos vs Predichos\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(resid, bins=12, edgecolor=\"k\", alpha=0.8)\n",
    "plt.title(\"Histograma de residuos\")\n",
    "plt.xlabel(\"Residuo\"); plt.ylabel(\"Frecuencia\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "sm.qqplot(resid, line=\"s\")\n",
    "plt.title(\"QQ-plot de residuos\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Residuos a lo largo del tiempo (para ver autocorrelación visual)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df_clean[\"Year\"], resid, marker=\"o\")\n",
    "plt.axhline(0, linestyle=\"--\")\n",
    "plt.title(\"Residuos en el tiempo\")\n",
    "plt.xlabel(\"Año\"); plt.ylabel(\"Residuo\")\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# 4) Tests estadísticos\n",
    "print(\"\\n--- Tests de diagnóstico ---\")\n",
    "\n",
    "# Normalidad (Jarque–Bera)\n",
    "try:\n",
    "    # statsmodels siempre devuelve (jb, pvalue, skew, kurtosis)\n",
    "    jb_stat, jb_p, jb_skew, jb_kurt = sm_jb(resid)\n",
    "except Exception:\n",
    "    # fallback: SciPy (puede devolver solo 2 valores)\n",
    "    jb = stats.jarque_bera(resid)\n",
    "    if hasattr(jb, \"__len__\") and len(jb) >= 2:\n",
    "        jb_stat, jb_p = jb[0], jb[1]\n",
    "        jb_skew = jb_kurt = float(\"nan\")\n",
    "    else:\n",
    "        jb_stat = float(jb)\n",
    "        jb_p = float(\"nan\")\n",
    "        jb_skew = jb_kurt = float(\"nan\")\n",
    "print(f\"Jarque-Bera: stat={jb_stat:.3f}, p-value={jb_p:.4f}  (skew={jb_skew:.3f}, kurt={jb_kurt:.3f})\")\n",
    "\n",
    "# Heterocedasticidad (Breusch–Pagan)\n",
    "bp_stat, bp_p, _, _ = het_breuschpagan(resid, X)\n",
    "print(f\"Breusch-Pagan: stat={bp_stat:.3f}, p-value={bp_p:.4f}\")\n",
    "\n",
    "# Autocorrelación en residuos (Ljung–Box)\n",
    "lb = acorr_ljungbox(resid, lags=[1, 4, 8, 12], return_df=True)\n",
    "print(\"\\nLjung-Box (p-values):\")\n",
    "print(lb[\"lb_pvalue\"].rename(index={1:\"lag1\",4:\"lag4\",8:\"lag8\",12:\"lag12\"}))\n",
    "\n",
    "# Durbin–Watson\n",
    "print(f\"\\nDurbin-Watson: {durbin_watson(resid):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Normalidad de los residuos (Jarque–Bera)\n",
    "\n",
    "JB = 3.936, p-value = 0.1397\n",
    "\n",
    "Como p > 0.05 → no rechazamos la hipótesis nula de normalidad.\n",
    "✅ Los residuos son aproximadamente normales → buen síntoma.\n",
    "\n",
    "2. Heterocedasticidad (Breusch–Pagan)\n",
    "\n",
    "BP = 1.790, p-value = 0.1809\n",
    "\n",
    "Como p > 0.05 → no hay evidencia fuerte de heterocedasticidad.\n",
    "✅ La varianza de los errores parece estable → los errores estándar son confiables.\n",
    "\n",
    "3. Autocorrelación (Ljung–Box + Durbin-Watson)\n",
    "\n",
    "Ljung–Box:\n",
    "\n",
    "lag1, lag4, lag8, lag12 → p-values casi cero → rechazamos la hipótesis de “no autocorrelación”.\n",
    "❌ Hay autocorrelación muy fuerte en los residuos.\n",
    "\n",
    "Durbin–Watson = 0.227\n",
    "\n",
    "Valores cercanos a 2 = no autocorrelación.\n",
    "\n",
    "Valores < 1 = fuerte autocorrelación positiva.\n",
    "\n",
    "Aquí 0.227 → autocorrelación positiva extrema.\n",
    "\n",
    "#### En resumen:\n",
    "\n",
    "Normalidad: bien.\n",
    "\n",
    "Homocedasticidad: bien.\n",
    "\n",
    "Autocorrelación: muy mal → el modelo lineal clásico OLS no captura la dinámica temporal.\n",
    "\n",
    "👉 Esto significa que tu modelo simple (Yield ~ Inflación) ignora la dependencia temporal. Los rendimientos de bonos son series temporales, por eso los residuos siguen un patrón."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reestimación con errores robustos HAC (Newey-West)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = sm.add_constant(df_clean[[\"inflation_yoy\"]])\n",
    "y = df_clean[\"yield_10y\"]\n",
    "\n",
    "# Modelo OLS\n",
    "ols_model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Ajuste con errores robustos HAC (Newey-West)\n",
    "# lag=4 (aprox. autocorrelación hasta 4 rezagos, puedes probar otros valores)\n",
    "nw_model = ols_model.get_robustcov_results(cov_type=\"HAC\", maxlags=4)\n",
    "\n",
    "print(\"\\n--- Regresión OLS con errores HAC (Newey-West) ---\")\n",
    "print(nw_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "#### 👉 ¿Qué cambió con HAC?\n",
    "\n",
    "Coeficientes (constante = 3.37, inflación = 0.65) → no cambiaron, porque la relación base sigue siendo la misma.\n",
    "\n",
    "Errores estándar (y por tanto t-stats y p-values) → son más grandes que antes (ej. la constante pasó de std=0.51 a 0.69).\n",
    "\n",
    "Pero siguen siendo muy significativos (p<0.001) → conclusión: la relación inflación → yield sigue siendo estadísticamente fuerte.\n",
    "\n",
    "Ahora los intervalos de confianza son más realistas, porque tienen en cuenta la autocorrelación.\n",
    "\n",
    "✅ En resumen: ya tienemos un modelo lineal robusto que muestra que por cada +1% de inflación, el rendimiento a 10 años sube ~0.65% en promedio, con bastante confianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo VAR (Yield + Inflación)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Selección de variables\n",
    "var_data = df_clean[[\"yield_10y\", \"inflation_yoy\"]].dropna()\n",
    "\n",
    "# Crear el modelo VAR\n",
    "model_var = VAR(var_data)\n",
    "\n",
    "# Selección de número óptimo de rezagos (lags)\n",
    "lag_order = model_var.select_order(maxlags=8)\n",
    "print(\"\\n--- Selección de rezagos óptimos ---\")\n",
    "print(lag_order.summary())\n",
    "\n",
    "# Ajustar el VAR con el lag óptimo (ejemplo: AIC)\n",
    "best_lag = lag_order.aic\n",
    "results_var = model_var.fit(best_lag)\n",
    "\n",
    "print(\"\\n--- Resumen VAR ---\")\n",
    "print(results_var.summary())\n",
    "\n",
    "# Pronóstico 5 años adelante\n",
    "forecast = results_var.forecast(var_data.values[-best_lag:], steps=5)\n",
    "forecast_df = pd.DataFrame(forecast, \n",
    "                           columns=[\"yield_10y_forecast\", \"inflation_forecast\"],\n",
    "                           index=range(df_clean[\"Year\"].max()+1, df_clean[\"Year\"].max()+6))\n",
    "\n",
    "print(\"\\n--- Pronóstico 5 años ---\")\n",
    "print(forecast_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Selección de rezagos\n",
    "\n",
    "AIC → lag 3 (destacado con *).\n",
    "\n",
    "Esto significa que tanto yield como inflación se explican mejor mirando los últimos 3 años de historia.\n",
    "\n",
    "Tiene sentido: los efectos de la inflación en los bonos no son inmediatos, tardan algunos años en reflejarse.\n",
    "\n",
    "#### 2. Resultados del VAR\n",
    "\n",
    "En el resumen VAR, cada ecuación muestra cómo una variable depende de sus propios rezagos y de los rezagos de la otra variable.\n",
    "\n",
    "Ejemplo interpretativo (simplificado):\n",
    "\n",
    "yield_10y depende positivamente de la inflación rezagada → confirma que inflación alta hoy tiende a subir los rendimientos en 1–3 años.\n",
    "\n",
    "inflation_yoy también puede mostrar influencia de yield_10y pasado (aunque más débil), porque tipos de interés altos suelen enfriar la inflación.\n",
    "\n",
    "#### 3. Pronóstico (forecast)\n",
    "\n",
    "El modelo te dio predicciones para 5 años:\n",
    "\n",
    "### Año\tYield 10y (%)\tInflación (%)\n",
    "2024\t~4.74\t~6.44\n",
    "\n",
    "2025\t~5.21\t~6.03\n",
    "\n",
    "2026\t~5.86\t~6.39\n",
    "\n",
    "2027\t~6.43\t~6.52\n",
    "\n",
    "2028\t(seguiría creciendo en línea)\t\n",
    "\n",
    "#### Interpretación rápida:\n",
    "El modelo cree que si la dinámica histórica se mantiene:\n",
    "\n",
    "Los rendimientos del 10 años subirían de ~4.7% a ~6.4% en 3 años.\n",
    "\n",
    "La inflación se mantendría alrededor de 6% → persistente, no se reduce rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gráfico histórico + forecast VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datos históricos\n",
    "hist_years = df_clean[\"Year\"]\n",
    "hist_yield = df_clean[\"yield_10y\"]\n",
    "hist_infl = df_clean[\"inflation_yoy\"]\n",
    "\n",
    "# Forecast del VAR (lo que ya calculamos antes)\n",
    "forecast_df.index.name = \"Year\"\n",
    "\n",
    "# Unimos histórico + forecast\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "# Yield\n",
    "plt.plot(hist_years, hist_yield, label=\"Yield 10y (histórico)\", color=\"blue\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"yield_10y_forecast\"], \n",
    "         label=\"Yield 10y (forecast VAR)\", color=\"blue\", linestyle=\"--\")\n",
    "\n",
    "# Inflación\n",
    "plt.plot(hist_years, hist_infl, label=\"Inflación YoY (histórico)\", color=\"red\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"inflation_forecast\"], \n",
    "         label=\"Inflación YoY (forecast VAR)\", color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.axvline(x=2024, color=\"gray\", linestyle=\"--\", alpha=0.6)  # separación entre histórico y forecast\n",
    "plt.title(\"Evolución y Forecast (VAR) - Yield 10y vs Inflación\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación del primer gráfico (Histórico + Forecast VAR)\n",
    "\n",
    "Lo que vemos en azul (Yield 10 años)\n",
    "\n",
    "La línea azul continua: es la evolución histórica del rendimiento de los bonos del Tesoro a 10 años (yield).\n",
    "\n",
    "La línea azul discontinua: es la predicción del modelo VAR para los próximos años.\n",
    "\n",
    "Observamos que el yield tuvo picos muy altos en los 70–80 (crisis de inflación) y luego una tendencia descendente hasta mínimos recientes.\n",
    "\n",
    "El forecast proyecta un ligero repunte del yield, lo que indica que los tipos de interés reales podrían subir en el futuro.\n",
    "\n",
    "Lo que vemos en rojo (Inflación YoY)\n",
    "\n",
    "La línea roja continua: es la inflación histórica. Destacan los picos en los años 70 (shocks petroleros) y el repunte fuerte en 2021–2022.\n",
    "\n",
    "La línea roja discontinua: es la predicción del VAR. Muestra que la inflación podría bajar desde los picos recientes, pero aún mantenerse algo elevada comparada con los 2010s.\n",
    "\n",
    "Interpretación conjunta\n",
    "\n",
    "El modelo VAR nos dice que yield e inflación están claramente relacionadas en el tiempo: cuando sube la inflación, el yield tiende a subir después (los inversores exigen más rentabilidad para compensar la pérdida de poder adquisitivo).\n",
    "\n",
    "La proyección indica un escenario de inflación todavía algo elevada con yields acompañando al alza → típico de un contexto post-crisis inflacionaria.\n",
    "\n",
    "#### En resumen:\n",
    "\n",
    "El gráfico confirma la relación positiva entre inflación y yield.\n",
    "\n",
    "El modelo espera que en los próximos años ambos suban moderadamente, no a niveles extremos como los 70, pero tampoco tan bajos como en los 2010s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  VAR completo: selección de rezagos + ajuste + forecast + IRF\n",
    " Requiere: statsmodels, pandas, matplotlib\n",
    " Usa df_clean con columnas: Year, yield_10y, inflation_yoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Preparar datos para VAR\n",
    "df_var = df_clean[[\"yield_10y\", \"inflation_yoy\"]].dropna().copy()\n",
    "\n",
    "# 1) Selección de rezagos óptimos\n",
    "model_var = VAR(df_var)\n",
    "sel = model_var.select_order(maxlags=8)\n",
    "print(\"\\n--- Selección de rezagos ---\")\n",
    "print(sel.summary())\n",
    "\n",
    "# Tomamos el lag con mejor AIC (puedes cambiar a .bic/.hqic/.fpe si prefieres)\n",
    "best_lag = sel.aic\n",
    "print(f\"\\nLag elegido (AIC): {best_lag}\")\n",
    "\n",
    "# 2) Ajuste del VAR con ese lag\n",
    "var_res = model_var.fit(best_lag)\n",
    "print(\"\\n--- Resumen VAR ---\")\n",
    "print(var_res.summary())\n",
    "\n",
    "# 3) Forecast 5 pasos hacia adelante\n",
    "steps = 5\n",
    "last_year = int(df_clean[\"Year\"].max())\n",
    "fcast = var_res.forecast(df_var.values[-best_lag:], steps=steps)\n",
    "forecast_df = pd.DataFrame(\n",
    "    fcast,\n",
    "    columns=[\"yield_10y_forecast\",\"inflation_forecast\"],\n",
    "    index=range(last_year+1, last_year+1+steps)\n",
    ")\n",
    "forecast_df.index.name = \"Year\"\n",
    "print(\"\\n--- Forecast ---\")\n",
    "print(forecast_df)\n",
    "\n",
    "# 4) Gráfico histórico + forecast (opcional si ya lo tenías)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"yield_10y\"], label=\"Yield 10y (histórico)\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"yield_10y_forecast\"], \"--\", label=\"Yield 10y (forecast VAR)\")\n",
    "plt.plot(df_clean[\"Year\"], df_clean[\"inflation_yoy\"], label=\"Inflación YoY (histórico)\")\n",
    "plt.plot(forecast_df.index, forecast_df[\"inflation_forecast\"], \"--\", label=\"Inflación YoY (forecast VAR)\")\n",
    "plt.axvline(x=last_year, color=\"gray\", linestyle=\"--\", alpha=0.6)\n",
    "plt.title(\"Evolución y Forecast (VAR) - Yield 10y vs Inflación\")\n",
    "plt.xlabel(\"Año\"); plt.ylabel(\"%\"); plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 5) IRF (Impulse Response Functions)\n",
    "irf_h = 10  # horizonte en años\n",
    "irf = var_res.irf(irf_h)\n",
    "\n",
    "# IRF combinadas\n",
    "fig = irf.plot(orth=True)\n",
    "plt.suptitle(\"Funciones de Impulso-Respuesta (IRF)\", fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# IRF específicas (opcional): respuesta de yield a shock de inflación, y viceversa\n",
    "fig = irf.plot_cum_effects(orth=True)\n",
    "plt.suptitle(\"IRF acumuladas (orth)\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Los resultados del modelo VAR muestran que:\n",
    "\n",
    "La inflación impulsa al rendimiento del bono a 10 años, confirmando que mayor inflación esperada eleva los tipos largos.\n",
    "\n",
    "El efecto contrario (yields sobre inflación) existe pero es más débil y menos persistente.\n",
    "\n",
    "Tanto la inflación como los yields presentan persistencia en sus shocks, manteniendo efectos durante varios periodos.\n",
    "\n",
    "El pronóstico VAR anticipa un repunte moderado en ambas variables, con algo más de volatilidad en la inflación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis VAR: Diagnóstico y Extensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Ljung–Box por variable (univariante)\n",
    "for col in var_res.resid.columns:\n",
    "    print(f\"\\nLjung–Box (lags=10) para {col}\")\n",
    "    print(acorr_ljungbox(var_res.resid[col].dropna(), lags=[10], return_df=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Durbin–Watson (otra medida de autocorrelación)\n",
    "dw = durbin_watson(var_res.resid.values)\n",
    "for col, val in zip(var_res.resid.columns, dw):\n",
    "    print(f\"Durbin–Watson {col}: {val:.2f}\")  # ~2 es bueno (sin autocorrelación)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Estabilidad del VAR\n",
    "var_res.is_stable(verbose=True)  # Debe devolver True / raíces dentro del círculo unitario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Heterocedasticidad (ARCH) por variable\n",
    "for col in var_res.resid.columns:\n",
    "    stat, pval, _, _ = het_arch(var_res.resid[col].dropna())\n",
    "    print(f\"ARCH para {col}: p-value = {pval:.4f}\")  # >= 0.05 ⇒ OK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Normalidad conjunta de residuos\n",
    "norm = var_res.test_normality()\n",
    "print(norm.summary())  # p-value alto ⇒ OK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in var_res.resid.columns:\n",
    "    plt.figure(); plot_acf(var_res.resid[col].dropna(), lags=20); plt.title(f\"ACF {col}\")\n",
    "    plt.figure(); plot_pacf(var_res.resid[col].dropna(), lags=20); plt.title(f\"PACF {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretación de los resultados (Punto 3.1)\n",
    "\n",
    "En los gráficos de ACF y PACF:\n",
    "\n",
    "La mayoría de las barras caen dentro de la banda azul (intervalo de confianza).\n",
    "\n",
    "Eso significa que no hay autocorrelación significativa en los residuos.\n",
    "\n",
    "Un modelo VAR bien especificado debe dejar los residuos como “ruido blanco”, y eso es lo que se ve aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Test de autocorrelación alternativa (Durbin–Watson)\n",
    "\n",
    "El estadístico Durbin–Watson verifica la autocorrelación de primer orden.  \n",
    "- Valor cercano a **2** ⇒ sin autocorrelación.  \n",
    "- Valor < 2 ⇒ autocorrelación positiva.  \n",
    "- Valor > 2 ⇒ autocorrelación negativa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw = durbin_watson(var_res.resid.values)\n",
    "for col, val in zip(var_res.resid.columns, dw):\n",
    "    print(f\"Durbin–Watson {col}: {val:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Test de estabilidad del VAR\n",
    "\n",
    "Un VAR estable tiene todas sus raíces dentro del círculo unitario.  \n",
    "Si es **True**, los pronósticos son fiables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_res.is_stable(verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Test de heterocedasticidad (ARCH)\n",
    "\n",
    "El test ARCH evalúa si la varianza de los residuos es constante.  \n",
    "- **p-value ≥ 0.05** ⇒ no hay heterocedasticidad (bien).  \n",
    "- **p-value < 0.05** ⇒ problemas de heterocedasticidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in var_res.resid.columns:\n",
    "    stat, pval, _, _ = het_arch(var_res.resid[col].dropna())\n",
    "    print(f\"ARCH {col}: p-value = {pval:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Test de normalidad de residuos\n",
    "\n",
    "El test de Jarque–Bera verifica si los residuos siguen una distribución normal.  \n",
    "- **p-value ≥ 0.05** ⇒ no rechazamos normalidad (OK).  \n",
    "- **p-value < 0.05** ⇒ residuos no normales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = var_res.test_normality()\n",
    "print(norm.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pronóstico extendido con intervalos de confianza\n",
    "\n",
    "El objetivo es proyectar las series `yield_10y` e `inflation_yoy` varios pasos hacia adelante.\n",
    "Mostramos tanto las predicciones puntuales como las bandas de confianza.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== 4. Pronóstico extendido con intervalos de confianza (VARResults) ====\n",
    "steps = 10  # años a proyectar\n",
    "last_year = int(df_clean[\"Year\"].max())\n",
    "\n",
    "# nº de rezagos que usó el VAR\n",
    "k = var_res.k_ar\n",
    "\n",
    "# Pronóstico: medias y bandas (lower/upper)\n",
    "fcast_mean, fcast_lower, fcast_upper = var_res.forecast_interval(\n",
    "    y=var_res.endog[-k:],  # las últimas k observaciones como estado inicial\n",
    "    steps=steps,\n",
    "    alpha=0.05             # 95% IC\n",
    ")\n",
    "\n",
    "cols = var_res.names  # ['yield_10y','inflation_yoy']\n",
    "\n",
    "# DataFrames ordenados con índice de años futuros\n",
    "idx_future = range(last_year+1, last_year+steps+1)\n",
    "f_mean  = pd.DataFrame(fcast_mean,  index=idx_future, columns=cols)\n",
    "f_lower = pd.DataFrame(fcast_lower, index=idx_future, columns=cols)\n",
    "f_upper = pd.DataFrame(fcast_upper, index=idx_future, columns=cols)\n",
    "\n",
    "print(\"\\n--- Pronóstico extendido (medias) ---\")\n",
    "print(f_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico histórico + forecast con bandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for col in cols:\n",
    "    # histórico\n",
    "    plt.plot(df_clean[\"Year\"], df_clean[col], label=f\"{col} (histórico)\")\n",
    "    # predicción\n",
    "    plt.plot(f_mean.index, f_mean[col], linestyle=\"--\", label=f\"{col} (forecast)\")\n",
    "    # intervalos\n",
    "    plt.fill_between(f_mean.index, f_lower[col], f_upper[col], alpha=0.2)\n",
    "\n",
    "plt.axvline(x=last_year, color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "plt.title(\"Pronóstico extendido VAR con intervalos de confianza (95%)\")\n",
    "plt.xlabel(\"Año\"); plt.ylabel(\"%\"); plt.legend(); plt.grid(True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación rápida:\n",
    "\n",
    "Se observa que el yield_10y tendería a estabilizarse, mientras que la inflación muestra un ligero descenso en el forecast, aunque con bastante incertidumbre (bandas amplias).\n",
    "\n",
    "Esto refleja la lógica: el modelo VAR capta relaciones, pero a largo plazo las predicciones son menos seguras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Descomposición de varianza del error de pronóstico (FEVD)\n",
    "\n",
    "Mide qué porcentaje del error de predicción de cada variable se explica por shocks propios y por la otra variable, a distintos horizontes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 10  # horizonte FEVD\n",
    "fevd = var_res.fevd(steps)\n",
    "\n",
    "# Resumen en texto\n",
    "print(fevd.summary())\n",
    "\n",
    "# Gráfico por variable\n",
    "_ = fevd.plot(figsize=(10,6))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Causalidad de Granger\n",
    "\n",
    "Contrasta si los rezagos de una variable ayudan a predecir a la otra (más allá de sus propios rezagos).\n",
    "- p-value < 0.05 ⇒ Rechazamos “no causa” ⇒ hay causalidad de Granger en esa dirección.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Inflation_yoy causa (Granger) a yield_10y?\n",
    "print(var_res.test_causality('yield_10y', ['inflation_yoy'], kind='f').summary())\n",
    "\n",
    "# ¿Yield_10y causa (Granger) a inflation_yoy?\n",
    "print(var_res.test_causality('inflation_yoy', ['yield_10y'], kind='f').summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Funciones de Impulso-Respuesta (IRF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.1 IRF ortogonalizadas (Cholesky) con bandas de confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizonte (años)\n",
    "h = 10\n",
    "\n",
    "# IRF básicas\n",
    "irf = var_res.irf(h)\n",
    "\n",
    "# Gráfico de IRF ortogonalizadas (Cholesky)\n",
    "fig = irf.plot(orth=True)\n",
    "fig.suptitle(\"IRF ortogonalizadas (Cholesky)\", fontsize=14)\n",
    "\n",
    "# Bandas de confianza por bootstrap Monte Carlo\n",
    "# (repl=1000 si quieres más precisión; tardará más)\n",
    "fig_ci = irf.errband_mc(orth=True, repl=500)  # devuelve fig y ejes con bandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.2 IRF acumuladas (efecto total a lo largo del horizonte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_cum = irf.plot_cum_effects(orth=True)\n",
    "fig_cum.suptitle(\"IRF acumuladas (orth)\", fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.3 Sensibilidad al orden de las variables\n",
    "Cambiar el orden es buena práctica de robustez: primero inflación, luego yield."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-ajustamos el VAR con columnas reordenadas\n",
    "df_alt = df_clean[[\"inflation_yoy\", \"yield_10y\"]].dropna().copy()\n",
    "model_alt = VAR(df_alt)\n",
    "var_res_alt = model_alt.fit(var_res.k_ar)  # usa el mismo nº de rezagos\n",
    "\n",
    "irf_alt = var_res_alt.irf(h)\n",
    "fig_alt = irf_alt.plot(orth=True)\n",
    "fig_alt.suptitle(\"IRF orth con orden alternativo (inflación primero)\", fontsize=14)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.4 Guardar figuras a disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"irf_orth.png\", dpi=150, bbox_inches=\"tight\")\n",
    "fig_cum.savefig(\"irf_cum_orth.png\", dpi=150, bbox_inches=\"tight\")\n",
    "fig_alt.savefig(\"irf_orth_alt_order.png\", dpi=150, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Interpretación Punto 7 (IRFs)\n",
    "\n",
    "Shock inflación → Yield 10Y: impacto fuerte y sostenido, los bonos suben porque el mercado exige más rentabilidad.\n",
    "\n",
    "Shock Yield 10Y → Inflación: efecto débil y pasajero, incluso negativo (tipos altos enfrían la economía).\n",
    "\n",
    "Inflación sobre sí misma: persistente, pero va perdiendo fuerza.\n",
    "\n",
    "Yield sobre sí mismo: se corrige rápido.\n",
    "\n",
    "IRFs acumuladas: confirman que la inflación arrastra a los yields, no al revés.\n",
    "\n",
    "Sensibilidad al orden: los resultados son robustos, no dependen del orden de variables.\n",
    "\n",
    "📌 Conclusión clara:\n",
    "La inflación lidera y los yields siguen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparar el dataset USA para el pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa = (\n",
    "    df_clean[['Year', 'yield_10y', 'inflation_yoy']]\n",
    "      .dropna()\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "df_usa['Year'] = df_usa['Year'].astype(int)\n",
    "df_usa = df_usa.set_index('Year').sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define el pipeline (elige rezagos automáticamente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_country_pipeline_auto(df, country_name, steps=10, maxlags=8, crit=\"aic\"):\n",
    "    \"\"\"\n",
    "    Pipeline VAR completo con selección automática de rezagos.\n",
    "    df: DataFrame con index=Year y columnas ['yield_10y','inflation_yoy']\n",
    "    steps: horizonte de forecast\n",
    "    maxlags: rezago máximo a evaluar\n",
    "    crit: 'aic' | 'bic' | 'hqic' | 'fpe'\n",
    "    \"\"\"\n",
    "    df = df[['yield_10y','inflation_yoy']].dropna().copy()\n",
    "    model = VAR(df)\n",
    "\n",
    "    # 1) Selección de rezagos\n",
    "    sel = model.select_order(maxlags=maxlags)\n",
    "    best_lag = getattr(sel, crit)\n",
    "    print(f\"\\n[{country_name}] Rezagos óptimos por {crit.upper()}: {best_lag}\")\n",
    "\n",
    "    # 2) Ajuste\n",
    "    res = model.fit(best_lag)\n",
    "    print(res.summary())\n",
    "\n",
    "    # 3) Diagnóstico (rápido)\n",
    "    print(\"\\n--- Diagnóstico ---\")\n",
    "    for col in res.resid.columns:\n",
    "        lb = acorr_ljungbox(res.resid[col].dropna(), lags=[10], return_df=True)\n",
    "        print(f\"Ljung-Box {col} (lag=10): p-value={lb['lb_pvalue'].iloc[0]:.4f}\")\n",
    "    dw = durbin_watson(res.resid.values)\n",
    "    for c,v in zip(res.resid.columns, dw):\n",
    "        print(f\"Durbin–Watson {c}: {v:.2f}\")\n",
    "    print(\"Estabilidad:\", res.is_stable(verbose=True))\n",
    "\n",
    "    # 4) Forecast con bandas\n",
    "    k = res.k_ar\n",
    "    mean, low, up = res.forecast_interval(res.endog[-k:], steps=steps, alpha=0.05)\n",
    "    idx_future = range(df.index.max()+1, df.index.max()+1+steps)\n",
    "    f_mean = pd.DataFrame(mean, index=idx_future, columns=res.names)\n",
    "    f_low  = pd.DataFrame(low,  index=idx_future, columns=res.names)\n",
    "    f_up   = pd.DataFrame(up,   index=idx_future, columns=res.names)\n",
    "\n",
    "    plt.figure(figsize=(11,5))\n",
    "    for col in res.names:\n",
    "        plt.plot(df.index, df[col], label=f\"{col} (hist.)\")\n",
    "        plt.plot(f_mean.index, f_mean[col], \"--\", label=f\"{col} (fcst)\")\n",
    "        plt.fill_between(f_mean.index, f_low[col], f_up[col], alpha=0.2)\n",
    "    plt.axvline(df.index.max(), color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.title(f\"{country_name} – Forecast VAR (95% IC)\")\n",
    "    plt.xlabel(\"Año\"); plt.ylabel(\"%\"); plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # 5) FEVD\n",
    "    fevd = res.fevd(steps)\n",
    "    print(\"\\n--- FEVD ---\")\n",
    "    print(fevd.summary())\n",
    "    fevd.plot(figsize=(9,5)); plt.show()\n",
    "\n",
    "    # 6) Granger\n",
    "    print(\"\\n--- Granger ---\")\n",
    "    print(res.test_causality('yield_10y',['inflation_yoy'], kind='f').summary())\n",
    "    print(res.test_causality('inflation_yoy',['yield_10y'], kind='f').summary())\n",
    "\n",
    "    # 7) IRFs (orth y acumuladas)\n",
    "    irf = res.irf(steps)\n",
    "    irf.plot(orth=True); plt.suptitle(f\"{country_name} – IRF orth\"); plt.show()\n",
    "    irf.plot_cum_effects(orth=True); plt.suptitle(f\"{country_name} – IRF acumuladas\"); plt.show()\n",
    "\n",
    "    return res, {\"forecast_mean\": f_mean, \"forecast_low\": f_low, \"forecast_up\": f_up}, fevd, irf, best_lag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecutar el pipeline para USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_results, usa_fcst, usa_fevd, usa_irf, usa_bestlag = run_country_pipeline_auto(\n",
    "    df_usa, country_name=\"USA\", steps=10, maxlags=8, crit=\"aic\"\n",
    ")\n",
    "print(\"Lag elegido (AIC):\", usa_bestlag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detectar la columna 10Y de Alemania en yields.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar si no esta ya en memoria:\n",
    "yields = pd.read_csv(YIELDS_CSV)\n",
    "\n",
    "# columnas 10Y tipo 'US10', 'DE10', etc.\n",
    "ten_cols = [c for c in yields.columns if re.fullmatch(r\"[A-Z]{2}\\d{2}\", c) and c.endswith(\"10\")]\n",
    "print(\"10Y detectadas (primeras 30):\", ten_cols[:30])\n",
    "\n",
    "# Intento automático para Alemania\n",
    "candidatos_de = [c for c in ten_cols if c.startswith((\"DE\",\"GE\",\"BD\",\"GM\"))]\n",
    "print(\"Candidatos Alemania:\", candidatos_de)\n",
    "\n",
    "# Si aparece 'DE10', úsala; si no, toma el primer candidato que salga.\n",
    "col_de = \"DE10\" if \"DE10\" in ten_cols else (candidatos_de[0] if candidatos_de else None)\n",
    "print(\"Columna usada para Alemania 10Y:\", col_de)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anualizar yields USA + Alemania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields_yr = yields.copy()\n",
    "yields_yr['Year'] = pd.to_datetime(yields_yr['time'], unit='ms').dt.year\n",
    "\n",
    "col_us = \"US10\"   # USA 10Y\n",
    "col_de = \"DE10\"   # Alemania 10Y\n",
    "\n",
    "y_ann = (\n",
    "    yields_yr[['Year', col_us, col_de]]\n",
    "      .groupby('Year', as_index=False)\n",
    "      .mean()\n",
    "      .rename(columns={col_us:'yield_10y_US', col_de:'yield_10y_DE'})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflación del Banco Mundial (USA + Alemania)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = pd.read_csv(WORLD_BANK_DATA)\n",
    "\n",
    "wb_small = wb.rename(columns={\n",
    "    'country_name':'Country',\n",
    "    'year':'Year',\n",
    "    'Inflation (CPI %)':'inflation_yoy'\n",
    "})[['Country','Year','inflation_yoy']].dropna()\n",
    "\n",
    "infl_us = wb_small.query(\"Country == 'United States'\")[['Year','inflation_yoy']].rename(columns={'inflation_yoy':'inflation_yoy_US'})\n",
    "infl_de = wb_small.query(\"Country == 'Germany'\")[['Year','inflation_yoy']].rename(columns={'inflation_yoy':'inflation_yoy_DE'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir datasets y lanzar el pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga el CSV de Alemania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) Cargar CSV Alemania desde FRED ===\n",
    "de_raw = pd.read_csv(IRLTLT)\n",
    "\n",
    "# Normalizar columnas\n",
    "de_raw['observation_date'] = pd.to_datetime(de_raw['observation_date'], errors='coerce')\n",
    "de_raw = de_raw.rename(columns={'IRLTLT01DEM156N':'yield_10y'})\n",
    "\n",
    "# === 2) Pasar de mensual → anual (promedio) ===\n",
    "de_annual = de_raw.set_index('observation_date').resample('YE').mean()\n",
    "de_annual.index = de_annual.index.year\n",
    "de_annual.index.name = 'Year'\n",
    "de_annual = de_annual.reset_index()\n",
    "\n",
    "print(\"Alemania yields anuales:\", de_annual['Year'].min(), \"→\", de_annual['Year'].max())\n",
    "display(de_annual.head())\n",
    "\n",
    "# === 3) Inflación Alemania desde World Bank ===\n",
    "wb_small = wb.rename(columns={\n",
    "    'country_name':'Country',\n",
    "    'year':'Year',\n",
    "    'Inflation (CPI %)':'inflation_yoy'\n",
    "})[['Country','Year','inflation_yoy']].dropna()\n",
    "\n",
    "infl_de = wb_small.query(\"Country == 'Germany'\")[['Year','inflation_yoy']]\n",
    "\n",
    "# === 4) Merge yields + inflación ===\n",
    "df_germany = (\n",
    "    de_annual.merge(infl_de, on='Year', how='inner')\n",
    "             .set_index('Year').sort_index()\n",
    ")\n",
    "\n",
    "print(\"Alemania combinado:\", df_germany.index.min(), \"→\", df_germany.index.max())\n",
    "display(df_germany.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alemania: cortar a 2010–2024 y correr el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Alemania 2010–2024 ---\n",
    "df_germany_2010_24 = df_germany.loc[2010:2024].copy()\n",
    "\n",
    "N = len(df_germany_2010_24)\n",
    "safe_maxlags = max(1, min(3, (N - 3)//2))   # con ~15 años suele salir 1–2\n",
    "print(f\"[Germany] N={N} | maxlags sugerido={safe_maxlags}\")\n",
    "\n",
    "de_res, de_fcst, de_fevd, de_irf, de_bestlag = run_country_pipeline_auto(\n",
    "    df_germany_2010_24, country_name=\"Germany (2010–2024)\",\n",
    "    steps=10, maxlags=safe_maxlags, crit=\"aic\"\n",
    ")\n",
    "print(\"Germany (2010–2024) – lag elegido:\", de_bestlag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA: mismo corte 2010–2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_country_pipeline_auto(df, country_name, steps=5, maxlags=2, crit=\"aic\"):\n",
    "    \"\"\"\n",
    "    df: index=Year (int), columnas ['yield_10y','inflation_yoy']\n",
    "    steps: horizonte de forecast\n",
    "    maxlags: rezago máximo permitido (luego se capea automáticamente)\n",
    "    \"\"\"\n",
    "    # 0) Formato y limpieza\n",
    "    df = df[['yield_10y','inflation_yoy']].dropna().copy()\n",
    "    df.index = df.index.astype(int)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # 1) Cálculo de un maxlags seguro según nº de observaciones\n",
    "    N = len(df)\n",
    "    k_endog = df.shape[1]  # 2\n",
    "    safe_max = max(1, min(maxlags, (N - 5)//k_endog))  # cap defensivo\n",
    "    if safe_max < 1:\n",
    "        raise ValueError(f\"Datos insuficientes (N={N}). Reduce rango de años o añade datos.\")\n",
    "    if safe_max < maxlags:\n",
    "        print(f\"[{country_name}] maxlags reducido de {maxlags} a {safe_max} por N={N}\")\n",
    "\n",
    "    # 2) Selección de rezagos y ajuste\n",
    "    model = VAR(df)\n",
    "    sel = model.select_order(maxlags=safe_max)\n",
    "    best_lag = getattr(sel, crit)\n",
    "    if best_lag is None or best_lag < 1:\n",
    "        best_lag = min(1, safe_max)\n",
    "    print(f\"\\n[{country_name}] Rezagos óptimos por {crit.upper()}: {best_lag}\")\n",
    "    res = model.fit(best_lag)\n",
    "    print(res.summary())\n",
    "\n",
    "    # 3) Diagnóstico robusto (Ljung–Box con lag seguro)\n",
    "    print(\"\\n--- Diagnóstico ---\")\n",
    "    nres = len(res.resid)\n",
    "    lb_lag = max(1, min(10, nres - 2, 2*best_lag))  # evita el error por tamaños\n",
    "    for col in res.resid.columns:\n",
    "        if lb_lag >= 1:\n",
    "            lb = acorr_ljungbox(res.resid[col].dropna(), lags=[lb_lag], return_df=True)\n",
    "            print(f\"Ljung-Box {col} (lag={lb_lag}): p={lb['lb_pvalue'].iloc[0]:.4f}\")\n",
    "        else:\n",
    "            print(f\"Ljung-Box {col}: saltado (muy pocas observaciones)\")\n",
    "    dw = durbin_watson(res.resid.values)\n",
    "    for c, v in zip(res.resid.columns, dw):\n",
    "        print(f\"Durbin–Watson {c}: {v:.2f}\")\n",
    "    print(\"Estabilidad:\", res.is_stable(verbose=True))\n",
    "\n",
    "    # 4) Forecast con bandas (95%)\n",
    "    k = res.k_ar\n",
    "    mean, low, up = res.forecast_interval(res.endog[-k:], steps=steps, alpha=0.05)\n",
    "    idx_future = range(df.index.max()+1, df.index.max()+1+steps)\n",
    "    f_mean = pd.DataFrame(mean, index=idx_future, columns=res.names)\n",
    "    f_low  = pd.DataFrame(low,  index=idx_future, columns=res.names)\n",
    "    f_up   = pd.DataFrame(up,   index=idx_future, columns=res.names)\n",
    "\n",
    "    plt.figure(figsize=(11,5))\n",
    "    for col in res.names:\n",
    "        plt.plot(df.index, df[col], label=f\"{col} (hist.)\")\n",
    "        plt.plot(f_mean.index, f_mean[col], \"--\", label=f\"{col} (fcst)\")\n",
    "        plt.fill_between(f_mean.index, f_low[col], f_up[col], alpha=0.2)\n",
    "    plt.axvline(df.index.max(), color=\"gray\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.title(f\"{country_name} – Forecast VAR (95% IC)\")\n",
    "    plt.xlabel(\"Año\"); plt.ylabel(\"%\"); plt.legend(); plt.grid(True); plt.show()\n",
    "\n",
    "    # 5) FEVD\n",
    "    fevd = res.fevd(steps)\n",
    "    print(\"\\n--- FEVD ---\")\n",
    "    print(fevd.summary())\n",
    "    fevd.plot(figsize=(9,5)); plt.show()\n",
    "\n",
    "    # 6) Causalidad de Granger\n",
    "    print(\"\\n--- Granger ---\")\n",
    "    print(res.test_causality('yield_10y', ['inflation_yoy'], kind='f').summary())\n",
    "    print(res.test_causality('inflation_yoy', ['yield_10y'], kind='f').summary())\n",
    "\n",
    "    # 7) IRFs (orth y acumuladas)\n",
    "    irf = res.irf(steps)\n",
    "    irf.plot(orth=True); plt.suptitle(f\"{country_name} – IRF orth\"); plt.show()\n",
    "    irf.plot_cum_effects(orth=True); plt.suptitle(f\"{country_name} – IRF acumuladas\"); plt.show()\n",
    "\n",
    "    return res, {\"forecast_mean\": f_mean, \"forecast_low\": f_low, \"forecast_up\": f_up}, fevd, irf, best_lag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_usa_2010_24     = df_usa.loc[2010:2024].copy()\n",
    "df_germany_2010_24 = df_germany.loc[2010:2024].copy()\n",
    "\n",
    "print(\"USA 2010–2024:\", df_usa_2010_24.index.min(), \"→\", df_usa_2010_24.index.max(), \"| N=\", len(df_usa_2010_24))\n",
    "print(\"DE  2010–2024:\", df_germany_2010_24.index.min(), \"→\", df_germany_2010_24.index.max(), \"| N=\", len(df_germany_2010_24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USA\n",
    "us_res, us_fcst, us_fevd, us_irf, us_bestlag = run_country_pipeline_auto(\n",
    "    df_usa_2010_24, country_name=\"USA (2010–2024)\", steps=5, maxlags=2, crit=\"aic\"\n",
    ")\n",
    "print(\"USA (2010–2024) – lag elegido:\", us_bestlag)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert {'yield_10y','inflation_yoy'}.issubset(df_usa.columns), \"df_usa no tiene las columnas correctas\"\n",
    "df_usa_2010_24 = df_usa.loc[2010:2024].copy()\n",
    "print(\"Rango USA recortado:\", df_usa_2010_24.index.min(), \"→\", df_usa_2010_24.index.max(), \"| N=\", len(df_usa_2010_24))\n",
    "print(df_usa_2010_24.head(), \"\\n\", df_usa_2010_24.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Años disponibles en cada fuente (USA)\n",
    "print(\"Yields USA (y_ann):\", y_ann[['Year','yield_10y_US']].dropna()['Year'].min(), \"→\", y_ann[['Year','yield_10y_US']].dropna()['Year'].max())\n",
    "print(\"Inflación USA (infl_us):\", infl_us['Year'].min(), \"→\", infl_us['Year'].max())\n",
    "\n",
    "# Qué años faltan en cada una dentro de 2010–2024\n",
    "yrs = set(range(2010, 2025))\n",
    "y_ok  = set(y_ann.loc[y_ann['yield_10y_US'].notna(), 'Year'])\n",
    "i_ok  = set(infl_us['Year'])\n",
    "print(\"Faltan en yields:\", sorted(yrs - y_ok))\n",
    "print(\"Faltan en inflación:\", sorted(yrs - i_ok))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anualizar DGS10 y crear Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar CSV DGS10 (tiene columnas: observation_date, DGS10)\n",
    "dgs = pd.read_csv(DGS10)\n",
    "\n",
    "# Limpiar tipos\n",
    "dgs[\"observation_date\"] = pd.to_datetime(dgs[\"observation_date\"], errors=\"coerce\")\n",
    "dgs[\"DGS10\"] = pd.to_numeric(dgs[\"DGS10\"], errors=\"coerce\")\n",
    "dgs = dgs.dropna(subset=[\"observation_date\", \"DGS10\"]).sort_values(\"observation_date\")\n",
    "\n",
    "# Resample anual (promedio) y crear Year de forma explícita\n",
    "dgs_ann = (\n",
    "    dgs.set_index(\"observation_date\")\n",
    "       .resample(\"YE\").mean()                  # promedio anual\n",
    "       .assign(Year=lambda x: x.index.year)    # crear Year desde el índice\n",
    "       .reset_index(drop=True)[[\"Year\", \"DGS10\"]]\n",
    "       .rename(columns={\"DGS10\": \"yield_10y\"})\n",
    ")\n",
    "\n",
    "# Filtrar 2021–2024 (o lo que tengas)\n",
    "dgs_ann = dgs_ann.query(\"Year >= 2021\").copy()\n",
    "\n",
    "print(dgs_ann.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unir con tu serie USA previa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalcular US10 anual (hasta 2020) desde tu yields.csv\n",
    "yields_yr = yields.copy()\n",
    "yields_yr['Year'] = pd.to_datetime(yields_yr['time'], unit='ms').dt.year\n",
    "\n",
    "us10_ann_old = (\n",
    "    yields_yr.groupby('Year')['US10'].mean()\n",
    "             .rename('yield_10y')\n",
    "             .reset_index()\n",
    ")\n",
    "\n",
    "print(\"US10 anualizado (hasta 2020):\")\n",
    "print(us10_ann_old.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us10_ann_old: tu serie histórica hasta 2020 (Year, yield_10y)\n",
    "us10_full = (\n",
    "    pd.concat([us10_ann_old, dgs_ann], ignore_index=True)\n",
    "      .sort_values(\"Year\")\n",
    "      .drop_duplicates(\"Year\", keep=\"last\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(us10_full.tail(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construir df_usa_2010_24 para el VAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegúrate de tener infl_us: (Year, inflation_yoy)\n",
    "df_usa_2010_24 = (\n",
    "    us10_full.merge(infl_us, on=\"Year\", how=\"inner\")\n",
    "             .query(\"Year >= 2010 and Year <= 2024\")\n",
    "             .set_index(\"Year\")\n",
    "             .sort_index()\n",
    "             .dropna()\n",
    ")\n",
    "\n",
    "print(df_usa_2010_24.tail(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USA (2015–2024) – VAR robusto con cap automático de lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa tu DataFrame ya preparado (índice Year, cols: yield_10y, inflation_yoy[_US])\n",
    "df_us = df_usa_2015_24.copy() if 'df_usa_2015_24' in globals() else df_usa_2010_24.loc[2015:2024].copy()\n",
    "if 'inflation_yoy_US' in df_us.columns:\n",
    "    df_us = df_us.rename(columns={'inflation_yoy_US':'inflation_yoy'})\n",
    "df_us = df_us[['yield_10y','inflation_yoy']].dropna().sort_index()\n",
    "df_us.index = df_us.index.astype(int)\n",
    "\n",
    "N, k = len(df_us), 2\n",
    "print(f\"[USA 2015–2024] N={N}\")\n",
    "\n",
    "# --- Selección de rezagos robusta ---\n",
    "# Cap muy prudente con muestras cortas:\n",
    "max_try = max(1, min(2, (N-5)//k))  # con N~10 esto da 1–2\n",
    "best_lag = None\n",
    "last_err = None\n",
    "\n",
    "for p_cap in [max_try, 1]:  # probamos con el cap calculado y, si falla, con 1\n",
    "    try:\n",
    "        sel = VAR(df_us).select_order(maxlags=p_cap)\n",
    "        cand = getattr(sel, 'aic') or 1\n",
    "        cand = int(cand) if cand is not None else 1\n",
    "        cand = max(1, min(cand, p_cap))\n",
    "        res  = VAR(df_us).fit(cand)\n",
    "        best_lag = cand\n",
    "        break\n",
    "    except Exception as e:\n",
    "        last_err = e\n",
    "        continue\n",
    "\n",
    "if best_lag is None:\n",
    "    raise last_err\n",
    "\n",
    "print(f\"Rezago óptimo (AIC, cap={p_cap}): {best_lag}\")\n",
    "print(res.summary())\n",
    "\n",
    "# --- Diagnóstico robusto ---\n",
    "lb_lag = max(1, min(5, N - 2, 2*best_lag))\n",
    "print(\"\\n--- Diagnóstico ---\")\n",
    "for col in res.resid.columns:\n",
    "    lb = acorr_ljungbox(res.resid[col].dropna(), lags=[lb_lag], return_df=True)\n",
    "    print(f\"Ljung-Box {col} (lag={lb_lag})  p={lb['lb_pvalue'].iloc[0]:.3f}\")\n",
    "dw_vals = durbin_watson(res.resid.values)\n",
    "print(\"Durbin–Watson:\", {c: round(dw,2) for c, dw in zip(res.resid.columns, dw_vals)})\n",
    "print(\"Estabilidad:\", res.is_stable(verbose=True))\n",
    "\n",
    "# --- Forecast (5 años, sin IC para N pequeño) ---\n",
    "steps = 5\n",
    "yhat = res.forecast(df_us.values[-best_lag:], steps=steps)\n",
    "years_fc = np.arange(df_us.index.max()+1, df_us.index.max()+steps+1)\n",
    "fc_df = pd.DataFrame(yhat, columns=df_us.columns, index=years_fc)\n",
    "\n",
    "plt.figure(figsize=(11,6))\n",
    "plt.plot(df_us.index, df_us['yield_10y'], label='yield_10y (hist)')\n",
    "plt.plot(df_us.index, df_us['inflation_yoy'], label='inflation_yoy (hist)')\n",
    "plt.plot(fc_df.index, fc_df['yield_10y'], '--', label='yield_10y (fcst)')\n",
    "plt.plot(fc_df.index, fc_df['inflation_yoy'], '--', label='inflation_yoy (fcst)')\n",
    "plt.axvline(x=df_us.index.max(), color='grey', ls='--', alpha=0.6)\n",
    "plt.title('USA (2015–2024) – VAR forecast (5 años)')\n",
    "plt.xlabel('Año'); plt.ylabel('%'); plt.grid(True); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# --- FEVD e IRFs (10 pasos) ---\n",
    "fevd = res.fevd(10); fig = fevd.plot(figsize=(10,6)); fig.suptitle('USA – FEVD (10)'); plt.show()\n",
    "irf = res.irf(10); fig1 = irf.plot(orth=True); fig1.suptitle('USA – IRF (orth)'); plt.show()\n",
    "fig2 = irf.plot_cum_effects(orth=True); fig2.suptitle('USA – IRF acumuladas (orth)'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparativa Alemania vs USA (2010–2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🇩🇪 Alemania\n",
    "\n",
    "Yields 10Y: en mínimos históricos, incluso negativos 2016–2020.\n",
    "\n",
    "Inflación: fuerte repunte desde 2021 por crisis energética y guerra en Ucrania.\n",
    "\n",
    "Relación: shocks de inflación → suben los yields (mercado exige más rentabilidad).\n",
    "\n",
    "#### 🇺🇸 Estados Unidos\n",
    "\n",
    "Yields 10Y: bajan fuerte en 2020 (COVID), suben rápido hasta 2024.\n",
    "\n",
    "Inflación: pico histórico en 2022 (8%) tras pandemia y energía.\n",
    "\n",
    "Relación: inflación explica gran parte de la variabilidad de yields; modelo algo inestable por pocos datos.\n",
    "\n",
    "#### 🔎 Conclusión\n",
    "\n",
    "Inflación lidera, yields siguen en ambos países.\n",
    "\n",
    "Alemania vivió rendimientos negativos (BCE muy expansiva), USA nunca bajó de 0.8% (Fed menos agresiva).\n",
    "\n",
    "Dos respuestas distintas a choques globales, pero misma dirección: más inflación = yields más altos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPAIN (2010–2024) – Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 0) Cargar fuentes si faltan ----------\n",
    "if 'yields' not in globals():\n",
    "    yields = pd.read_csv(YIELDS_CSV)\n",
    "if 'wb' not in globals():\n",
    "    wb = pd.read_csv(WORLD_BANK_DATA)\n",
    "\n",
    "# ---------- 1) Yields 10Y España (ES10) → anual ----------\n",
    "yields_yr = yields.copy()\n",
    "# 'time' suele ser epoch ms en tu fichero\n",
    "yields_yr['Year'] = pd.to_datetime(yields_yr['time'], unit='ms').dt.year\n",
    "\n",
    "if 'ES10' not in yields_yr.columns:\n",
    "    raise RuntimeError(\"No encuentro la columna ES10 en yields.csv\")\n",
    "\n",
    "es10_ann = (yields_yr.groupby('Year')['ES10'].mean()\n",
    "                        .rename('yield_10y')\n",
    "                        .reset_index())\n",
    "\n",
    "# ---------- 2) Inflación España desde World Bank (detección robusta) ----------\n",
    "cols = {c.lower(): c for c in wb.columns}\n",
    "country_col = cols.get('country_name') or cols.get('country') or cols.get('country name')\n",
    "year_col    = cols.get('year') or cols.get('date')\n",
    "\n",
    "if not country_col or not year_col:\n",
    "    raise RuntimeError(\"No encuentro columnas de país/año en el archivo WB. Revisa nombres.\")\n",
    "\n",
    "inflation_candidates = [c for c in wb.columns if \"inflation\" in c.lower() and \"cpi\" in c.lower()]\n",
    "if not inflation_candidates:\n",
    "    raise RuntimeError(\"No encuentro columna de inflación CPI en WB (busqué 'inflation' y 'CPI').\")\n",
    "infl_col = inflation_candidates[0]\n",
    "\n",
    "infl_es = (wb[[country_col, year_col, infl_col]]\n",
    "             .rename(columns={country_col:'Country', year_col:'Year', infl_col:'inflation_yoy'})\n",
    "             .query(\"Country == 'Spain'\")\n",
    "             [['Year','inflation_yoy']]\n",
    "             .dropna())\n",
    "\n",
    "# ---------- 3) Merge + recorte 2010–2024 ----------\n",
    "df_spain = (es10_ann.merge(infl_es, on='Year', how='inner')\n",
    "                    .set_index('Year').sort_index())\n",
    "df_spain_2010_24 = df_spain.loc[2010:2024].dropna().copy()\n",
    "\n",
    "print(\"Spain – rango disponible tras merge:\",\n",
    "      df_spain_2010_24.index.min(), \"→\", df_spain_2010_24.index.max(),\n",
    "      \"| N =\", len(df_spain_2010_24))\n",
    "display(df_spain_2010_24.tail())\n",
    "\n",
    "# ---------- 4) Ejecutar VAR (parámetros prudentes para N~10–15) ----------\n",
    "sp_res, sp_fcst, sp_fevd, sp_irf, sp_bestlag = run_country_pipeline_auto(\n",
    "    df_spain_2010_24, country_name=\"Spain (2010–2024)\", steps=5, maxlags=2, crit=\"aic\"\n",
    ")\n",
    "print(\"Spain (2010–2024) – rezagos elegidos (AIC):\", sp_bestlag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yield_10y → inflation_yoy (izquierda):\n",
    "\n",
    "Un shock positivo en los rendimientos de 10 años genera un aumento inicial de la inflación, que se estabiliza después de 3 años.\n",
    "\n",
    "La respuesta es moderada y se disipa rápido.\n",
    "\n",
    "Eso sugiere que los tipos largos tienen poca capacidad de traspaso directo a la inflación en España en este periodo.\n",
    "\n",
    "inflation_yoy → inflation_yoy (derecha):\n",
    "\n",
    "Un shock de inflación tiende a persistir 2–3 años, con efecto negativo moderado y luego recuperación.\n",
    "\n",
    "En otras palabras, los shocks inflacionarios en España no son totalmente transitorios, pero tampoco se vuelven explosivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 📌 Conclusión rápida (España 2010–2024):\n",
    "\n",
    "Los tipos largos no causan fuertemente la inflación (apoyo a lo visto en Granger).\n",
    "\n",
    "La inflación sí muestra cierta dinámica propia (persistencia).\n",
    "\n",
    "El sistema (VAR) es estable y razonablemente predecible en el corto plazo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reino Unido 🇬🇧"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Verificar columnas de yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yields.columns.tolist())\n",
    "print(yields.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si el índice ya es el año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yields = yields.reset_index().rename(columns={'index':'Year'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Reino Unido ===\n",
    "\n",
    "# 1) Rendimientos 10Y (UK)\n",
    "y_uk = (\n",
    "    yields[['Year','GB10']]\n",
    "    .rename(columns={'GB10':'yield_10y_UK'})\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "# 2) Inflación UK\n",
    "infl_uk = (\n",
    "    wb_small.query(\"Country == 'United Kingdom'\")\n",
    "    [['Year','inflation_yoy']]\n",
    "    .rename(columns={'inflation_yoy':'inflation_yoy_UK'})\n",
    ")\n",
    "\n",
    "# 3) Merge\n",
    "df_uk = (\n",
    "    y_uk.merge(infl_uk, on='Year', how='inner')\n",
    "         .rename(columns={'yield_10y_UK':'yield_10y',\n",
    "                          'inflation_yoy_UK':'inflation_yoy'})\n",
    "         .set_index('Year').sort_index()\n",
    ")\n",
    "\n",
    "# Filtrar rango 2010–2024\n",
    "df_uk = df_uk.loc[2010:2024]\n",
    "\n",
    "print(\"UK rango disponible:\", df_uk.index.min(), \"→\", df_uk.index.max(), \"| N=\", len(df_uk))\n",
    "display(df_uk.tail())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corre el VAR y genera gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reino Unido: VAR 2010–2024 ---\n",
    "uk_res, uk_fcst, uk_fevd, uk_irf, uk_bestlag = run_country_pipeline_auto(\n",
    "    df_uk, country_name=\"UK (2010–2024)\", steps=5, maxlags=2, crit=\"aic\"\n",
    ")\n",
    "print(\"UK – rezago elegido (AIC):\", uk_bestlag)\n",
    "\n",
    "# (opcional) guardar figuras si tu función las pinta\n",
    "plt.savefig(\"uk_irf_orth.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reino Unido – Resultados VAR (2010–2024)\n",
    "\n",
    "Datos disponibles:\n",
    "\n",
    "Rendimiento 10 años (yield_10y_UK) y inflación anual (inflation_yoy).\n",
    "\n",
    "Rango: 2010–2024 → 15 observaciones.\n",
    "\n",
    "VAR estimado:\n",
    "\n",
    "Rezagos óptimos: 2 (AIC).\n",
    "\n",
    "El sistema es estable (no explota).\n",
    "\n",
    "Forecast (2025–2029):\n",
    "\n",
    "Los rendimientos 10Y se mantienen estables en torno a 3.5–4%.\n",
    "\n",
    "La inflación muestra tendencia moderada: repunte hacia ~3% pero con intervalos amplios (incertidumbre alta).\n",
    "\n",
    "Descomposición de varianza (FEVD):\n",
    "\n",
    "Los yields dependen principalmente de sí mismos (>90%).\n",
    "\n",
    "La inflación también es mayormente explicada por sí misma (>80–90%), con poca influencia de los rendimientos.\n",
    "\n",
    "Causalidad de Granger:\n",
    "\n",
    "No hay evidencia de causalidad significativa (p-valores > 0.1).\n",
    "\n",
    "Es decir: ni la inflación predice claramente los rendimientos, ni al revés.\n",
    "\n",
    "Respuestas a impulsos (IRF):\n",
    "\n",
    "Un shock en los rendimientos tiene efecto muy leve sobre inflación (positivo al inicio, se disipa).\n",
    "\n",
    "Un shock en la inflación apenas impacta los rendimientos, incluso con respuestas negativas pequeñas.\n",
    "\n",
    "#### Conclusión corta (UK):\n",
    "En Reino Unido, los rendimientos a 10 años son bastante autónomos y siguen su propia dinámica. La inflación influye muy poco y no hay relación causal fuerte entre ambas variables. El modelo proyecta estabilidad en yields y una inflación moderada, aunque con mucha incertidumbre tras 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Japón 🇯🇵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Rendimientos 10Y (JP)\n",
    "y_jp = (\n",
    "    yields[['JP10']]\n",
    "    .rename(columns={'JP10':'yield_10y'})\n",
    "    .dropna()\n",
    ")\n",
    "y_jp.index.name = \"Year\"\n",
    "\n",
    "# 2) Inflación Japón\n",
    "infl_jp = (\n",
    "    wb_small.query(\"Country == 'Japan'\")\n",
    "    [['Year','inflation_yoy']]\n",
    "    .set_index(\"Year\")\n",
    ")\n",
    "\n",
    "# 3) Merge de las dos series\n",
    "df_jp = (\n",
    "    y_jp.join(infl_jp, how=\"inner\")\n",
    "    .rename(columns={'inflation_yoy':'inflation_yoy'})\n",
    ")\n",
    "\n",
    "# 4) Recorte 2010–2024\n",
    "df_jp = df_jp.loc[2010:2024]\n",
    "\n",
    "print(\"JP rango disponible:\", df_jp.index.min(), \"-\", df_jp.index.max(), \"| N=\", len(df_jp))\n",
    "display(df_jp.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === JAPÓN – VAR completo y robusto (crea res_jp y hace forecast con bandas) ===\n",
    "# 0) Asegurar formato\n",
    "df_jp = df_jp[['yield_10y','inflation_yoy']].dropna().copy()\n",
    "df_jp.index = df_jp.index.astype(int)\n",
    "df_jp = df_jp.sort_index().loc[2010:2024]\n",
    "N = len(df_jp)\n",
    "print(f\"[JP] N={N} | años {df_jp.index.min()}–{df_jp.index.max()}\")\n",
    "\n",
    "# 1) Selección de rezagos robusta (cap descendente)\n",
    "model_jp = VAR(df_jp)\n",
    "safe_p = None\n",
    "for cap in [4,3,2,1]:\n",
    "    try:\n",
    "        sel = model_jp.select_order(cap)\n",
    "        p = sel.aic if sel.aic is not None else 1\n",
    "        p = int(max(1, min(p, cap)))\n",
    "        res_jp = model_jp.fit(p)\n",
    "        safe_p = p\n",
    "        print(f\"Rezago elegido (AIC dentro de cap={cap}): p={p}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"cap={cap} no estimable → {e}\")\n",
    "\n",
    "if safe_p is None:\n",
    "    # última red\n",
    "    safe_p = 1\n",
    "    res_jp = model_jp.fit(safe_p)\n",
    "    print(\"Forzado p=1\")\n",
    "\n",
    "print(res_jp.summary())\n",
    "print(\"Estabilidad VAR:\", res_jp.is_stable())\n",
    "\n",
    "# 2) Forecast con bandas (5 años)\n",
    "steps = 5\n",
    "p = res_jp.k_ar\n",
    "last_Y = df_jp.values[-p:]                       # condiciones iniciales\n",
    "fc_mean, fc_lo, fc_hi = res_jp.forecast_interval(last_Y, steps=steps, alpha=0.05)\n",
    "\n",
    "start = int(df_jp.index.max()) + 1\n",
    "idx_fc = np.arange(start, start + steps)\n",
    "\n",
    "fc = pd.DataFrame(fc_mean, index=idx_fc, columns=df_jp.columns)\n",
    "lo = pd.DataFrame(fc_lo,   index=idx_fc, columns=df_jp.columns).add_suffix('_lo')\n",
    "hi = pd.DataFrame(fc_hi,   index=idx_fc, columns=df_jp.columns).add_suffix('_hi')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "df_jp[['yield_10y','inflation_yoy']].plot(ax=ax)\n",
    "ax.plot(fc.index, fc['yield_10y'], '--', label='yield_10y (fcst)')\n",
    "ax.fill_between(fc.index, lo['yield_10y_lo'], hi['yield_10y_hi'], alpha=0.2)\n",
    "ax.plot(fc.index, fc['inflation_yoy'], '--', label='inflation_yoy (fcst)')\n",
    "ax.fill_between(fc.index, lo['inflation_yoy_lo'], hi['inflation_yoy_hi'], alpha=0.2)\n",
    "ax.axvline(df_jp.index.max(), ls='--', color='gray', alpha=0.6)\n",
    "ax.set_title(f\"Japón (2010–{df_jp.index.max()}) – VAR forecast ({steps} años)\")\n",
    "ax.set_ylabel('%'); ax.grid(True); ax.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "# 3) FEVD, Granger e IRFs\n",
    "fevd = res_jp.fevd(10); print(fevd.summary()); fevd.plot(figsize=(9,5)); plt.show()\n",
    "print(res_jp.test_causality('yield_10y', ['inflation_yoy'], kind='f').summary())\n",
    "print(res_jp.test_causality('inflation_yoy', ['yield_10y'], kind='f').summary())\n",
    "irf = res_jp.irf(10); irf.plot(orth=True); plt.show(); irf.plot_cum_effects(orth=True); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados clave\n",
    "\n",
    "Orden elegido (AIC): 4 → El modelo usa hasta 4 rezagos para explicar la dinámica.\n",
    "\n",
    "Estabilidad VAR: False → 🚨 Esto significa que el sistema no cumple la condición de estabilidad (al menos una raíz característica >1).\n",
    "En la práctica → el forecast es válido pero menos fiable, las bandas de error se disparan (como ves en la zona naranja).\n",
    "\n",
    "### Interpretación del gráfico\n",
    "\n",
    "Yield 10 años (línea azul)\n",
    "\n",
    "Históricamente muy estable (alrededor del 1.5%–2%).\n",
    "\n",
    "El forecast (línea verde discontinua) se mantiene casi plano, con poca variación.\n",
    "\n",
    "→ El VAR refleja que Japón no tiene grandes movimientos en tipos largos.\n",
    "\n",
    "Inflación interanual (línea naranja)\n",
    "\n",
    "Mucha más volatilidad en la historia reciente (negativa en 2020, picos altos tras 2022).\n",
    "\n",
    "El forecast (línea roja discontinua) muestra un rebote hacia arriba, con alta incertidumbre (bandas muy anchas).\n",
    "\n",
    "→ Esto refleja que la inflación en Japón es muy difícil de prever con pocos datos.\n",
    "\n",
    "### Conclusión corta para Japón\n",
    "\n",
    "Los rendimientos a 10 años son muy estables, con pronóstico casi plano.\n",
    "\n",
    "La inflación es altamente incierta, y el VAR la proyecta con posible aumento, pero con gran varianza.\n",
    "\n",
    "La falta de estabilidad estadística sugiere que el modelo podría necesitar:\n",
    "\n",
    "Más años de datos, o\n",
    "\n",
    "Incluir más variables (ej. PIB, política monetaria, tipo de cambio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🇩🇪 Alemania\n",
    "\n",
    "Datos completos y estables.\n",
    "\n",
    "Rendimientos y tipos muestran relación moderada.\n",
    "\n",
    "Inflación relativamente contenida, forecast razonable.\n",
    "\n",
    "## 🇺🇸 Estados Unidos\n",
    "\n",
    "Serie más larga y robusta.\n",
    "\n",
    "VAR bien estimado con lags pequeños.\n",
    "\n",
    "Forecast estable: yields suben suavemente, inflación más volátil pero con señal clara.\n",
    "\n",
    "## 🇪🇸 España\n",
    "\n",
    "Serie corta pero consistente.\n",
    "\n",
    "Rendimientos bajando tras 2010, inflación moderada.\n",
    "\n",
    "Forecast: yields ligeramente al alza, inflación estable con bandas amplias.\n",
    "\n",
    "## 🇬🇧 Reino Unido\n",
    "\n",
    "Datos completos, VAR estable.\n",
    "\n",
    "Rendimientos estables en torno a 4–5%.\n",
    "\n",
    "Inflación muy volátil (pico 2022), forecast muestra normalización pero con incertidumbre.\n",
    "\n",
    "🇯🇵 Japón\n",
    "\n",
    "Serie con 15 observaciones → pocos datos.\n",
    "\n",
    "Rendimientos extremadamente estables (1–2%).\n",
    "\n",
    "Inflación impredecible: forecast incierto, modelo inestable.\n",
    "\n",
    "Conclusión: se necesitan más variables para mejorar.\n",
    "\n",
    "## 📌 Conclusión general\n",
    "\n",
    "Robustos: USA y Alemania (mejor calidad de forecast).\n",
    "\n",
    "Interesantes para comparar: UK y España (muestran volatilidad post-crisis e inflación reciente).\n",
    "\n",
    "Frágil: Japón (modelo inestable, forecast poco fiable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ML Utilities (usamos para todos los países) ===\n",
    "\n",
    "# 1) Dataset supervisado: lags como features\n",
    "def make_supervised(df, lags=3, h=1, target='yield_10y'):\n",
    "    Xy = df.copy()\n",
    "    for L in range(1, lags+1):\n",
    "        Xy[f'yield_lag{L}'] = Xy['yield_10y'].shift(L)\n",
    "        Xy[f'infl_lag{L}']  = Xy['inflation_yoy'].shift(L)\n",
    "    Xy['target'] = Xy[target].shift(-h)\n",
    "    return Xy.dropna()\n",
    "\n",
    "# 2) Expanding backtest con un modelo sklearn\n",
    "def expanding_backtest(df, model, lags=3, h=1, test_start=2018):\n",
    "    Xy = make_supervised(df, lags=lags, h=h)\n",
    "    preds, trues, years = [], [], []\n",
    "    for yr in Xy.index:\n",
    "        if yr < test_start: \n",
    "            continue\n",
    "        train = Xy.loc[Xy.index < yr]\n",
    "        test  = Xy.loc[[yr]]\n",
    "        if len(train) < 6: \n",
    "            continue\n",
    "        X_tr, y_tr = train.drop(columns=['target']), train['target']\n",
    "        X_te, y_te = test.drop(columns=['target']), test['target'].iloc[0]\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_hat = model.predict(X_te)[0]\n",
    "        preds.append(y_hat); trues.append(y_te); years.append(int(yr))\n",
    "    return pd.DataFrame({'Year': years, 'y_true': trues, 'y_pred': preds}).set_index('Year')\n",
    "\n",
    "# 3) Baseline naive\n",
    "def naive_forecast(df, h=1, start_year=2018):\n",
    "    target = df['yield_10y'].shift(-h)\n",
    "    naive  = df['yield_10y']\n",
    "    out = pd.DataFrame({'y_true': target, 'y_pred': naive}).dropna()\n",
    "    return out.loc[out.index >= start_year]\n",
    "\n",
    "# 4) VAR baseline\n",
    "def var_recursive_forecast(df, h=1, start_year=2018, maxlags=3):\n",
    "    preds, trues, years = [], [], []\n",
    "    for yr in range(start_year, int(df.index.max())+1):\n",
    "        train = df.loc[df.index < yr]\n",
    "        if len(train) < 6:\n",
    "            continue\n",
    "        safe = max(1, min(maxlags, (len(train)-3)//2))\n",
    "        try:\n",
    "            res = VAR(train).fit(ic='aic', maxlags=safe)\n",
    "            y_hat = res.forecast(res.y, steps=1)[0][0]\n",
    "            preds.append(y_hat)\n",
    "            trues.append(df.loc[yr,'yield_10y'])\n",
    "            years.append(yr)\n",
    "        except Exception as e:\n",
    "            print(f\"skip {yr}: {e}\")\n",
    "            continue\n",
    "    return pd.DataFrame({'Year': years, 'y_true': trues, 'y_pred': preds}).set_index('Year')\n",
    "\n",
    "# 5) Métricas\n",
    "def eval_metrics(df_pred):\n",
    "    mae = mean_absolute_error(df_pred['y_true'], df_pred['y_pred'])\n",
    "    rmse = sqrt(mean_squared_error(df_pred['y_true'], df_pred['y_pred']))\n",
    "    return mae, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ML para USA ===\n",
    "TEST_START = 2018\n",
    "\n",
    "dfc = df_us[['yield_10y','inflation_yoy']].dropna().copy()\n",
    "dfc.index = dfc.index.astype(int)\n",
    "\n",
    "# Baseline Naive\n",
    "p_naive = naive_forecast(dfc, h=1, start_year=TEST_START)\n",
    "m_naive = eval_metrics(p_naive)\n",
    "\n",
    "# VAR baseline\n",
    "p_var = var_recursive_forecast(dfc, h=1, start_year=TEST_START, maxlags=3)\n",
    "m_var = eval_metrics(p_var)\n",
    "\n",
    "# ElasticNet\n",
    "enet = ElasticNetCV(l1_ratio=[0.1,0.5,0.9], cv=3, max_iter=20000)\n",
    "p_en  = expanding_backtest(dfc, enet, lags=3, h=1, test_start=TEST_START)\n",
    "m_en  = eval_metrics(p_en)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "p_rf = expanding_backtest(dfc, rf, lags=3, h=1, test_start=TEST_START)\n",
    "m_rf = eval_metrics(p_rf)\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingRegressor(random_state=42)\n",
    "p_gb = expanding_backtest(dfc, gb, lags=3, h=1, test_start=TEST_START)\n",
    "m_gb = eval_metrics(p_gb)\n",
    "\n",
    "# Tabla resumen USA\n",
    "usa_results = pd.DataFrame([\n",
    "    ['Naive', *m_naive],\n",
    "    ['VAR', *m_var],\n",
    "    ['ElasticNet', *m_en],\n",
    "    ['RandomForest', *m_rf],\n",
    "    ['GradientBoosting', *m_gb],\n",
    "], columns=['Model','MAE','RMSE'])\n",
    "\n",
    "usa_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.tail())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset con las variables relevantes\n",
    "dfc = df[['yield_10y', 'inflation_yoy']].dropna().copy()\n",
    "dfc.index = dfc['Year'].astype(int)   # Usar el año como índice\n",
    "\n",
    "# Probar naive forecast\n",
    "p_naive = naive_forecast(dfc, h=1, start_year=2018)\n",
    "\n",
    "print(p_naive.head())\n",
    "print(p_naive.tail())\n",
    "print(\"Shape:\", p_naive.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BLOQUE ML ROBUSTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- utilidades ----------\n",
    "def make_supervised(df, lags=1):\n",
    "    \"\"\"\n",
    "    Construye X,y con rezagos de yield_10y e inflation_yoy.\n",
    "    y = yield_10y_t ; X = [yield_10y_{t-1..t-l}, infl_{t-1..t-l}]\n",
    "    \"\"\"\n",
    "    work = df.copy()\n",
    "    cols = []\n",
    "    for k in range(1, lags+1):\n",
    "        for c in ['yield_10y','inflation_yoy']:\n",
    "            name = f\"{c}_lag{k}\"\n",
    "            work[name] = work[c].shift(k)\n",
    "            cols.append(name)\n",
    "    work = work.dropna()\n",
    "    X = work[cols].values\n",
    "    y = work['yield_10y'].values\n",
    "    idx = work.index.values.astype(int)\n",
    "    return X, y, idx\n",
    "\n",
    "def eval_metrics_safe(df_pred, label):\n",
    "    if df_pred is None or len(df_pred)==0:\n",
    "        return pd.Series({'Model':label, 'MAE':np.nan, 'RMSE':np.nan})\n",
    "    mae = mean_absolute_error(df_pred['y_true'], df_pred['y_pred'])\n",
    "    rmse = sqrt(mean_squared_error(df_pred['y_true'], df_pred['y_pred']))\n",
    "    return pd.Series({'Model':label, 'MAE':mae, 'RMSE':rmse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- pronósticos por ventana expandida ----------\n",
    "def naive_recursive_forecast(df, start_year):\n",
    "    preds, trues, years = [], [], []\n",
    "    for yr in range(start_year, int(df.index.max())+1):\n",
    "        hist = df.loc[df.index < yr]\n",
    "        if len(hist) < 1: \n",
    "            continue\n",
    "        y_hat = float(hist['yield_10y'].iloc[-1])    # último valor\n",
    "        y_true = float(df.loc[yr, 'yield_10y'])\n",
    "        preds.append(y_hat); trues.append(y_true); years.append(int(yr))\n",
    "    return pd.DataFrame({'Year':years, 'y_true':trues, 'y_pred':preds}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_recursive_forecast_fix(df, start_year, p=1, min_train=3):\n",
    "    preds, trues, years = [], [], []\n",
    "    for yr in range(start_year, int(df.index.max())+1):\n",
    "        train = df.loc[df.index < yr]\n",
    "        if len(train) < max(min_train, p+1):\n",
    "            continue\n",
    "        try:\n",
    "            res = VAR(train).fit(p)  # p fijo para muestras pequeñas\n",
    "            preds.append(float(res.forecast(res.y, steps=1)[0][0]))  # 1ª col = yield\n",
    "            trues.append(float(df.loc[yr, 'yield_10y']))\n",
    "            years.append(int(yr))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.DataFrame({'Year':years, 'y_true':trues, 'y_pred':preds}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_recursive_forecast(df, start_year, lags, model):\n",
    "    X_all, y_all, idx = make_supervised(df, lags=lags)\n",
    "    preds, trues, years = [], [], []\n",
    "    # map year -> row position en X_all\n",
    "    year_to_pos = {int(y):i for i,y in enumerate(idx)}\n",
    "    for yr in range(start_year, int(df.index.max())+1):\n",
    "        if yr not in year_to_pos: \n",
    "            continue\n",
    "        pos = year_to_pos[yr]\n",
    "        if pos < 1: \n",
    "            continue\n",
    "        X_train, y_train = X_all[:pos], y_all[:pos]\n",
    "        X_test, y_test   = X_all[pos:pos+1], y_all[pos:pos+1]\n",
    "        if len(y_train) < 3:\n",
    "            continue\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_hat = float(model.predict(X_test)[0])\n",
    "            preds.append(y_hat); trues.append(float(y_test[0])); years.append(int(yr))\n",
    "        except Exception:\n",
    "            continue\n",
    "    return pd.DataFrame({'Year':years, 'y_true':trues, 'y_pred':preds}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- ejecución para un país ----------\n",
    "def run_country_ML(dfc, country_name, test_start=2018, lags=1):\n",
    "    dfc = dfc.dropna().copy()\n",
    "    dfc.index = dfc.index.astype(int)\n",
    "    if len(dfc) < max(6, lags+3):\n",
    "        print(f\"[{country_name}] muy pocos datos -> se omite.\")\n",
    "        return pd.DataFrame(columns=['Model','MAE','RMSE'])\n",
    "    first, last = int(dfc.index.min()), int(dfc.index.max())\n",
    "    print(f\"{country_name} años disponibles: {first} → {last} | N= {len(dfc)}\")\n",
    "    TEST_START = max(test_start, first + lags + 2)  # garantía de mínimo train\n",
    "    print(\"TEST_START usado:\", TEST_START)\n",
    "\n",
    "    # Naive\n",
    "    p_naive = naive_recursive_forecast(dfc, TEST_START)\n",
    "    m_naive = eval_metrics_safe(p_naive, \"Naive\")\n",
    "\n",
    "    # VAR (p=1)\n",
    "    p_var = var_recursive_forecast_fix(dfc, TEST_START, p=1, min_train=3)\n",
    "    m_var  = eval_metrics_safe(p_var, \"VAR(p=1)\")\n",
    "\n",
    "    # ElasticNet\n",
    "    enet = Pipeline([('scaler', StandardScaler()),\n",
    "                     ('model', ElasticNetCV(l1_ratio=[0.1,0.5,0.9], cv=3, max_iter=20000, n_jobs=None))])\n",
    "    p_en = sk_recursive_forecast(dfc, TEST_START, lags=lags, model=enet)\n",
    "    m_en = eval_metrics_safe(p_en, \"ElasticNet\")\n",
    "\n",
    "    # RandomForest\n",
    "    rf = RandomForestRegressor(n_estimators=400, max_depth=None, random_state=0)\n",
    "    p_rf = sk_recursive_forecast(dfc, TEST_START, lags=lags, model=rf)\n",
    "    m_rf = eval_metrics_safe(p_rf, \"RandomForest\")\n",
    "\n",
    "    # GradientBoosting\n",
    "    gb = GradientBoostingRegressor(random_state=0)\n",
    "    p_gb = sk_recursive_forecast(dfc, TEST_START, lags=lags, model=gb)\n",
    "    m_gb = eval_metrics_safe(p_gb, \"GradientBoosting\")\n",
    "\n",
    "    res = pd.DataFrame([m_naive, m_var, m_en, m_rf, m_gb])\n",
    "    print(f\"# de predicciones usadas -> Naive: {len(p_naive)} | VAR: {len(p_var)} | EN: {len(p_en)} | RF: {len(p_rf)} | GB: {len(p_gb)}\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Lanza para los países disponibles ----------\n",
    "all_results = []\n",
    "\n",
    "countries = {\n",
    "    'USA': 'df_us',\n",
    "    'Germany': 'df_germany' if 'df_germany' in globals() else 'df_de',\n",
    "    'Spain': 'df_es',\n",
    "    'United Kingdom': 'df_uk',\n",
    "    'Japan': 'df_jp'\n",
    "}\n",
    "\n",
    "for name, varname in countries.items():\n",
    "    if isinstance(varname, str) and varname in globals():\n",
    "        dfc = globals()[varname]\n",
    "        try:\n",
    "            dfc = dfc[['yield_10y','inflation_yoy']]\n",
    "        except Exception:\n",
    "            print(f\"[{name}] dataframe no tiene columnas esperadas, se omite.\")\n",
    "            continue\n",
    "        res = run_country_ML(dfc, name, test_start=2018, lags=1)\n",
    "        if len(res):\n",
    "            res.insert(0, 'Country', name)\n",
    "            all_results.append(res)\n",
    "    else:\n",
    "        print(f\"[{name}] no encontrado en el entorno, se omite.\")\n",
    "\n",
    "results_table = pd.concat(all_results, ignore_index=True) if all_results else pd.DataFrame(columns=['Country','Model','MAE','RMSE'])\n",
    "display(results_table)\n",
    "# ========= FIN BLOQUE =========\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest ML multi-país: yield_10y ~ {lags(yield_10y), lags(inflation_yoy)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 0) ENTRADAS ESPERADAS --------\n",
    "# - DataFrame 'yields' con col 'time' (epoch ms o fecha) y columnas 10Y tipo 'US10','DE10','GB10','JP10','ES10',...\n",
    "# - DataFrame 'wb_small' con columnas ['Country','Year','inflation_yoy']\n",
    "#\n",
    "# Si no existen en memoria, intenta cargarlos desde archivos habituales:\n",
    "try:\n",
    "    yields\n",
    "except NameError:\n",
    "    yields = pd.read_csv(YIELDS_CSV)\n",
    "\n",
    "try:\n",
    "    wb_small\n",
    "except NameError:\n",
    "    wb = pd.read_csv(WORLD_BANK_DATA)\n",
    "    wb_small = wb.rename(columns={\n",
    "        'country_name':'Country',\n",
    "        'year':'Year',\n",
    "        'Inflation (CPI %)':'inflation_yoy'\n",
    "    })[['Country','Year','inflation_yoy']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 1) UTILIDADES DE DATOS --------\n",
    "def make_annual_yields(yields_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Agrega por año todas las columnas XX10 que existan en 'yields'.\"\"\"\n",
    "    df = yields_df.copy()\n",
    "    # Asegura columna fecha->año\n",
    "    if 'time' in df.columns:\n",
    "        try:\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='ms', errors='coerce')\n",
    "        except Exception:\n",
    "            df['time'] = pd.to_datetime(df['time'], errors='coerce')\n",
    "        df = df.dropna(subset=['time'])\n",
    "        df['Year'] = df['time'].dt.year\n",
    "    elif 'Year' not in df.columns:\n",
    "        raise ValueError(\"No encuentro 'time' ni 'Year' en yields.\")\n",
    "    # columnas 10Y (XX10)\n",
    "    ten10 = [c for c in df.columns if re.fullmatch(r\"[A-Z]{2}10\", str(c))]\n",
    "    if not ten10:\n",
    "        raise ValueError(\"No encuentro columnas '*10' (p.ej. US10, DE10) en yields.\")\n",
    "    # media anual\n",
    "    y_ann = df.groupby('Year', as_index=False)[ten10].mean()\n",
    "    return y_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_country_df(y_ann: pd.DataFrame, wb_small: pd.DataFrame, code2: str, country_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Crea df con Year, yield_10y, inflation_yoy para un país.\"\"\"\n",
    "    col = f\"{code2}10\"\n",
    "    if col not in y_ann.columns:\n",
    "        raise KeyError(f\"No existe {col} en yields anuales.\")\n",
    "    y = (y_ann[['Year', col]]\n",
    "         .rename(columns={col:'yield_10y'}))\n",
    "    i = (wb_small.query(\"Country == @country_name\")[['Year','inflation_yoy']]\n",
    "         .copy())\n",
    "    df = (y.merge(i, on='Year', how='inner')\n",
    "            .dropna()\n",
    "            .set_index('Year')\n",
    "            .sort_index())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lags(df: pd.DataFrame, lags:int=3) -> pd.DataFrame:\n",
    "    \"\"\"Crea variables rezagadas para ambos (yield_10y, inflation_yoy). Salida: X, y, index.\"\"\"\n",
    "    d = df.copy()\n",
    "    for L in range(1, lags+1):\n",
    "        d[f'yield_10y_l{L}'] = d['yield_10y'].shift(L)\n",
    "        d[f'inflation_yoy_l{L}'] = d['inflation_yoy'].shift(L)\n",
    "    d = d.dropna().copy()\n",
    "    y = d['yield_10y'].copy()\n",
    "    X = d.drop(columns=['yield_10y'])\n",
    "    return X, y, d.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 2) MODELOS ROLLING --------\n",
    "def naive_recursive(df: pd.DataFrame, start_year:int) -> pd.DataFrame:\n",
    "    \"\"\"Predicción naive: y_hat_t = y_{t-1}.\"\"\"\n",
    "    df = df.sort_index()\n",
    "    preds, truth, idx = [], [], []\n",
    "    years = df.index.values\n",
    "    for t in years:\n",
    "        if t < start_year: \n",
    "            continue\n",
    "        pos = np.where(years==t)[0][0]\n",
    "        if pos == 0: \n",
    "            continue\n",
    "        y_hat = df.iloc[pos-1]['yield_10y']\n",
    "        preds.append(float(y_hat))\n",
    "        truth.append(float(df.iloc[pos]['yield_10y']))\n",
    "        idx.append(int(t))\n",
    "    return pd.DataFrame({'Year':idx,'y_pred':preds,'y_true':truth}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_recursive(df: pd.DataFrame, start_year:int, maxlags:int=3) -> pd.DataFrame:\n",
    "    \"\"\"VAR rolling 1 paso; se salta si no hay suficientes datos.\"\"\"\n",
    "    df = df.sort_index()\n",
    "    preds, truth, idx = [], [], []\n",
    "    years = df.index.values\n",
    "    for t in years:\n",
    "        if t < start_year:\n",
    "            continue\n",
    "        end_pos = np.where(years==t)[0][0]\n",
    "        train = df.iloc[:end_pos]\n",
    "        if len(train) < (maxlags+4):  # seguridad\n",
    "            continue\n",
    "        safe = max(1, min(maxlags, (len(train)-2)//2))\n",
    "        try:\n",
    "            res = VAR(train).fit(ic='aic', maxlags=safe)\n",
    "            y_hat = res.forecast(train.values[-res.k_ar:], steps=1)[0][0]  # 1ª variable = yield\n",
    "        except Exception:\n",
    "            continue\n",
    "        preds.append(float(y_hat))\n",
    "        truth.append(float(df.iloc[end_pos]['yield_10y']))\n",
    "        idx.append(int(t))\n",
    "    return pd.DataFrame({'Year':idx,'y_pred':preds,'y_true':truth}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sk_recursive(df: pd.DataFrame, start_year:int, model, lags:int=3) -> pd.DataFrame:\n",
    "    \"\"\"Framework común para ElasticNet / RF / GB con features de rezagos.\"\"\"\n",
    "    df = df.sort_index()\n",
    "    # Pre-lags para no recalcular en cada ventana\n",
    "    Xall, yall, idx_all = make_lags(df, lags=lags)  # índices coinciden con años válidos\n",
    "    preds, truth, idx = [], [], []\n",
    "    years = df.index.values\n",
    "    for t in years:\n",
    "        if t < start_year: \n",
    "            continue\n",
    "        if t not in idx_all: \n",
    "            # no hay suficientes rezagos aún\n",
    "            continue\n",
    "        # train = años con índice < t dentro de idx_all\n",
    "        mask_train = idx_all < t\n",
    "        if mask_train.sum() < 5:  # mínimo razonable\n",
    "            continue\n",
    "        X_tr, y_tr = Xall[mask_train], yall[mask_train]\n",
    "        try:\n",
    "            mdl = model() if callable(model) else model\n",
    "            mdl.fit(X_tr, y_tr)\n",
    "            # pred para el año t (fila exacta de idx_all == t)\n",
    "            x_t = Xall[idx_all==t]\n",
    "            y_hat = mdl.predict(x_t)[0]\n",
    "        except Exception:\n",
    "            continue\n",
    "        preds.append(float(y_hat))\n",
    "        # verdad para t\n",
    "        truth.append(float(df.loc[t, 'yield_10y']))\n",
    "        idx.append(int(t))\n",
    "    return pd.DataFrame({'Year':idx,'y_pred':preds,'y_true':truth}).set_index('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(df_pred: pd.DataFrame):\n",
    "    if df_pred is None or df_pred.empty:\n",
    "        return np.nan, np.nan, 0\n",
    "    return (mean_absolute_error(df_pred['y_true'], df_pred['y_pred']),\n",
    "            sqrt(mean_squared_error(df_pred['y_true'], df_pred['y_pred'])),\n",
    "            len(df_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 3) PREPARAR Y CORRER --------\n",
    "y_ann = make_annual_yields(yields)\n",
    "\n",
    "countries = [\n",
    "    # (nombre_mostrar, code2 en yields, nombre_en_WB)\n",
    "    (\"USA\",     \"US\", \"United States\"),\n",
    "    (\"Germany\", \"DE\", \"Germany\"),\n",
    "    (\"United Kingdom\", \"GB\", \"United Kingdom\"),\n",
    "    (\"Japan\",   \"JP\", \"Japan\"),\n",
    "    (\"Spain\",   \"ES\", \"Spain\"),\n",
    "]\n",
    "\n",
    "TEST_START_DEFAULT = 2018   # para garantizar observaciones en la ventana de test\n",
    "LAGS_SK = 3\n",
    "\n",
    "rows = []\n",
    "\n",
    "for display_name, code2, wb_name in countries:\n",
    "    # construir panel país\n",
    "    try:\n",
    "        dfc = build_country_df(y_ann, wb_small, code2, wb_name)\n",
    "    except Exception as e:\n",
    "        print(f\"[{display_name}] no se pudo construir el panel -> {e}. Se omite.\")\n",
    "        continue\n",
    "\n",
    "    # rango y elección de test_start\n",
    "    yr_min, yr_max, N = int(dfc.index.min()), int(dfc.index.max()), len(dfc)\n",
    "    # si hay al menos 8–9 obs, usa 2018; si no, desplaza\n",
    "    TEST_START = TEST_START_DEFAULT\n",
    "    while TEST_START <= yr_min and TEST_START < yr_max:\n",
    "        TEST_START += 1\n",
    "    while (yr_max - TEST_START + 1) < 3 and TEST_START > yr_min:  # al menos 3 puntos de test\n",
    "        TEST_START -= 1\n",
    "\n",
    "    print(f\"\\n{display_name} años disponibles: {yr_min} → {yr_max} | N= {N}\")\n",
    "    print(\"TEST_START usado:\", TEST_START)\n",
    "\n",
    "    # NAIVE\n",
    "    p_naive = naive_recursive(dfc, TEST_START)\n",
    "    mae, rmse, n = metrics(p_naive)\n",
    "    rows.append([display_name, \"Naive\", mae, rmse, n])\n",
    "\n",
    "    # VAR (si alcanza)\n",
    "    p_var = var_recursive(dfc, TEST_START, maxlags=3)\n",
    "    mae, rmse, n = metrics(p_var)\n",
    "    rows.append([display_name, f\"VAR(p=? )\", mae, rmse, n])\n",
    "\n",
    "    # ElasticNet\n",
    "    def EN(): return ElasticNetCV(l1_ratio=[0.1,0.5,0.9], cv=3, max_iter=30000, n_jobs=None)\n",
    "    p_en = sk_recursive(dfc, TEST_START, EN, lags=LAGS_SK)\n",
    "    mae, rmse, n = metrics(p_en)\n",
    "    rows.append([display_name, \"ElasticNet\", mae, rmse, n])\n",
    "\n",
    "    # RandomForest\n",
    "    def RF(): return RandomForestRegressor(n_estimators=500, random_state=7)\n",
    "    p_rf = sk_recursive(dfc, TEST_START, RF, lags=LAGS_SK)\n",
    "    mae, rmse, n = metrics(p_rf)\n",
    "    rows.append([display_name, \"RandomForest\", mae, rmse, n])\n",
    "\n",
    "    # GradientBoosting\n",
    "    def GB(): return GradientBoostingRegressor(random_state=7)\n",
    "    p_gb = sk_recursive(dfc, TEST_START, GB, lags=LAGS_SK)\n",
    "    mae, rmse, n = metrics(p_gb)\n",
    "    rows.append([display_name, \"GradientBoosting\", mae, rmse, n])\n",
    "\n",
    "    print(f\"# de predicciones usadas => Naive: {len(p_naive)} | VAR: {len(p_var)} | EN: {len(p_en)} | RF: {len(p_rf)} | GB: {len(p_gb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- 4) RESUMEN --------\n",
    "summary = pd.DataFrame(rows, columns=['Country','Model','MAE','RMSE','N_pred']).sort_values(['Country','MAE'])\n",
    "display(summary)\n",
    "filename = \"files/output/ml_backtest_summary.csv\"\n",
    "summary.to_csv(filename, index=False)\n",
    "print(f\"\\nGuardado: {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
